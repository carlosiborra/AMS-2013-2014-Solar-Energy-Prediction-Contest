{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1. Aprendizaje Automático\n",
    "\n",
    "Authors: Carlos Iborra Llopis (100451170), Alejandra Galán Arrospide (100451273) <br>\n",
    "Link al repositorio de GitHub: https://github.com/carlosiborra/Grupo02-Practica1-AprendizajeAutomatico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Table of contents\n",
    "\n",
    "- [Práctica 1. Aprendizaje Automático](#práctica-1-aprendizaje-automático)\n",
    "  - [0. Table of contents](#0-table-of-contents)\n",
    "  - [1. Requirements](#1-requirements)\n",
    "  - [2. Reading the datasets](#2-reading-the-datasets)\n",
    "  - [3. Exploratory Data Analysis](#3-EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Importing necessary libraries \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from matplotlib.cbook import boxplot_stats as bps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Cleaning ../data/img/ folder\n",
    "This way we avoid creating multiple images and sending the old ones to the trash.<br>\n",
    "Also using this to upload cleaner commits to GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Cleaning the ../data/img/ folder \"\"\"\n",
    "import os\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"../data/img/*\")\n",
    "for f in files:\n",
    "    if os.path.isfile(f) and f.endswith(\".png\"):\n",
    "        os.remove(f)\n",
    "\n",
    "files = glob.glob(\"../data/img/box-plot/*\")\n",
    "for f in files:\n",
    "    if os.path.isfile(f) and f.endswith(\".png\"):\n",
    "        os.remove(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Reading the datasets\n",
    "Reading the datasets from the bz2 files, group 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Reading the dataset \"\"\"\n",
    "disp_df = pd.read_csv(\"../data/disp_st2ns1.txt.bz2\", compression=\"bz2\", index_col=0)\n",
    "comp_df = pd.read_csv(\"../data/comp_st2ns1.txt.bz2\", compression=\"bz2\", index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts of Exploratory Data Analysis**\n",
    "\n",
    "- **2 types of Data Analysis**\n",
    "  - Confirmatory Data Analysis\n",
    "  - Exploratory Data Analysis\n",
    "- **4 Objectives of EDA**\n",
    "  - Discover Patterns\n",
    "  - Spot Anomalies\n",
    "  - Frame Hypothesis\n",
    "  - Check Assumptions\n",
    "- **2 methods for exploration**\n",
    "  - Univariate Analysis\n",
    "  - Bivariate Analysis\n",
    "- **Stuff done during EDA**\n",
    "  - Trends\n",
    "  - Distribution\n",
    "  - Mean\n",
    "  - Median\n",
    "  - Outlier\n",
    "  - Spread measurement (SD)\n",
    "  - Correlations\n",
    "  - Hypothesis testing\n",
    "  - Visual Exploration\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Dataset preparation\n",
    "\n",
    "To conduct exploratory data analysis (EDA) on our real data, we need to prepare the data first. Therefore, we have decided to separate the data into training and test sets at an early stage to avoid data leakage, which could result in an overly optimistic evaluation of the model, among other consequences. This separation will be done by dividing the data prematurely into training and test sets since potential data leakage can occur from the usage of the test partition, especially when including the result variable.\n",
    "\n",
    "It is important to note that this step is necessary because all the information obtained in this section will be used to make decisions such as dimensionality reduction. Furthermore, this approach makes the evaluation more realistic and rigorous since the test set is not used until the end of the process.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train Test Split (time series) \"\"\"\n",
    "\n",
    "# * Make a copy of the dataframe (as Padas dataframe is mutable, therefore uses a reference)\n",
    "disp_df_copy = disp_df.copy()\n",
    "\n",
    "# print(disp_df)\n",
    "# print(disp_df_copy)\n",
    "\n",
    "# Now we make the train_x, train_y, test_x, test_y splits taking into account the time series\n",
    "# Note: the time series is ordered by date, therefore we need to split the data in a way that the train data is before the test data\n",
    "# Note: the 10 first years are used for training and the last two years for testing\n",
    "# Note: this is done because if not, we will be predicting the past from the future, which leads to errors and overfitting (data leakage) in the model\n",
    "\n",
    "# * Calculate the number of rows for training and testing\n",
    "num_rows = disp_df_copy.shape[0]\n",
    "num_train_rows = int(\n",
    "    num_rows * 10 / 12\n",
    ")  # 10 first years for training, 2 last years for testing\n",
    "\n",
    "# * Split the data into train and test dataframes (using iloc instead of train_test_split as it picks random rows)\n",
    "train_df = disp_df_copy.iloc[\n",
    "    :num_train_rows, :\n",
    "]  # train contains the first 10 years of rows\n",
    "test_df = disp_df_copy.iloc[\n",
    "    num_train_rows:, :\n",
    "]  # test contains the last 2 years of rows\n",
    "\n",
    "# Print the number of rows for each dataframe\n",
    "print(f\"Number of rows for training (EDA): {train_df.shape[0]}\")\n",
    "print(f\"Number of rows for testing: {test_df.shape[0]}\")\n",
    "\n",
    "\n",
    "# ! We maintain the original dataframe for later use (as we will divide it into train and test dataframes below)\n",
    "# ! For the EDA, we will use the train_df dataframe (with the outpout variable)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Dataset description\n",
    "\n",
    "- **apcp_sfc**: 3-Hour accumulated precipitation at the surface (kg·m⁽⁻²⁾)\n",
    "- **dlwrf_sfc**: Downward long-wave radiative flux average at the surface (W·m⁽⁻²⁾)\n",
    "- **dswrf_sfc**: Downward short-wave radiative flux average at the surface (W·m⁽⁻²⁾)\n",
    "- **pres_msl**: Air pressure at mean sea level (Pa)\n",
    "- **pwat_eatm**: Precipitable Water over the entire depth of the atmosphere (kg·m⁽⁻²⁾)\n",
    "- **spfh_2m**: Specific Humidity at 2 m above ground (kg·kg⁽⁻¹⁾)\n",
    "- **tcdc_eatm**: Total cloud cover over the entire depth of the atmosphere (%)\n",
    "- **tcolc_eatm**: Total column-integrated condensate over the entire atmos. (kg·m⁽⁻²⁾)\n",
    "- **tmax_2m**: Maximum Temperature over the past 3 hours at 2 m above the ground (K)\n",
    "- **tmin_2m**: Mininmum Temperature over the past 3 hours at 2 m above the ground (K)\n",
    "- **tmp_2m**: Current temperature at 2 m above the ground (K)\n",
    "- **tmp_sfc**: Temperature of the surface (K)\n",
    "- **ulwrf_sfc**: Upward long-wave radiation at the surface (W·m⁽⁻²⁾)\n",
    "- **ulwrf_tatm**: Upward long-wave radiation at the top of the atmosphere (W·m⁽⁻²⁾)\n",
    "- **uswrf_sfc**: Upward short-wave radiation at the surface (W·m⁽⁻²⁾)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the columns of the dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Missing values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, we check the number the total number of missing values in the dataset in order to know if we have to clean the dataset or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can oberve, there are no missing values in the dataset, but theres still the possibility of having missing values measured as 0's, so we will check if all those zeros make sense in the context of the dataset or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the plot, we can see that there are a lot of 0 values in the dataset\n",
    "train_df.plot(legend=False, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_df.eq(0.0).sum() / len(train_df) * 100\n",
    "\n",
    "# Select those columns with more than 30% of zeros\n",
    "result = result[result > 30.0]\n",
    "result = result.sort_values(ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "As output of the previous cell, we can see that there exist a lot of zeros in the dataset, let's analize if those zeros make sense or not.\n",
    "\n",
    "The variables with most ammount of zeros (>30%) are:\n",
    "\n",
    "- **dswrf_s1_1**: Downward short-wave radiative flux average at the surface, at 12:00 UTC, normal to have a lot of zeros as it is not sunny at 12:00\n",
    "- **uswrf_s1_1**: Upward short-wave radiation at the surface, at 12:00 UTC, normal to have a lot of zeros as it is not sunny at 12:00\n",
    "- **apcp_s**: 3-Hour accumulated precipitation at the surface, as it is not raining every day, it is normal to have a lot of zeros\n",
    "- **tcdc_ea**: Total cloud cover over the entire depth of the atmosphere, as it is not cloudy every day, it is normal to have a lot of zeros\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets start by assigning the zeros to NaNs. By doing this we can visualize the varibles that take more values other than zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_df_nan = train_df.replace(0.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting missing values \"\"\"\n",
    "# Sustitute 0.0 values with NaN and plot the name of the columns with missing values\n",
    "# ? msno.bar is a simple visualization of nullity by column\n",
    "msno.bar(disp_df_nan, labels=True, fontsize=7, figsize=(15, 7))\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/missing_values_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting the missing values in a matrix \"\"\"\n",
    "\n",
    "# ? The msno.matrix nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion.\n",
    "msno.matrix(disp_df_nan)\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/missing_values_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting the missing values in a heatmap \"\"\"\n",
    "# As in a hetmap not every value is shown, we must delimit the values to the ones with more than 30% of missing values\n",
    "result = disp_df.eq(0.0).sum() / len(disp_df) * 100\n",
    "result = result[result > 30.0]  # Select those columns with more than 30% of zeros\n",
    "result = result.sort_values(ascending=False)\n",
    "result = result.index.tolist()  # Convert to list\n",
    "result\n",
    "\n",
    "# ? The missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another\n",
    "msno.heatmap(disp_df_nan[result], fontsize=7, figsize=(15, 7))\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/missing_values_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting the dendrogram \"\"\"\n",
    "\n",
    "# ? The dendrogram allows you to more fully correlate variable completion, revealing trends deeper than the pairwise ones visible in the correlation heatmap:\n",
    "msno.dendrogram(disp_df_nan, orientation=\"top\", fontsize=7, figsize=(15, 7))\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/missing_values_dendrogram.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Conclusions\n",
    "In this section, we have observe that there are no attibutes with 'Null' nor 'NaN' nor 'None' values. This indicated that at a first glance, the data is clean, at least of those datatypes.\n",
    "\n",
    "In second place, we have observed that the attributes that we suspected could have an important number of missing values (represented by 0 instead of the previously mentioned), had instead valuable information, as we have proved along this section.<br>Since the data is clean and we have concluded there are no missing values, we do not need to complete them using a model or other methods, so we can move on to the next step, observing the outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Outliers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting outliers in a dataset before training a model is crucial because outliers can significantly affect the performance and accuracy of the model. Outliers are data points that deviate significantly from the rest of the dataset and can cause the model to learn incorrect patterns and relationships. When outliers are present in the data, they can also increase the variance of the model, which can result in overfitting. Overfitting occurs when the model fits too closely to the training data, leading to poor generalization to new data. Therefore, it is important to detect and handle outliers appropriately to ensure the model's accuracy and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_attributes = train_df.columns.values.tolist()\n",
    "#print(list_of_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot with all attributes in the dataset\n",
    "# sns.boxplot(data=train_df, orient=\"h\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['apcp_sf1_1'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, by plotting the boxplots and making the outliers (fliers) visible, we are able to see some outliers in the dataset.<br>\n",
    "Take into account that the outliers are represented by the points outside the boxplot and they can be potentially wrong values or just values that are not usual in the dataset (ruido)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Histogram to identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Histogram showing the distribtuion of train_df to show the outliers \"\"\"\n",
    "plt.hist(train_df)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Boxplot to identify outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objective of noticing the outliers on each attribute, we create a box-plot of each of the attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting the boxplot for each attribute and getting the outliers of each attribute \"\"\"\n",
    "total_outliers = []\n",
    "# * We iterate over the list of attributes\n",
    "for attribute in list_of_attributes:\n",
    "    # * sns.regplot(x=train_df[attribute], y=train_df['total'], fit_reg=False)\n",
    "    sns.boxplot(data=train_df[attribute], x=train_df[attribute], orient=\"h\")\n",
    "    # * Use the command below to show each plot (small size for visualization sake)\n",
    "    # sns.set(rc={'figure.figsize':(1,.5)})\n",
    "    # plt.show()\n",
    "    # * All the images are saved in the folder ../data/img/box-plot\n",
    "    plt.savefig(f\"../data/img/box-plot/{str(attribute)}.png\")\n",
    "\n",
    "    # We obtain the a list of outliers for each attribute\n",
    "    list_of_outliers = train_df[attribute][train_df[attribute] > train_df[attribute].quantile(0.75) + 1.5*(train_df[attribute].quantile(0.75) - train_df[attribute].quantile(0.25))].tolist()\n",
    "    outliers = [f'{attribute} outliers'] + [len(list_of_outliers)] + [list_of_outliers]\n",
    "    # * In order to print the total number of outliers for each attribute\n",
    "    # print(f'{attribute} has {len(list_of_outliers)} outliers')\n",
    "    # ! Data structure: [attribute, number of outliers, list of outliers]\n",
    "    # print(outliers)\n",
    "    total_outliers.append(outliers)\n",
    "\n",
    "# print the first 2 elements of each element in the list -> [[atb, num],[atb, num],...]\n",
    "num_atb_outliers = 0\n",
    "for i in total_outliers:\n",
    "    if i[1] != 0:\n",
    "        num_atb_outliers += 1\n",
    "        print(f\"{i[0:2]}...\")\n",
    "        \n",
    "# Number of outliers != 0 for each attribute\n",
    "print(f\"Total number of atributes with outliers: {num_atb_outliers} / {len(total_outliers)-1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to create a list containing the name of the atribute, the number of outliers and the value of the outliers for each attribute, calculated by applying the IQR method.<br> This is relevant as we managed to create a 'total_outliers' variable that contains the list data structures of all the different outliers from all the attributes, so that it can be easily accessed in a future to remove the outliers from the dataset if needed for testing purposes.\n",
    "\n",
    "As suspected, we can see that **there are a lot of outliers in the dataset**, therefore it is plausible that some of them are noise, thus possibly being removed in a future model in order to improve it (either by hand or by selection in the preprocess pipeline).<br>Now, we need to analyze if they are the result of bad measurements or if they are significant data for the analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionaly, as we will see later, this amount of outliers indicate us that probably a Robust Scaler will be more appropriate than using a Standard Scaler, as the Robust Scaler is more robust to outliers than the Standard Scaler, thus being more appropriate for this dataset model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Skewness and Kurtosis to identify outliers\n",
    "Skewness and kurtosis are commonly used to measure the shape of a distribution. Skewness measures the degree of asymmetry in the distribution, while kurtosis measures the degree of flatness in the distribution compared to a normal distribution.\n",
    "We will look for observations that are far from the central tendency of the distribution and may indicate the presence of extreme values or data points that do not fit the pattern of the majority of the data (which as expected, happens to be the case in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Skewness \"\"\"\n",
    "# ? skewness: measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.\n",
    "train_df.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Kurtosis \"\"\"\n",
    "# ? kurtosis: measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution.\n",
    "train_df.kurt().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"apcp_sf4_1\"]\n",
    "plt.figure(1)\n",
    "plt.title(\"Normal\")\n",
    "sns.distplot(y, kde=True, fit=st.norm)\n",
    "plt.figure(2)\n",
    "plt.title(\"Log Normal\")\n",
    "sns.distplot(y, kde=True, fit=st.lognorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.skew(), color=\"blue\", axlabel=\"Skewness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.distplot(\n",
    "    train_df.kurt(), color=\"r\", axlabel=\"Kurtosis\", norm_hist=False, kde=True, rug=False\n",
    ")\n",
    "# plt.hist(train.kurt(),orientation = 'vertical',histtype = 'bar',label ='Kurtosis', color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Correlation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are getting information about the correlation of the variables between them. This information is valuable in order to make good decisions when deleting redundant attributes. Also note we are getting information about the correlation between each attribute and the solution variable. This allows us to know the most relevant attributes, making the best decisions when creating the different models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = train_df.corr()\n",
    "correlation = abs(correlation)\n",
    "print(correlation.shape)  # 76 x 76 matrix of correlation values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the correlation matrix formatted into our own data structure\n",
    "This is done for the sake of simplicity and to be able to visualize the correlation matrix in a more intuitive way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list = []\n",
    "\n",
    "for column in train_df.columns:\n",
    "    correlation.loc[:, column] = abs(\n",
    "        correlation.iloc[:, train_df.columns.get_loc(column)]\n",
    "    )\n",
    "    mask = correlation.loc[:, column] > 0.95\n",
    "    # print(correlation[column][mask].sort_values(ascending = False))\n",
    "\n",
    "    # Translate the comment below to English:\n",
    "    # we add the correlation values to a list of lists, which contains the names of the correlated columns and their correlation index\n",
    "\n",
    "    # The first segment adds the name of the column we are analyzing\n",
    "    # The second segment adds the names of the columns correlated (except the column we are analyzing) > 0.95\n",
    "    # The third segment adds the correlation index of the columns correlated (except the column we are analyzing) > 0.95\n",
    "    # Second and third segment are added to the first segment as a list of lists\n",
    "\n",
    "    # First we need to create a dictionary with the column names and their correlation values (except the column we are analyzing)\n",
    "    dict = {\n",
    "        key: value\n",
    "        for key, value in correlation.loc[column, mask]\n",
    "        .sort_values(ascending=False)\n",
    "        .iloc[1:]\n",
    "        .to_dict()\n",
    "        .items()\n",
    "    }\n",
    "    # print (dict)\n",
    "\n",
    "    # Then we create a list of lists with the column names and their correlation values from the dictionary created above\n",
    "    corr_list = [[key] + [value] for key, value in dict.items()]\n",
    "    # Finally we add the name of the column we are analyzing to the list of lists created above as the first element of the list (str)\n",
    "    corr_list.insert(0, [\"Columna: \" + column])\n",
    "\n",
    "    # ! Data structure: [[columna, [columna correlada 1, indice de correlacion], [columna correlada 2, indice de correlacion], ...], ...]\n",
    "    print(corr_list)\n",
    "\n",
    "    correlation_list += [corr_list]\n",
    "print(correlation_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" seaborne Correlation Heat Map \"\"\"\n",
    "# It needs to show all the columns\n",
    "fig, ax = plt.subplots(figsize=(19, 18))\n",
    "\n",
    "plt.title(\"Correlation Heat Map\", y=1)\n",
    "# We use blue color scale because it is easier to see the annotations and the correlation values\n",
    "sns.heatmap(\n",
    "    correlation,\n",
    "    square=True,\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 4},\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    "    vmin=0.0,\n",
    "    vmax=1,\n",
    ")\n",
    "# We can modify vmax=0.95 in order to get same color scale for values with more than 0.95 correlation\n",
    "# Note: it delays around 15 seconds as it needs to plot a 76*76 matrix with its 5766 correlation values\n",
    "\n",
    "# Exporting image as png to ../data/img folder - easier to visualize the annotations, better resolution\n",
    "plt.savefig(\"../data/img/correlation_heatmap.png\", dpi=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe clearly how there are a lot of correlations between the different attributes, which is expected as they are all weather related variables.<br> This is important to know as it will allow us to know which attributes are redundant and which ones are not, so that we can delete the redundant ones in order to improve the model. <br><br> Once obtained the most correlated columns of the dataset, we can plot them and visualize their correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "columns = ['apcp_sf1_1', 'apcp_sf2_1', 'apcp_sf3_1','apcp_sf4_1', 'apcp_sf5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "columns = [ 'dlwrf_s1_1', 'dlwrf_s2_1', 'dlwrf_s3_1', 'dlwrf_s4_1', 'dlwrf_s5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "columns = ['pwat_ea1_1', 'pwat_ea2_1','pwat_ea3_1','pwat_ea4_1','pwat_ea5_1', 'dlwrf_s1_1', 'dlwrf_s2_1', 'dlwrf_s3_1', 'dlwrf_s4_1', 'dlwrf_s5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "columns = ['dswrf_s1_1', 'dswrf_s2_1', 'dswrf_s3_1', 'dswrf_s4_1', 'dswrf_s5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "columns = ['dswrf_s1_1', 'dswrf_s2_1', 'dswrf_s3_1', 'dswrf_s4_1', 'dswrf_s5_1', 'uswrf_s1_1', 'uswrf_s2_1', 'uswrf_s3_1', 'uswrf_s4_1', 'uswrf_s5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "columns = ['pres_ms1_1', 'pres_ms2_1', 'pres_ms3_1', 'pres_ms4_1', 'pres_ms5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "columns = ['pwat_ea1_1', 'pwat_ea2_1','pwat_ea3_1','pwat_ea4_1','pwat_ea5_1', 'spfh_2m1_1', 'spfh_2m2_1', 'spfh_2m3_1', 'spfh_2m4_1', 'spfh_2m5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "columns = ['spfh_2m1_1', 'spfh_2m2_1', 'spfh_2m3_1', 'spfh_2m4_1', 'spfh_2m5_1','ulwrf_s1_1', 'ulwrf_s2_1', 'ulwrf_s3_1', 'ulwrf_s4_1', 'ulwrf_s5_1']\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1, kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "# columns = ['tmax_2m1_1', 'tmax_2m2_1', 'tmax_2m3_1', 'tmax_2m4_1', 'tmax_2m5_1', 'tmin_2m1_1', 'tmin_2m2_1', 'tmin_2m3_1', 'tmin_2m4_1', 'tmin_2m5_1','tmp_2m_1_1', 'tmp_2m_2_1', 'tmp_2m_3_1', 'tmp_2m_4_1', 'tmp_2m_5_1', 'tmp_sfc1_1', 'tmp_sfc2_1', 'tmp_sfc3_1', 'tmp_sfc4_1', 'tmp_sfc5_1','ulwrf_s1_1', 'ulwrf_s2_1', 'ulwrf_s3_1', 'ulwrf_s4_1', 'ulwrf_s5_1']\n",
    "\n",
    "# sns.pairplot(train_df[columns], height = 1 ,kind ='scatter',diag_kind='kde')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "columns = [\"ulwrf_t1_1\", \"ulwrf_t2_1\", \"ulwrf_t3_1\"]\n",
    "\n",
    "sns.pairplot(train_df[columns], height=1, kind=\"scatter\", diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "columns = ['ulwrf_t4_1', 'ulwrf_t5_1', ]\n",
    "\n",
    "sns.pairplot(train_df[columns], height = 1 ,kind ='scatter',diag_kind='kde')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "columns = [\"uswrf_s2_1\", \"uswrf_s3_1\", \"uswrf_s4_1\", \"uswrf_s5_1\"]\n",
    "\n",
    "sns.pairplot(train_df[columns], height=1, kind=\"scatter\", diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graphs above, we can observe than the most correlated variables present a linear relationship between them. This shows as a diagonal in the graph, since both variables grow at the same time.<br>\n",
    "As we already commented, this is expected as the variables are all weather related, so it is normal that they are correlated and must be taken into account when creating the model (eliminating the redundant ones)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Train-Test division \n",
    "\n",
    "Since we are working with a time dependent data, we need to avoid mixing it. Also, we are required to add the first 10 years of data to the train set and the last 2 years to the test set. This means we are assigning a 83.333333 percent of the data to train and a 16.66666666 to test.\n",
    "\n",
    "**Note**: This division was already done before the EDA. We overwrite it to start from a clean state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `iloc` is useful when we want to split data based on the index or other criteria, while `train_test_split` is useful when wanting to randomly split data into training and testing subsets.<br>\n",
    "Therefore, we will use `iloc` to split the data into train and test sets as we are dealing with time dependent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the metrics from sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# As we have noted during the EDA, for this dataset full of outliers, its preferable to use the RobustScaler\n",
    "# Although this wont make a huge difference\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for training: 3650\n",
      "Number of rows for testing: 730\n",
      "(3650, 75) (3650,) (730, 75) (730,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train Test Split (time series) \"\"\"\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# * Make a copy of the dataframe (as Padas dataframe is mutable, therefore uses a reference)\n",
    "disp_df_copy = disp_df.copy()\n",
    "\n",
    "# print(disp_df)\n",
    "# print(disp_df_copy)\n",
    "\n",
    "# Now we make the train_x, train_y, test_x, test_y splits taking into account the time series\n",
    "# Note: the time series is ordered by date, therefore we need to split the data in a way that the train data is before the test data\n",
    "# Note: the 10 first years are used for training and the last two years for testing\n",
    "# Note: this is done because if not, we will be predicting the past from the future, which leads to errors and overfitting (data leakage) in the model\n",
    "\n",
    "# * Calculate the number of rows for training and testing\n",
    "num_rows = disp_df_copy.shape[0]\n",
    "num_train_rows = int(\n",
    "    num_rows * 10 / 12\n",
    ")  # 10 first years for training, 2 last years for testing\n",
    "\n",
    "# * Split the data into train and test dataframes (using iloc instead of train_test_split as it picks random rows)\n",
    "train_df = disp_df_copy.iloc[\n",
    "    :num_train_rows, :\n",
    "]  # train contains the first 10 years of rows\n",
    "test_df = disp_df_copy.iloc[\n",
    "    num_train_rows:, :\n",
    "]  # test contains the last 2 years of rows\n",
    "\n",
    "# Print the number of rows for each dataframe\n",
    "print(f\"Number of rows for training: {train_df.shape[0]}\")\n",
    "print(f\"Number of rows for testing: {test_df.shape[0]}\")\n",
    "\n",
    "# Print the dataframes\n",
    "# print(train_df), print(test_df)\n",
    "\n",
    "# * Separate the input features and target variable for training and testing\n",
    "X_train = train_df.drop(\"salida\", axis=1)  # This is the input features for training\n",
    "y_train = train_df[\"salida\"]  # This is the target variable for training\n",
    "X_test = test_df.drop(\"salida\", axis=1)  # This is the input features for testing\n",
    "y_test = test_df[\"salida\"]  # This is the target variable for testing\n",
    "\n",
    "# Print the shapes of the dataframes\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Train-Test RMSE and MAE function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function enables us to analyze the level of overfitting in the model. To perform this analysis, we compare the results of the training dataset from the first fold created by the time-series split, with the validation results of the same fold. Note that by using the training and validation sets, we avoid using the test set for any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "def train_and_test_folds (model,score, X_train, y_train, X_test, y_test, dic_folds):\n",
    "    # we print the type of the data X_train\n",
    "    print(type(X_train))\n",
    "    X_train2 = X_train.loc[X_train.index.isin(dic_folds[\"F1\"][0])]\n",
    "    y_train2 = y_train.loc[y_train.index.isin(dic_folds[\"F1\"][0])]\n",
    "\n",
    "    X_test2 = X_train.loc[X_train.index.isin(dic_folds[\"F1\"][1])]\n",
    "    y_test2 = y_train.loc[y_train.index.isin(dic_folds[\"F1\"][1])]\n",
    "    y_train_pred = model.predict(X_train2)\n",
    "    rmse_train = mean_squared_error(y_train2, y_train_pred, squared=False)\n",
    "    mae_train = mean_absolute_error(y_train2, y_train_pred)\n",
    "\n",
    "\n",
    "    y_test_pred = model.predict(X_test2)\n",
    "    rmse_test = mean_squared_error(y_test2, y_test_pred, squared=False)\n",
    "    mae_test = mean_absolute_error(y_test2, y_test_pred)\n",
    "\n",
    "\n",
    "    print(f\"Results of the best estimator of {model.__class__.__name__}\")\n",
    "    print(f\"NMAE in validation: {score:.2f}\")\n",
    "    print(f\"RMSE train: {rmse_train:.2f}\", f\"MAE train: {mae_train:.2f}\", sep=\"\\t\")\n",
    "    print(f\"RMSE test: {rmse_test:.2f}\", f\"MAE test: {mae_test:.2f}\", sep=\"\\t\")\n",
    "\n",
    "    # ! Train accuracy using scatter plot\n",
    "    plt.plot(X_train2.iloc[:, [0]], y_train2, \".\", label=\"train first fold\")\n",
    "    plt.plot(X_train2.iloc[:, [0]], y_train_pred, \"r.\", label=\"train first fold pred\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # ! Prediction errors using a histogram\n",
    "    # Calculate the difference between test predictions and test data\n",
    "    prediction_errors = y_train2 - y_train_pred\n",
    "    \n",
    "    plt.hist(prediction_errors, bins=25)\n",
    "    plt.xlabel('Prediction Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Prediction Errors (RMSE: {rmse_train:.2f}, MAE: {mae_train:.2f})')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # ! Test accuracy using scatter plot\n",
    "    plt.plot(X_test2.iloc[:, [0]], y_test2, \".\", label=\"validation first fold\")\n",
    "    plt.plot(X_test2.iloc[:, [0]], y_test_pred, \"r.\", label=\"validation first fold pred\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    " \n",
    "    # ! Prediction errors using a histogram\n",
    "    # Calculate the difference between test predictions and test data\n",
    "    prediction_errors = y_test2 - y_test_pred\n",
    "\n",
    "    plt.hist(prediction_errors, bins=25)\n",
    "    plt.xlabel('Prediction Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Prediction Errors (RMSE: {rmse_test:.2f}, MAE: {mae_test:.2f})')\n",
    "    plt.show()\n",
    "\n",
    "    return [score, rmse_train, mae_train, rmse_test, mae_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "def train_and_test(model, score, X_train, y_train, X_test, y_test):\n",
    "    # Train\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    # Test\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Results of the best estimator of {model.__class__.__name__}\")\n",
    "    print(f\"NMAE in validation: {score:.2f}\")\n",
    "    print(f\"RMSE train: {rmse_train:.2f}\", f\"MAE train: {mae_train:.2f}\", sep=\"\\t\")\n",
    "    print(f\"RMSE test: {rmse_test:.2f}\", f\"MAE test: {mae_test:.2f}\", sep=\"\\t\")\n",
    "\n",
    "    # ! Train accuracy using scatter plot\n",
    "    # plt.plot(X_train.iloc[:, [0]], y_train, \".\", label=\"train\")\n",
    "    # plt.plot(X_train.iloc[:, [0]], y_train_pred, \"r.\", label=\"train pred\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # ! Prediction errors using a histogram\n",
    "    # Calculate the difference between test predictions and test data\n",
    "    prediction_errors = y_train - y_train_pred\n",
    "    \n",
    "    # plt.hist(prediction_errors, bins=25)\n",
    "    # plt.xlabel('Prediction Errors')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.title(f'Prediction Errors (RMSE: {rmse_train:.2f}, MAE: {mae_train:.2f})')\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "    # ! Test accuracy using scatter plot\n",
    "    # plt.plot(X_test.iloc[:, [0]], y_test, \".\", label=\"test\")\n",
    "    # plt.plot(X_test.iloc[:, [0]], y_test_pred, \"r.\", label=\"test pred\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    " \n",
    "    # ! Prediction errors using a histogram\n",
    "    # Calculate the difference between test predictions and test data\n",
    "    prediction_errors = y_test - y_test_pred\n",
    "\n",
    "    # plt.hist(prediction_errors, bins=25)\n",
    "    # plt.xlabel('Prediction Errors')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.title(f'Prediction Errors (RMSE: {rmse_test:.2f}, MAE: {mae_test:.2f})')\n",
    "    # plt.show()\n",
    "\n",
    "    return [score, rmse_train, mae_train, rmse_test, mae_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Print model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def print_results(name, model, score, time):\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"{name} best model is:\\n\\n{model}\")\n",
    "    print(\"\\nParameters:\", model.best_params_)\n",
    "\n",
    "    print(\n",
    "        f\"\\nPerformance: NMAE (val): {score[0]}\",\n",
    "        f\"RMSE train: {score[1]}\",\n",
    "        f\"MAE train: {score[2]}\",\n",
    "        f\"RMSE train: {score[3]}\",\n",
    "        f\"MAE test: {score[4]}\",\n",
    "        sep=\" | \",\n",
    "    )\n",
    "\n",
    "    print(f\"Execution time: {time}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Basic methods:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this section, we will analyze the performance of three methods: KNN, Regression Trees, and Linear Regression. For each method, we will provide a predefined model and another model with selected hyper-parameters. Our hypothesis is that the selected models will provide better performance, while the predefined ones will be better in terms of timing.\n",
    "\n",
    "Please note that we will be using GridSearch with only one possibility (the predefined one) for the hyper-parameter to make it easier to create the predefined models. Additionally, we have decided to use RandomSearch for the selection of the parameters as it has been shown to provide good results with much less computing required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Three dictionaries to store the results of the models\n",
    "models, results, times = {}, {}, {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. KNN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN (k-Nearest Neighbors) is a non-parametric algorithm used for classification and regression. It works by finding the k closest training examples in the feature space to a new input, and assigns the output value based on the majority class among the k neighbors in the case of classification or the average of the output values in the case of regression(our case). The value of k is a hyperparameter that must be chosen before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1. KNN - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1.1. KNN - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! NEW VERSION\n",
    "\n",
    "\n",
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "# Using a pipeline to scale the data and then apply the model\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scale\", StandardScaler()),\n",
    "        # ('select', SelectKBest(f_regression)),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_neighbors\": [5],\n",
    "    \"model__weights\": [\"uniform\"],\n",
    "    \"model__metric\": [\"minkowski\"],\n",
    "    # 'select__k': list(range(1, X_train.shape[1]+1))\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(\n",
    "        n_splits\n",
    "    ),  # We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# We calculate the subsets used for training and testing in the different folds of the cross-validation\n",
    "dict_folds = {}\n",
    "\n",
    "\n",
    "for n_splits, (train_index, test_index) in enumerate(model.cv.split(X_train)):\n",
    "    index = \"F\"+str(n_splits+1)\n",
    "    train_index_formatted = []\n",
    "    test_index_formatted = []\n",
    "    for i in range(len(train_index)):\n",
    "        train_index_formatted.append( 'V' + str(int(train_index[i]+1)))\n",
    "    \n",
    "    for i in range(len(test_index)):\n",
    "        test_index_formatted.append( 'V' + str(int(test_index[i]+1)))\n",
    "\n",
    "    dict_folds[index] = [train_index_formatted,test_index_formatted]\n",
    "score = train_and_test_folds( model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test, dict_folds)   \n",
    "\n",
    "models[\"KNN_pred\"] = model\n",
    "results[\"KNN_pred\"] = score\n",
    "times[\"KNN_pred\"] = total_time\n",
    "\n",
    "print_results(\"KNN PREDEFINED PARAMETERS\", model, score, total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -3239984.25\n",
      "RMSE train: 3517654.38\tMAE train: 2493007.22\n",
      "RMSE test: 4052918.05\tMAE test: 2932657.73\n",
      "---------------------------------------------------\n",
      "KNN PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scale', RobustScaler()),\n",
      "                                       ('model', KNeighborsRegressor())]),\n",
      "             param_grid={'model__algorithm': ['auto'],\n",
      "                         'model__metric': ['minkowski'],\n",
      "                         'model__n_neighbors': [5],\n",
      "                         'model__weights': ['uniform']},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__algorithm': 'auto', 'model__metric': 'minkowski', 'model__n_neighbors': 5, 'model__weights': 'uniform'}\n",
      "\n",
      "Performance: NMAE (val): -3239984.25 | RMSE train: 3517654.379918169 | MAE train: 2493007.2164383563 | RMSE train: 4052918.045996807 | MAE test: 2932657.7260273974\n",
      "Execution time: 0.2155897617340088s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scale\", RobustScaler()),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_neighbors\": [5],\n",
    "    \"model__weights\": [\"uniform\"],\n",
    "    \"model__metric\": [\"minkowski\"],\n",
    "    \"model__algorithm\": [\"auto\"],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(\n",
    "        n_splits\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"KNN_pred\"] = model\n",
    "results[\"KNN_pred\"] = score\n",
    "times[\"KNN_pred\"] = total_time\n",
    "\n",
    "print_results(\"KNN PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1.2. KNN - Predefined parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2690780.41\n",
      "RMSE train: 3108869.52\tMAE train: 2162755.27\n",
      "RMSE test: 3817678.94\tMAE test: 2636704.85\n",
      "---------------------------------------------------\n",
      "KNN PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scale', RobustScaler()),\n",
      "                                       ('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', KNeighborsRegressor())]),\n",
      "             param_grid={'model__algorithm': ['auto'],\n",
      "                         'model__metric': ['minkowski'],\n",
      "                         'model__n_neighbors': [5],\n",
      "                         'model__weights': ['uniform'],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__algorithm': 'auto', 'model__metric': 'minkowski', 'model__n_neighbors': 5, 'model__weights': 'uniform', 'select__k': 6}\n",
      "\n",
      "Performance: NMAE (val): -2690780.4078947366 | RMSE train: 3108869.5243311627 | MAE train: 2162755.2657534247 | RMSE train: 3817678.9396583214 | MAE test: 2636704.8493150687\n",
      "Execution time: 9.636045217514038s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "# Using a pipeline to scale the data and then apply the model\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scale\", RobustScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_neighbors\": [5],\n",
    "    \"model__weights\": [\"uniform\"],\n",
    "    \"model__metric\": [\"minkowski\"],\n",
    "    \"model__algorithm\": [\"auto\"],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"KNN_pred_k\"] = model\n",
    "results[\"KNN_pred_k\"] = score\n",
    "times[\"KNN_pred_k\"] = total_time\n",
    "\n",
    "print_results(\"KNN PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the NMAE is normalized by the mean absolute error of the test set, it is expected to be different from the MAE calculated directly using the mean_absolute_error function. The NMAE is a way to evaluate the performance of a model in a cross-validation setting, while the MAE is a direct measure of the model's performance on the training set.\n",
    "\n",
    "Therefore, as we can not use the results of RMSE nor MAE in test, we will use the NMAE scoring given in validation to select the best model (as it is a fairly correct aproximation)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.1.2. KNN - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen during the EDA, we have a lot of outliers in the dataset, so we will use a Robust Scaler to scale the data, as it is more robust to outliers than the Standard Scaler or the MinMax Scaler."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the process of comparing the Selected parameters with the Predefined parameters, we will create two different models, one for each set of parameters, created one from another with the best parameters found in the previous step and a pipeline with the preprocessing steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2.1. KNN - Selected parameters - No attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, as explained in the introduction of the section, the main parameter is the number of neighbors considered. Additionally, we have decided to add other relevant parameters that should be chosen:\n",
    "\n",
    "- The metric: KNN is a model based on the distances of the data points, so the way we measure this distance affects the results.\n",
    "- The weights: We can decide whether we give the same importance to all neighbors or if the closest neighbors should have a greater impact on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2880131.56\n",
      "RMSE train: 0.00\tMAE train: 0.00\n",
      "RMSE test: 3565366.01\tMAE test: 2558754.34\n",
      "---------------------------------------------------\n",
      "KNN SELECTED PARAMETERS best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                             ('model', KNeighborsRegressor())]),\n",
      "                   n_iter=75,\n",
      "                   param_distributions={'model__algorithm': ['auto',\n",
      "                                                             'ball_tree',\n",
      "                                                             'kd_tree',\n",
      "                                                             'brute'],\n",
      "                                        'model__metric': ['euclidean',\n",
      "                                                          'manhattan',\n",
      "                                                          'minkowski',\n",
      "                                                          'chebyshev'],\n",
      "                                        'model__n_neighbors': [1, 3, 5, 7, 9,\n",
      "                                                               11, 13, 15, 17,\n",
      "                                                               19, 21, 23, 25,\n",
      "                                                               27, 29, 31, 33,\n",
      "                                                               35, 37, 39, 41,\n",
      "                                                               43, 45, 47, 49],\n",
      "                                        'model__weights': ['uniform',\n",
      "                                                           'distance']},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__weights': 'distance', 'model__n_neighbors': 17, 'model__metric': 'manhattan', 'model__algorithm': 'kd_tree'}\n",
      "\n",
      "Performance: NMAE (val): -2880131.5631625694 | RMSE train: 0.0 | MAE train: 0.0 | RMSE train: 3565366.01276105 | MAE test: 2558754.341563862\n",
      "Execution time: 21.66078281402588s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "budget = 75\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_neighbors\": list(range(1, 50, 2)),\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    \"model__metric\": [\"euclidean\", \"manhattan\", \"minkowski\", \"chebyshev\"],\n",
    "    \"model__algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "}\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(\n",
    "        n_splits\n",
    "    ),  # TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"KNN_select\"] = model\n",
    "results[\"KNN_select\"] = score\n",
    "times[\"KNN_select\"] = total_time\n",
    "\n",
    "print_results(\"KNN SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2.2. KNN - Selected parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2620137.86\n",
      "RMSE train: 0.00\tMAE train: 0.00\n",
      "RMSE test: 3573786.29\tMAE test: 2470235.34\n",
      "---------------------------------------------------\n",
      "KNN SELECTED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                       ('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', KNeighborsRegressor())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__algorithm': ['kd_tree'],\n",
      "                         'model__metric': ['minkowski'],\n",
      "                         'model__n_neighbors': [9],\n",
      "                         'model__weights': ['distance'],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__algorithm': 'kd_tree', 'model__metric': 'minkowski', 'model__n_neighbors': 9, 'model__weights': 'distance', 'select__k': 8}\n",
      "\n",
      "Performance: NMAE (val): -2620137.8590261317 | RMSE train: 0.0 | MAE train: 0.0 | RMSE train: 3573786.2885428783 | MAE test: 2470235.3428950827\n",
      "Execution time: 5.894104719161987s\n"
     ]
    }
   ],
   "source": [
    "# Now, we will use the previously calculated best model to add the selection of attributes through the SelectKBest function in the pipeline\n",
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Previous best model had as parameters: {'model__weights': 'distance', 'model__n_neighbors': 9, 'model__metric': 'manhattan'}\n",
    " \n",
    "param_grid = {\n",
    "    \"model__n_neighbors\": [9],\n",
    "    \"model__weights\": [\"distance\"],\n",
    "    \"model__metric\": [\"minkowski\"],\n",
    "    \"model__algorithm\": [\"kd_tree\"],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(\n",
    "        n_splits\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"KNN_select_k\"] = model\n",
    "results[\"KNN_select_k\"] = score\n",
    "times[\"KNN_select_k\"] = total_time\n",
    "\n",
    "print_results(\"KNN SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Regression Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees work by recursively partitioning the data into subsets based on the values of their features, creating a tree-like structure that maps each set of features to a predicted target value. Each node in the tree represents a feature, and each branch represents a decision rule based on the value of that feature. The goal is to split the data in a way that creates the most homogeneous subsets with respect to the target variable. Once the tree is constructed, it can be used to make predictions on new data by following the decision rules down the tree until a leaf node is reached, which contains the predicted target value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In trees (both regression trees and random forests), it is not necessary to scale the data, as the algorithm is not sensitive to the scale of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Regression Trees - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.1. Regression Trees - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -3467149.44\n",
      "RMSE train: 0.00\tMAE train: 0.00\n",
      "RMSE test: 4415298.67\tMAE test: 3096676.85\n",
      "Grid scores on development set:\n",
      "[-3467149.44078947] [354807.01638332]\n",
      "---------------------------------------------------\n",
      "REGRESSION TREES PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('model',\n",
      "                                        DecisionTreeRegressor(random_state=1))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__criterion': ['squared_error'],\n",
      "                         'model__max_depth': [None],\n",
      "                         'model__max_features': [None],\n",
      "                         'model__min_samples_split': [2]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2}\n",
      "\n",
      "Performance: NMAE (val): -3467149.4407894737 | RMSE train: 0.0 | MAE train: 0.0 | RMSE train: 4415298.670843619 | MAE test: 3096676.8493150687\n",
      "Execution time: 0.5558083057403564s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"model\", DecisionTreeRegressor(random_state=1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__criterion\": [\"squared_error\"],\n",
    "    \"model__max_depth\": [None],\n",
    "    \"model__min_samples_split\": [2],\n",
    "    \"model__max_features\": [None],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "# Print the different grid scores\n",
    "print(\"Grid scores on development set:\")\n",
    "print(model.cv_results_[\"mean_test_score\"], model.cv_results_[\"std_test_score\"])\n",
    "\n",
    "models[\"RegTrees_pred\"] = model\n",
    "results[\"RegTrees_pred\"] = score\n",
    "times[\"RegTrees_pred\"] = total_time\n",
    "\n",
    "print_results(\"REGRESSION TREES PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.2. Regression Trees - Predefined parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -3328832.17\n",
      "RMSE train: 0.00\tMAE train: 0.00\n",
      "RMSE test: 4436486.02\tMAE test: 3133033.15\n",
      "---------------------------------------------------\n",
      "REGRESSION TREES PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model',\n",
      "                                        DecisionTreeRegressor(random_state=1))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__criterion': ['squared_error'],\n",
      "                         'model__max_depth': [None],\n",
      "                         'model__max_features': [None],\n",
      "                         'model__min_samples_split': [2],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'select__k': 74}\n",
      "\n",
      "Performance: NMAE (val): -3328832.171052632 | RMSE train: 0.0 | MAE train: 0.0 | RMSE train: 4436486.024386344 | MAE test: 3133033.1506849313\n",
      "Execution time: 2.886359453201294s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('select', SelectKBest(f_regression)),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__criterion\": [\"squared_error\"],\n",
    "    \"model__max_depth\": [None],\n",
    "    \"model__min_samples_split\": [2],\n",
    "    \"model__max_features\": [None],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RegTrees_pred_k\"] = model\n",
    "results[\"RegTrees_pred_k\"] = score\n",
    "times[\"RegTrees_pred_k\"] = total_time\n",
    "\n",
    "print_results(\"REGRESSION TREES PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "As we can see, the default model is clearly overfitting, as indicated by the 0 error for the train section and a high error for the test section. This is likely due to the lack of control over the maximum depth of the tree, combined with a small minimum sample split that leaves only one sample in each leaf. This causes the model to memorize each data point, leading to poor generalization performance.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Regression Trees - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building upon the previous definition, we can reduce the most important parameters to be ajusted to the following:\n",
    "- max_features : controls the numberof features ( or attributes ) used in the tree. \n",
    "- min_samples-split : controls the minumum number of instances a leafe must have in order to be able to subdivide. This parameter can prevent the tree from overfitting. \n",
    "- max-depth : This parammeter also helps to prevent overfitting by stoping the tree from subdividing to much. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2.1. Regression Trees - Selected parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2743220.58\n",
      "RMSE train: 3259190.45\tMAE train: 2080612.60\n",
      "RMSE test: 3751318.58\tMAE test: 2517586.23\n",
      "---------------------------------------------------\n",
      "REGRESSION TREES SELECTED PARAMETERS best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('model',\n",
      "                                              DecisionTreeRegressor(random_state=1))]),\n",
      "                   n_iter=75, n_jobs=-1,\n",
      "                   param_distributions={'model__criterion': ['absolute_error',\n",
      "                                                             'squared_error'],\n",
      "                                        'model__max_depth': [5, 10, 15, 20, 25,\n",
      "                                                             30, 35, 40, 45, 50,\n",
      "                                                             55, 60],\n",
      "                                        'model__max_features': ['sqrt', 'log2',\n",
      "                                                                None],\n",
      "                                        'model__min_samples_split': [5, 6, 7, 8,\n",
      "                                                                     9, 10, 11,\n",
      "                                                                     12, 13, 14,\n",
      "                                                                     15, 16, 17,\n",
      "                                                                     18, 19, 20,\n",
      "                                                                     21, 22, 23,\n",
      "                                                                     24, 25, 26,\n",
      "                                                                     27, 28, 29,\n",
      "                                                                     30, 31, 32,\n",
      "                                                                     33, 34, ...]},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__min_samples_split': 106, 'model__max_features': None, 'model__max_depth': 30, 'model__criterion': 'absolute_error'}\n",
      "\n",
      "Performance: NMAE (val): -2743220.575657895 | RMSE train: 3259190.446254432 | MAE train: 2080612.602739726 | RMSE train: 3751318.579863181 | MAE test: 2517586.2328767125\n",
      "Execution time: 16.169135332107544s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "budget = 75\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"model\", DecisionTreeRegressor(random_state=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__criterion\": [\"absolute_error\", \"squared_error\"],\n",
    "    \"model__max_depth\": list(range(5, 61, 5)),\n",
    "    \"model__min_samples_split\": list(range(5, 200)),\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "\n",
    "# We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "model = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RegTrees_select\"] = model\n",
    "results[\"RegTrees_select\"] = score\n",
    "times[\"RegTrees_select\"] = total_time\n",
    "\n",
    "print_results(\"REGRESSION TREES SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2.2. Regression Trees - Selected parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2727416.15\n",
      "RMSE train: 3452866.62\tMAE train: 2199234.33\n",
      "RMSE test: 3788146.80\tMAE test: 2545067.88\n",
      "---------------------------------------------------\n",
      "REGRESSION TREES SELECTED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model',\n",
      "                                        DecisionTreeRegressor(random_state=1))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__criterion': ['absolute_error'],\n",
      "                         'model__max_depth': [30],\n",
      "                         'model__max_features': [None],\n",
      "                         'model__min_samples_split': [106],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__criterion': 'absolute_error', 'model__max_depth': 30, 'model__max_features': None, 'model__min_samples_split': 106, 'select__k': 11}\n",
      "\n",
      "Performance: NMAE (val): -2727416.151315789 | RMSE train: 3452866.617242818 | MAE train: 2199234.328767123 | RMSE train: 3788146.7966390885 | MAE test: 2545067.8767123288\n",
      "Execution time: 26.24833345413208s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Previous model Parameters: {'model__min_samples_split': 106, 'model__max_features': None, 'model__max_depth': 30, 'model__criterion': 'absolute_error'}\n",
    "\n",
    "param_grid = {\n",
    "    \"model__criterion\": [\"absolute_error\"],\n",
    "    \"model__max_depth\": [30],\n",
    "    \"model__min_samples_split\": [106],\n",
    "    \"model__max_features\": [None],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "# We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RegTrees_select_k\"] = model\n",
    "results[\"RegTrees_select_k\"] = score\n",
    "times[\"RegTrees_select_k\"] = total_time\n",
    "\n",
    "print_results(\"REGRESSION TREES SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Linnear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a supervised learning algorithm that models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. The goal is to find the best fit line that can predict the dependent variable given the independent variables.\n",
    "\n",
    "For the selected model we will be considering Lasso and Ridge.\n",
    "Lasso and Ridge regression are two popular regularization techniques used with linear regression. Lasso adds a penalty term to the regression equation that encourages the model to minimize the absolute value of the regression coefficients, which can lead to some coefficients being exactly zero. Ridge regression, on the other hand, adds a penalty term that encourages the model to minimize the square of the regression coefficients, which can help prevent overfitting. These techniques can improve the performance of the linear regression model by reducing the impact of irrelevant or highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Linear Regression - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.1. KNN - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2437056.06\n",
      "RMSE train: 3254352.60\tMAE train: 2321647.06\n",
      "RMSE test: 3103586.45\tMAE test: 2242422.37\n",
      "---------------------------------------------------\n",
      "LINEAR REGRESSION PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                       ('model', LinearRegression())]),\n",
      "             n_jobs=-1, param_grid={'model__fit_intercept': [True]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__fit_intercept': True}\n",
      "\n",
      "Performance: NMAE (val): -2437056.0592061607 | RMSE train: 3254352.603690468 | MAE train: 2321647.0597032406 | RMSE train: 3103586.4486739947 | MAE test: 2242422.367108231\n",
      "Execution time: 0.30195021629333496s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline([(\"scaler\", RobustScaler()), (\"model\", LinearRegression())])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__fit_intercept\": [True],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"LinearReg_pred\"] = model\n",
    "results[\"LinearReg_pred\"] = score\n",
    "times[\"LinearReg_pred\"] = total_time\n",
    "\n",
    "print_results(\"LINEAR REGRESSION PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.2. KNN - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2421796.65\n",
      "RMSE train: 3256574.00\tMAE train: 2323171.61\n",
      "RMSE test: 3107801.96\tMAE test: 2248616.81\n",
      "---------------------------------------------------\n",
      "LINEAR REGRESSION PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                       ('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', LinearRegression())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__fit_intercept': [True],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__fit_intercept': True, 'select__k': 72}\n",
      "\n",
      "Performance: NMAE (val): -2421796.652193799 | RMSE train: 3256573.9989301027 | MAE train: 2323171.6092511206 | RMSE train: 3107801.9576505884 | MAE test: 2248616.8067180943\n",
      "Execution time: 2.0286073684692383s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__fit_intercept\": [True],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"LinearReg_pred_k\"] = model\n",
    "results[\"LinearReg_pred_k\"] = score\n",
    "times[\"LinearReg_pred_k\"] = total_time\n",
    "\n",
    "print_results(\"LINEAR REGRESSION PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Linear Regression - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding upon the previous discussion, when using Lasso regression, we can focus on adjusting the following key parameters:\n",
    "\n",
    "- alpha: This parameter determines the amount of regularization applied to the model. A higher alpha results in stronger regularization, which can help to reduce overfitting.\n",
    "- k: This parameter determines the number of features selected by the Lasso model. By adjusting k, we can control the complexity of the model and potentially improve its performance.\n",
    "It's worth noting that these are just a few of the many parameters that can be adjusted when using Lasso regression. However, by focusing on these key parameters, we can gain a better understanding of how the model works and how to optimize its performance.\n",
    "\n",
    "\n",
    "\n",
    "We can reduce the most important parameters to be adjusted for Ridge regression to the following:\n",
    "\n",
    "- alpha: controls the strength of the regularization penalty applied to the coefficients. A high alpha value can lead to underfitting, while a low alpha value can lead to overfitting.\n",
    "- k: the number of top features selected by the SelectKBest function. This parameter determines the number of features to be used in the model and can have an impact on its performance.\n",
    "\n",
    "\n",
    "We can reduce the most important parameters for Elastic Net regression to be adjusted to the following:\n",
    "\n",
    "- alpha: controls the regularization strength of both L1 and L2 penalties. A high alpha will increase the regularization strength, while a low alpha will decrease it.\n",
    "- l1_ratio: controls the ratio between L1 and L2 penalties. A l1_ratio of 1 is equivalent to Lasso regression, while a ratio of 0 is equivalent to Ridge regression.\n",
    "- k: the number of features to be selected by the SelectKBest method. This parameter is part of the pipeline and helps to select the most relevant features for the model.\n",
    "Adjusting these parameters can help prevent overfitting and improve the performance of the Elastic Net regression model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.1. Linear Regression - Selected parameters - Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: -2916665.224197623\n",
      "{'model__alpha': 52025.49442372698}\n",
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2916665.22\n",
      "RMSE train: 3876831.69\tMAE train: 2906173.48\n",
      "RMSE test: 3737074.21\tMAE test: 2829956.26\n",
      "Model: -2396352.0117066414\n",
      "{'model__alpha': 0.9693631061142517}\n",
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2396352.01\n",
      "RMSE train: 3276534.92\tMAE train: 2333075.68\n",
      "RMSE test: 3103991.39\tMAE test: 2240841.40\n",
      "[1.7644586563110352, 1.6062359809875488]\n",
      "---------------------------------------------------\n",
      "LINEAR REGRESSION SELECTED PARAMETERS best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                             ('model',\n",
      "                                              Ridge(random_state=10))]),\n",
      "                   n_iter=75, n_jobs=-1,\n",
      "                   param_distributions={'model__alpha': array([ 0.01      ,  0.01097844,  0.01205261,  0.01323188,  0.01452654,\n",
      "        0.01594787,  0.01750827,  0.01922135,  0.02110203,  0.02316674,\n",
      "        0.025...\n",
      "        0.66730492,  0.73259654,  0.80427655,  0.88297   ,  0.96936311,\n",
      "        1.06420924,  1.16833549,  1.28264983,  1.40814912,  1.54592774,\n",
      "        1.69718713,  1.86324631,  2.04555335,  2.245698  ,  2.46542555,\n",
      "        2.70665207,  2.9714811 ,  3.26222201,  3.5814101 ,  3.93182876,\n",
      "        4.31653369,  4.73887961,  5.20254944,  5.71158648,  6.27042962,\n",
      "        6.88395207,  7.55750387,  8.29695852,  9.1087642 , 10.        ])},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__alpha': 0.9693631061142517}\n",
      "\n",
      "Performance: NMAE (val): -2421796.652193799 | RMSE train: 3256573.9989301027 | MAE train: 2323171.6092511206 | RMSE train: 3107801.9576505884 | MAE test: 2248616.8067180943\n",
      "Execution time: 1.6062359809875488s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "budget = 75\n",
    "n_splits = 5\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "# ! Pipelines\n",
    "pipeline_lasso = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"model\", Lasso(fit_intercept=True, tol=0.5, random_state=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_ridge = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"model\", Ridge(fit_intercept=True, random_state=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipeline_elastic = Pipeline(\n",
    "#     [\n",
    "#         (\"scaler\", RobustScaler()),\n",
    "#         (\"model\", ElasticNet(fit_intercept=True, tol=0.5, random_state=10)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ! Parameter grids\n",
    "param_grid_lasso = {\n",
    "    \"model__alpha\": np.logspace(-2, 5, 75), # Between 0.001 and 100000\n",
    "}\n",
    "\n",
    "param_grid_ridge = {\n",
    "    \"model__alpha\": np.logspace(-2, 1, 75), # Between 0.001 and 10\n",
    "}\n",
    "\n",
    "param_grid_elastic = {\n",
    "    \"model__alpha\": np.logspace(-2, 5, 75), # Between 0.001 and 10\n",
    "    \"model__l1_ratio\": np.linspace(0, 1, 75), # Between 0 and 1\n",
    "}\n",
    "\n",
    "# ! If we want to use random values for the parameters -> unconsistency in the results\n",
    "regr_lasso = RandomizedSearchCV(\n",
    "    pipeline_lasso,\n",
    "    param_grid_lasso,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "regr_ridge = RandomizedSearchCV(\n",
    "    pipeline_ridge,\n",
    "    param_grid_ridge,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# regr_elastic = RandomizedSearchCV(\n",
    "#     pipeline_elastic,\n",
    "#     param_grid_elastic,\n",
    "#     scoring=\"neg_mean_absolute_error\",\n",
    "#     cv=TimeSeriesSplit(),\n",
    "#     n_iter=budget,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "model = [regr_lasso, regr_ridge] #, regr_elastic]\n",
    "\n",
    "\n",
    "ln_reg_time, scoring = [], []\n",
    "\n",
    "for i in model:\n",
    "    start_time = time.time()\n",
    "    i.fit(X=X_train, y=y_train)\n",
    "    print(f\"Model: {i.best_score_}\")\n",
    "    print(i.best_params_)\n",
    "    # Now we reevaluate the model on the test set to obtain more accurate results\n",
    "    scoring.append(i.best_score_)\n",
    "    all_scores.append(\n",
    "        train_and_test(\n",
    "            i.best_estimator_, i.best_score_, X_train, y_train, X_test, y_test\n",
    "        )\n",
    "    )\n",
    "    ln_reg_time.append(time.time() - start_time)\n",
    "\n",
    "print(ln_reg_time)\n",
    "\n",
    "# Select the best model (based on the MAE)\n",
    "max_score = min(\n",
    "    all_scores, key=lambda x: abs(x[0])\n",
    ")  # Best model is the one that minimizes the validation NMAE\n",
    "best_model = model[all_scores.index(max_score)]\n",
    "total_time = ln_reg_time[all_scores.index(max_score)]\n",
    "\n",
    "models[\"LinearReg_select\"] = best_model\n",
    "results[\"LinearReg_select\"] = max_score\n",
    "times[\"LinearReg_select\"] = total_time\n",
    "\n",
    "# Print results\n",
    "print_results(\"LINEAR REGRESSION SELECTED PARAMETERS\", best_model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.2. Linear Regression - Selected parameters - Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2389586.49\n",
      "RMSE train: 3278341.47\tMAE train: 2333541.31\n",
      "RMSE test: 3108020.39\tMAE test: 2244967.22\n",
      "---------------------------------------------------\n",
      "LINEAR REGRESSION SELECTED PARAMETERS best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                             ('model',\n",
      "                                              Ridge(random_state=10))]),\n",
      "                   n_iter=75, n_jobs=-1,\n",
      "                   param_distributions={'model__alpha': array([ 0.01      ,  0.01097844,  0.01205261,  0.01323188,  0.01452654,\n",
      "        0.01594787,  0.01750827,  0.01922135,  0.02110203,  0.02316674,\n",
      "        0.025...\n",
      "        0.66730492,  0.73259654,  0.80427655,  0.88297   ,  0.96936311,\n",
      "        1.06420924,  1.16833549,  1.28264983,  1.40814912,  1.54592774,\n",
      "        1.69718713,  1.86324631,  2.04555335,  2.245698  ,  2.46542555,\n",
      "        2.70665207,  2.9714811 ,  3.26222201,  3.5814101 ,  3.93182876,\n",
      "        4.31653369,  4.73887961,  5.20254944,  5.71158648,  6.27042962,\n",
      "        6.88395207,  7.55750387,  8.29695852,  9.1087642 , 10.        ])},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__alpha': 0.9693631061142517}\n",
      "\n",
      "Performance: NMAE (val): -2389586.491181177 | RMSE train: 3278341.466529396 | MAE train: 2333541.305110323 | RMSE train: 3108020.390028838 | MAE test: 2244967.221944342\n",
      "Execution time: 1.8783280849456787s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "# We use Ridge as model as it is the best performing one\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", Ridge(fit_intercept=True, random_state=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Previous model Parameters: {'model__alpha': 0.9693631061142517}\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.9693631061142517],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "# We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"LinearReg_select_k\"] = model\n",
    "results[\"LinearReg_select_k\"] = score\n",
    "times[\"LinearReg_select_k\"] = total_time\n",
    "\n",
    "# Print results\n",
    "print_results(\"LINEAR REGRESSION SELECTED PARAMETERS\", best_model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be observed, the selected model, Ridge, does not delete any of the attributes (as expected, as it is one of its flaws), but some of their weights are close to zero, so we can consider that they are not relevant for the model.\n",
    "\n",
    "On the other hand, the Lasso model and the ElasticNet model, do delete some of the attributes, but the results are worse than the Ridge model, so we will not consider them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LinearReg_select_k with score (-NMAE) 2389586.491181177 and time 1.8783280849456787s\n",
      "Worst model: RegTrees_pred with score (-NMAE) 3467149.4407894737 and time 0.5558083057403564s\n",
      "Fastest model: KNN_pred with score (-NMAE) 3239984.25 and time 0.2155897617340088s\n",
      "Slowest model: RegTrees_select_k with score(-NMAE) 2727416.151315789 and time 26.24833345413208s\n",
      "\n",
      "Average models score: 2778536.9694322506\n",
      "Average models time: 7.423440059026082\n",
      "\n",
      "The score difference between the best and worst model is:  1077562.9496082966\n",
      "The score difference between the best and fastest model is:  5629570.741181177\n",
      "The time difference between the best and fastest model model is:  1.66273832321167\n",
      "The time difference between the fastest and slowest model is:  26.03274369239807\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# ! Obtain best, worst, fastest and slowest model\n",
    "max_score = max(results.values(), key=lambda x: abs(x[0]))  # We use the scoring (NMAE) as explained above to select the best model\n",
    "min_score = min(results.values(), key=lambda x: abs(x[0]))\n",
    "# Obtain the key name of the best and worst model\n",
    "max_time = max(times.values(), key=lambda x: x)\n",
    "min_time = min(times.values(), key=lambda x: x)\n",
    "\n",
    "best_model = list(results.keys())[list(results.values()).index(min_score)]\n",
    "worst_model = list(results.keys())[list(results.values()).index(max_score)]\n",
    "fastest_model = list(times.keys())[list(times.values()).index(min_time)]\n",
    "slowest_model = list(times.keys())[list(times.values()).index(max_time)]\n",
    "\n",
    "print(f\"Best model: {best_model} with score (-NMAE) {abs(min_score[0])} and time {list(times.values())[list(results.values()).index(min_score)]}s\")\n",
    "print(f\"Worst model: {worst_model} with score (-NMAE) {abs(max_score[0])} and time {list(times.values())[list(results.values()).index(max_score)]}s\")\n",
    "print(f\"Fastest model: {fastest_model} with score (-NMAE) {abs(results[fastest_model][0])} and time {min_time}s\")\n",
    "print(f\"Slowest model: {slowest_model} with score(-NMAE) {abs(results[slowest_model][0])} and time {max_time}s\")\n",
    "\n",
    "\n",
    "# ! Average (test MAE) score of the models\n",
    "avg_score = 0\n",
    "avg_time = 0\n",
    "\n",
    "for key, value in results.items():\n",
    "    avg_score += results[key][0]\n",
    "    avg_time += times[key]\n",
    "\n",
    "print(f\"\\nAverage models score: {abs(avg_score/len(results))}\")\n",
    "print(f\"Average models time: {avg_time/len(times)}\\n\")\n",
    "\n",
    "\n",
    "# ! Differences\n",
    "print(\"The score difference between the best and worst model is: \", abs(max_score[0] - min_score)[0])  # Scoring evaluation -NMAE\n",
    "print(\"The score difference between the best and fastest model is: \", abs(min_score[0] - abs(results[fastest_model][0])))  # Scoring evaluation -NMAE\n",
    "print(\"The time difference between the best and fastest model model is: \", abs(list(times.values())[list(results.values()).index(min_score)] - min_time))\n",
    "print(\"The time difference between the fastest and slowest model is: \", abs(max_time - min_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SCORES (NMAE in evaluation)\n",
      "0. KNN_pred: 3239984.25\n",
      "1. KNN_pred_k: 2690780.4078947366\n",
      "2. KNN_select: 2880131.5631625694\n",
      "3. KNN_select_k: 2620137.8590261317\n",
      "4. RegTrees_pred: 3467149.4407894737\n",
      "5. RegTrees_pred_k: 3328832.171052632\n",
      "6. RegTrees_select: 2743220.575657895\n",
      "7. RegTrees_select_k: 2727416.151315789\n",
      "8. LinearReg_pred: 2437056.0592061607\n",
      "9. LinearReg_pred_k: 2421796.652193799\n",
      "10. LinearReg_select: 2396352.0117066414\n",
      "11. LinearReg_select_k: 2389586.491181177\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TIMES (s)\n",
      "0. KNN_pred: 0.2155897617340088\n",
      "2. KNN_select: 21.66078281402588\n",
      "4. RegTrees_pred: 0.5558083057403564\n",
      "6. RegTrees_select: 16.169135332107544\n",
      "8. LinearReg_pred: 0.30195021629333496\n",
      "10. LinearReg_select: 1.6062359809875488\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ATTRIBUTE SELECTION TIMES (s)\n",
      "1. KNN_pred_k: 9.636045217514038\n",
      "3. KNN_select_k: 5.894104719161987\n",
      "5. RegTrees_pred_k: 2.886359453201294\n",
      "7. RegTrees_select_k: 26.24833345413208\n",
      "9. LinearReg_pred_k: 2.0286073684692383\n",
      "11. LinearReg_select_k: 1.8783280849456787\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the results up to now\n",
    "# ! Plot the score\n",
    "print(\"MODEL SCORES (NMAE in evaluation)\")\n",
    "iter = 0\n",
    "for key, value in results.items():\n",
    "    plt.bar(iter, abs(value[0]))\n",
    "    print(f\"{iter}. {key}: {abs(value[0])}\")\n",
    "    iter += 1\n",
    "plt.title(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/basic_methods_score.png\")\n",
    "plt.show()\n",
    "\n",
    "# ! Plot the time (just the even ones == the ones that are not selectors of attributes)\n",
    "print(\"MODEL TIMES (s)\")\n",
    "iter = 0\n",
    "for key, value in times.items():\n",
    "    if iter % 2 == 0:\n",
    "        plt.bar(iter, value)\n",
    "        print(f\"{iter}. {key}: {value}\")\n",
    "    iter += 1\n",
    "plt.title(\"Time\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/basic_methods_time.png\")\n",
    "plt.show()\n",
    "\n",
    "# ! Plot the time (just the odd ones == the selectors of attributes)\n",
    "print(\"MODEL ATTRIBUTE SELECTION TIMES (s)\")\n",
    "iter = 0\n",
    "for key, value in times.items():\n",
    "    if iter % 2 != 0:\n",
    "        plt.bar(iter, value)\n",
    "        print(f\"{iter}. {key}: {value}\")\n",
    "    iter += 1\n",
    "plt.title(\"Time to select attributes\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder - easier to visualize the annotations, better resolution\n",
    "plt.savefig(\"../data/img/basic_methods_time_atb.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Conclusions: \n",
    "\n",
    "After computig the models we can see that the best model in terms of MAE is the LinearReg_selected, but the best timing model is LinearReg_pred.\n",
    "\n",
    "***Obtener algunas conclusiones, tales como: ¿cuál es el mejor método? ¿Cuál de los métodos \n",
    "básicos de aprendizaje automático es más rápido? ¿Los resultados son mejores que los \n",
    "regresores triviales/naive/baseline? ¿El ajuste de hiperparámetros mejora con respecto a los \n",
    "valores por omisión? ¿Hay algún equilibrio entre tiempo de ejecución y mejora de \n",
    "resultados? Etc***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Reducing Dimensionality TODO\n",
    ">¿Es posible reducir la dimensionalidad del problema?\n",
    "\n",
    "Yes, it is possible to reduce the problem dimensionality, and as stated throughout the EDA, there are a lot of attributes that are highly correlated, so we can reduce the dimensionality of the problem by removing some of the attributes. Thus, it is recommended to use a PCA to reduce the dimensionality of the problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the EDA section, there are several attributes that are closely related to the point of being redundant. Our hypothesis is that dropping these features would not significantly affect the overall results. Additionally, we have implemented an additional step to detect and eliminate different attributes based on the model. We have done this by using the \"SelectKBest\" feature selector, which only considers the relationship between the attributes and the output variable. The tests designed to check the hypothesis will only contain the selected features from the SelectKBest step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Advanced methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be consistent, although we have already seen that usign the selection of attributes makes the model better, we will continue to use the two-step method we have been doing. This way, we can also verify that the results are better than the ones obtained with the basic methods (for both with and without attribute selection)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Support Vector Machines (SVMs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) is a supervised learning algorithm used for classification and regression analysis. SVM works by finding the hyperplane that best separates the data into different classes. The hyperplane is chosen such that it maximizes the margin between the closest data points from each class, known as support vectors. SVM can also use kernel functions to transform the input data into a higher dimensional space, allowing the separation of non-linearly separable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. SVMs - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.1. SVMs - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -6953343.12\n",
      "RMSE train: 8058525.28\tMAE train: 6899170.65\n",
      "RMSE test: 7478465.50\tMAE test: 6281604.09\n",
      "---------------------------------------------------\n",
      "SVM PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                       ('model', SVR())]),\n",
      "             param_grid={'model__epsilon': [0.1], 'model__gamma': ['scale'],\n",
      "                         'model__kernel': ['rbf']},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "\n",
      "Performance: NMAE (val): -6953343.117286754 | RMSE train: 8058525.276321875 | MAE train: 6899170.647284467 | RMSE train: 7478465.501368871 | MAE test: 6281604.088961575\n",
      "Execution time: 2.069565773010254s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('scaler', RobustScaler()),\n",
    "        (\"model\", SVR())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__kernel\": [\"rbf\"],\n",
    "    \"model__C\": [1.0],\n",
    "    \"model__gamma\": [\"scale\"],\n",
    "    \"model__epsilon\": [0.1],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"SVM_pred\"] = model\n",
    "results[\"SVM_pred\"] = score\n",
    "times[\"SVM_pred\"] = total_time\n",
    "\n",
    "print_results(\"SVM PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.2. SVMs - Predefined parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -6952999.55\n",
      "RMSE train: 8057851.47\tMAE train: 6898491.59\n",
      "RMSE test: 7477858.61\tMAE test: 6280965.57\n",
      "---------------------------------------------------\n",
      "SVM PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                                       ('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', SVR())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__C': [1.0], 'model__epsilon': [0.1],\n",
      "                         'model__gamma': ['scale'], 'model__kernel': ['rbf'],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__C': 1.0, 'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'rbf', 'select__k': 2}\n",
      "\n",
      "Performance: NMAE (val): -6952999.553407727 | RMSE train: 8057851.465218631 | MAE train: 6898491.591050504 | RMSE train: 7477858.611258205 | MAE test: 6280965.566937376\n",
      "Execution time: 29.70225501060486s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", SVR()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__kernel\": [\"rbf\"],\n",
    "    \"model__C\": [1.0],\n",
    "    \"model__gamma\": [\"scale\"],\n",
    "    \"model__epsilon\": [0.1],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"SVM_pred_k\"] = model\n",
    "results[\"SVM_pred_k\"] = score\n",
    "times[\"SVM_pred_k\"] = total_time\n",
    "\n",
    "print_results(\"SVM PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. SVMs - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building upon the previous definition, we can reduce the most important parameters to be adjusted to the following for SVM:\n",
    "\n",
    "- Kernel: This parameter defines the type of kernel used to transform the input data into a higher-dimensional space in order to perform classification. The most commonly used kernels are linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "- C: This parameter determines the trade-off between maximizing the margin and minimizing the classification error. A smaller value of C creates a larger margin but may misclassify some data points, while a larger value of C may lead to overfitting.\n",
    "- Gamma: This parameter defines the influence of each training example on the decision boundary. A smaller value of gamma makes the decision boundary smoother, while a larger value of gamma makes it more complex and can lead to overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2.1. SVMs - Selected parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2331773.95\n",
      "RMSE train: 3384381.68\tMAE train: 2251590.34\n",
      "RMSE test: 3314781.26\tMAE test: 2272204.42\n",
      "---------------------------------------------------\n",
      "SVM SELECTED PARAMETERS best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                             ('model', SVR())]),\n",
      "                   n_iter=15, n_jobs=-1,\n",
      "                   param_distributions={'model__C': [100000, 1000000, 5000000],\n",
      "                                        'model__gamma': ['scale', 'auto'],\n",
      "                                        'model__kernel': ['linear', 'poly',\n",
      "                                                          'rbf', 'sigmoid']},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__kernel': 'linear', 'model__gamma': 'auto', 'model__C': 1000000}\n",
      "\n",
      "Performance: NMAE (val): -2331773.9543751357 | RMSE train: 3384381.6752997166 | MAE train: 2251590.3404441564 | RMSE train: 3314781.2564529474 | MAE test: 2272204.415296306\n",
      "Execution time: 36.98407244682312s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "budget = 15\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # We scale the data to avoid overfitting - Recommended for SVMs\n",
    "        (\"model\", SVR())\n",
    "        # Support Vector Regression (SVR for regression, SVC for classification)\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"model__C\": [100000, 500000, 1000000, 5000000],\n",
    "    \"model__gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "# We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "model = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"SVM_select\"] = model\n",
    "results[\"SVM_select\"] = score\n",
    "times[\"SVM_select\"] = total_time\n",
    "\n",
    "print_results(\"SVM SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2331773.95\n",
      "RMSE train: 3384381.68\tMAE train: 2251590.34\n",
      "RMSE test: 3314781.26\tMAE test: 2272204.42\n",
      "---------------------------------------------------\n",
      "SVM SELECTED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', SVR())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__C': [1000000], 'model__gamma': ['auto'],\n",
      "                         'model__kernel': ['linear'],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__C': 1000000, 'model__gamma': 'auto', 'model__kernel': 'linear', 'select__k': 75}\n",
      "\n",
      "Performance: NMAE (val): -2331773.9543751357 | RMSE train: 3384381.6752997166 | MAE train: 2251590.3404441564 | RMSE train: 3314781.2564529474 | MAE test: 2272204.415296306\n",
      "Execution time: 36.91520929336548s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "# We use Ridge as model as it is the best performing one\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"select\", SelectKBest(f_regression)),\n",
    "        (\"model\", SVR())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Previous model Parameters: {'model__kernel': 'linear', 'model__gamma': 'auto', 'model__C': 1000000}\n",
    "\n",
    "param_grid = {\n",
    "    \"model__kernel\": [\"linear\"],\n",
    "    \"model__C\": [1000000],\n",
    "    \"model__gamma\": [\"auto\"],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "# We use TimeSeriesSplit to split the data in folds without losing the temporal order\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"SVM_select_k\"] = model\n",
    "results[\"SVM_select_k\"] = score\n",
    "times[\"SVM_select_k\"] = total_time\n",
    "\n",
    "print_results(\"SVM SELECTED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Random Forests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class or mean prediction of the individual trees. Random forests improve on the decision tree model by reducing overfitting and increasing accuracy. This is achieved by generating multiple decision trees and then aggregating their predictions through a voting system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Random Forests - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1.1. Random Forests - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2447807.29\n",
      "RMSE train: 1249861.81\tMAE train: 866788.80\n",
      "RMSE test: 3157684.68\tMAE test: 2212594.97\n",
      "---------------------------------------------------\n",
      "RANDOM FOREST PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('model', RandomForestRegressor())]),\n",
      "             param_grid={'model__criterion': ['squared_error'],\n",
      "                         'model__max_depth': [None],\n",
      "                         'model__max_features': [None],\n",
      "                         'model__min_samples_split': [2],\n",
      "                         'model__n_estimators': [100]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "\n",
      "Performance: NMAE (val): -2447807.2894736845 | RMSE train: 1249861.8142356414 | MAE train: 866788.7991780821 | RMSE train: 3157684.6842388203 | MAE test: 2212594.97260274\n",
      "Execution time: 39.911582946777344s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline([(\"model\", RandomForestRegressor(random_state=10))])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100],\n",
    "    \"model__criterion\": [\"squared_error\"],\n",
    "    \"model__max_depth\": [None],\n",
    "    \"model__min_samples_split\": [2],\n",
    "    \"model__max_features\": [None],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RandForest_pred\"] = model\n",
    "results[\"RandForest_pred\"] = score\n",
    "times[\"RandForest_pred\"] = total_time\n",
    "\n",
    "print_results(\"RANDOM FOREST PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1.2. Random Forests - Predefined parameters - Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2436340.53\n",
      "RMSE train: 1230647.08\tMAE train: 859275.53\n",
      "RMSE test: 3167880.67\tMAE test: 2219648.30\n",
      "---------------------------------------------------\n",
      "RANDOM FOREST PREDEFINED PARAMETERS best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model', RandomForestRegressor())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__criterion': ['squared_error'],\n",
      "                         'model__max_depth': [None],\n",
      "                         'model__max_features': [None],\n",
      "                         'model__min_samples_split': [2],\n",
      "                         'model__n_estimators': [100],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'select__k': 75}\n",
      "\n",
      "Performance: NMAE (val): -2436340.5286184214 | RMSE train: 1230647.077689153 | MAE train: 859275.5293150685 | RMSE train: 3167880.67115327 | MAE test: 2219648.301369863\n",
      "Execution time: 150.3789565563202s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [(\"select\", SelectKBest(f_regression)), (\"model\", RandomForestRegressor(random_state=10))]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100],\n",
    "    \"model__criterion\": [\"squared_error\"],\n",
    "    \"model__max_depth\": [None],\n",
    "    \"model__min_samples_split\": [2],\n",
    "    \"model__max_features\": [None],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RandForest_pred_k\"] = model\n",
    "results[\"RandForest_pred_k\"] = score\n",
    "times[\"RandForest_pred_k\"] = total_time\n",
    "\n",
    "print_results(\"RANDOM FOREST PREDEFINED PARAMETERS\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2. Random Forests - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building upon the previous definition, we can reduce the most important parameters to be adjusted to the following:\n",
    "\n",
    "- n_estimators: controls the number of trees in the forest.\n",
    "- max_depth: controls the maximum depth of each tree in the forest.\n",
    "- min_samples_split: controls the minimum number of instances a leaf must have in order to be able to subdivide. This parameter can prevent the tree from overfitting.\n",
    "- min_samples_leaf: controls the minimum number of instances required to be at a leaf node. Like min_samples_split, this parameter can also help prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2382299.52\n",
      "RMSE train: 1425045.62\tMAE train: 980722.47\n",
      "RMSE test: 3052803.13\tMAE test: 2107542.02\n",
      "---------------------------------------------------\n",
      "Random Forest best model is:\n",
      "\n",
      "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "                   estimator=Pipeline(steps=[('model',\n",
      "                                              RandomForestRegressor(random_state=10))]),\n",
      "                   n_iter=75, n_jobs=-1,\n",
      "                   param_distributions={'model__max_depth': [5, 10, 15, 20, 25,\n",
      "                                                             30, 35],\n",
      "                                        'model__max_features': ['sqrt', 'log2'],\n",
      "                                        'model__min_samples_split': [2, 3, 5, 7,\n",
      "                                                                     10],\n",
      "                                        'model__n_estimators': [100, 300, 800,\n",
      "                                                                900]},\n",
      "                   scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__n_estimators': 900, 'model__min_samples_split': 5, 'model__max_features': 'sqrt', 'model__max_depth': 25}\n",
      "\n",
      "Performance: NMAE (val): -2382299.5231620534 | RMSE train: 1425045.6232300766 | MAE train: 980722.4699717613 | RMSE train: 3052803.132746112 | MAE test: 2107542.020872962\n",
      "Execution time: 157.48544430732727s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "budget = 75\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"model\", RandomForestRegressor(random_state=10))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100, 300, 800, 900],\n",
    "    \"model__max_depth\": list(range(5, 36, 5)),\n",
    "    \"model__min_samples_split\": [2, 3, 5, 7, 10],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RandForest_select\"] = model\n",
    "results[\"RandForest_select\"] = score\n",
    "times[\"RandForest_select\"] = total_time\n",
    "\n",
    "print_results(\"Random Forest\", model, score, total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the best estimator of Pipeline\n",
      "NMAE in validation: -2388704.04\n",
      "RMSE train: 1779325.48\tMAE train: 1287528.38\n",
      "RMSE test: 3046110.91\tMAE test: 2100753.02\n",
      "---------------------------------------------------\n",
      "Random Forest best model is:\n",
      "\n",
      "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
      "             estimator=Pipeline(steps=[('select',\n",
      "                                        SelectKBest(score_func=<function f_regression at 0x7fbf8629ab90>)),\n",
      "                                       ('model',\n",
      "                                        RandomForestRegressor(random_state=10))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'model__max_depth': [11],\n",
      "                         'model__max_features': ['sqrt'],\n",
      "                         'model__min_samples_split': [5],\n",
      "                         'model__n_estimators': [200],\n",
      "                         'select__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                       23, 24, 25, 26, 27, 28, 29, 30, ...]},\n",
      "             scoring='neg_mean_absolute_error')\n",
      "\n",
      "Parameters: {'model__max_depth': 11, 'model__max_features': 'sqrt', 'model__min_samples_split': 5, 'model__n_estimators': 200, 'select__k': 75}\n",
      "\n",
      "Performance: NMAE (val): -2388704.0372038735 | RMSE train: 1779325.482904614 | MAE train: 1287528.379922953 | RMSE train: 3046110.9140748647 | MAE test: 2100753.0185126793\n",
      "Execution time: 44.384307622909546s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [(\"select\", SelectKBest(f_regression)), (\"model\", RandomForestRegressor(random_state=10))]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [200],\n",
    "    \"model__max_depth\": [11],\n",
    "    \"model__min_samples_split\": [5],\n",
    "    \"model__max_features\": [\"sqrt\"],\n",
    "    \"select__k\": list(range(1, X_train.shape[1] + 1)),\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "models[\"RandForest_select_k\"] = model\n",
    "results[\"RandForest_select_k\"] = score\n",
    "times[\"RandForest_select_k\"] = total_time\n",
    "\n",
    "print_results(\"Random Forest\", model, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Best model\n",
    "We will re-visit all the models and select the best one, which we have stated to be the one with the lowest MAE and the lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0. Sected model: KNN_pred\n",
      "\n",
      "Parameters: {'model__algorithm': 'auto', 'model__metric': 'minkowski', 'model__n_neighbors': 5, 'model__weights': 'uniform'}\n",
      "Score NMAE in train-validation: -3239984.25\n",
      "Score MAE (train): 2493007.2164383563 | Score RMSE (train): 3517654.379918169\n",
      "Score MAE (test): 2932657.7260273974 | Score RMSE (test): 4052918.045996807\n",
      "Time: 0.2155897617340088\n",
      "\n",
      "\n",
      "1. Sected model: KNN_pred_k\n",
      "\n",
      "Parameters: {'model__algorithm': 'auto', 'model__metric': 'minkowski', 'model__n_neighbors': 5, 'model__weights': 'uniform', 'select__k': 6}\n",
      "Score NMAE in train-validation: -2690780.4078947366\n",
      "Score MAE (train): 2162755.2657534247 | Score RMSE (train): 3108869.5243311627\n",
      "Score MAE (test): 2636704.8493150687 | Score RMSE (test): 3817678.9396583214\n",
      "Time: 9.636045217514038\n",
      "\n",
      "\n",
      "2. Sected model: KNN_select\n",
      "\n",
      "Parameters: {'model__weights': 'distance', 'model__n_neighbors': 17, 'model__metric': 'manhattan', 'model__algorithm': 'kd_tree'}\n",
      "Score NMAE in train-validation: -2880131.5631625694\n",
      "Score MAE (train): 0.0 | Score RMSE (train): 0.0\n",
      "Score MAE (test): 2558754.341563862 | Score RMSE (test): 3565366.01276105\n",
      "Time: 21.66078281402588\n",
      "\n",
      "\n",
      "3. Sected model: KNN_select_k\n",
      "\n",
      "Parameters: {'model__algorithm': 'kd_tree', 'model__metric': 'minkowski', 'model__n_neighbors': 9, 'model__weights': 'distance', 'select__k': 8}\n",
      "Score NMAE in train-validation: -2620137.8590261317\n",
      "Score MAE (train): 0.0 | Score RMSE (train): 0.0\n",
      "Score MAE (test): 2470235.3428950827 | Score RMSE (test): 3573786.2885428783\n",
      "Time: 5.894104719161987\n",
      "\n",
      "\n",
      "4. Sected model: RegTrees_pred\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2}\n",
      "Score NMAE in train-validation: -3467149.4407894737\n",
      "Score MAE (train): 0.0 | Score RMSE (train): 0.0\n",
      "Score MAE (test): 3096676.8493150687 | Score RMSE (test): 4415298.670843619\n",
      "Time: 0.5558083057403564\n",
      "\n",
      "\n",
      "5. Sected model: RegTrees_pred_k\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'select__k': 74}\n",
      "Score NMAE in train-validation: -3328832.171052632\n",
      "Score MAE (train): 0.0 | Score RMSE (train): 0.0\n",
      "Score MAE (test): 3133033.1506849313 | Score RMSE (test): 4436486.024386344\n",
      "Time: 2.886359453201294\n",
      "\n",
      "\n",
      "6. Sected model: RegTrees_select\n",
      "\n",
      "Parameters: {'model__min_samples_split': 106, 'model__max_features': None, 'model__max_depth': 30, 'model__criterion': 'absolute_error'}\n",
      "Score NMAE in train-validation: -2743220.575657895\n",
      "Score MAE (train): 2080612.602739726 | Score RMSE (train): 3259190.446254432\n",
      "Score MAE (test): 2517586.2328767125 | Score RMSE (test): 3751318.579863181\n",
      "Time: 16.169135332107544\n",
      "\n",
      "\n",
      "7. Sected model: RegTrees_select_k\n",
      "\n",
      "Parameters: {'model__criterion': 'absolute_error', 'model__max_depth': 30, 'model__max_features': None, 'model__min_samples_split': 106, 'select__k': 11}\n",
      "Score NMAE in train-validation: -2727416.151315789\n",
      "Score MAE (train): 2199234.328767123 | Score RMSE (train): 3452866.617242818\n",
      "Score MAE (test): 2545067.8767123288 | Score RMSE (test): 3788146.7966390885\n",
      "Time: 26.24833345413208\n",
      "\n",
      "\n",
      "8. Sected model: LinearReg_pred\n",
      "\n",
      "Parameters: {'model__fit_intercept': True}\n",
      "Score NMAE in train-validation: -2437056.0592061607\n",
      "Score MAE (train): 2321647.0597032406 | Score RMSE (train): 3254352.603690468\n",
      "Score MAE (test): 2242422.367108231 | Score RMSE (test): 3103586.4486739947\n",
      "Time: 0.30195021629333496\n",
      "\n",
      "\n",
      "9. Sected model: LinearReg_pred_k\n",
      "\n",
      "Parameters: {'model__fit_intercept': True, 'select__k': 72}\n",
      "Score NMAE in train-validation: -2421796.652193799\n",
      "Score MAE (train): 2323171.6092511206 | Score RMSE (train): 3256573.9989301027\n",
      "Score MAE (test): 2248616.8067180943 | Score RMSE (test): 3107801.9576505884\n",
      "Time: 2.0286073684692383\n",
      "\n",
      "\n",
      "10. Sected model: LinearReg_select\n",
      "\n",
      "Parameters: {'model__alpha': 0.9693631061142517}\n",
      "Score NMAE in train-validation: -2396352.0117066414\n",
      "Score MAE (train): 2333075.6766354376 | Score RMSE (train): 3276534.918917554\n",
      "Score MAE (test): 2240841.395277726 | Score RMSE (test): 3103991.394817176\n",
      "Time: 1.6062359809875488\n",
      "\n",
      "\n",
      "11. Sected model: LinearReg_select_k\n",
      "\n",
      "Parameters: {'model__alpha': 0.9693631061142517, 'select__k': 72}\n",
      "Score NMAE in train-validation: -2389586.491181177\n",
      "Score MAE (train): 2333541.305110323 | Score RMSE (train): 3278341.466529396\n",
      "Score MAE (test): 2244967.221944342 | Score RMSE (test): 3108020.390028838\n",
      "Time: 1.8783280849456787\n",
      "\n",
      "\n",
      "12. Sected model: SVM_pred\n",
      "\n",
      "Parameters: {'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "Score NMAE in train-validation: -6953343.117286754\n",
      "Score MAE (train): 6899170.647284467 | Score RMSE (train): 8058525.276321875\n",
      "Score MAE (test): 6281604.088961575 | Score RMSE (test): 7478465.501368871\n",
      "Time: 2.069565773010254\n",
      "\n",
      "\n",
      "13. Sected model: SVM_pred_k\n",
      "\n",
      "Parameters: {'model__C': 1.0, 'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'rbf', 'select__k': 2}\n",
      "Score NMAE in train-validation: -6952999.553407727\n",
      "Score MAE (train): 6898491.591050504 | Score RMSE (train): 8057851.465218631\n",
      "Score MAE (test): 6280965.566937376 | Score RMSE (test): 7477858.611258205\n",
      "Time: 29.70225501060486\n",
      "\n",
      "\n",
      "14. Sected model: SVM_select\n",
      "\n",
      "Parameters: {'model__kernel': 'linear', 'model__gamma': 'auto', 'model__C': 1000000}\n",
      "Score NMAE in train-validation: -2331773.9543751357\n",
      "Score MAE (train): 2251590.3404441564 | Score RMSE (train): 3384381.6752997166\n",
      "Score MAE (test): 2272204.415296306 | Score RMSE (test): 3314781.2564529474\n",
      "Time: 36.98407244682312\n",
      "\n",
      "\n",
      "15. Sected model: SVM_select_k\n",
      "\n",
      "Parameters: {'model__C': 1000000, 'model__gamma': 'auto', 'model__kernel': 'linear', 'select__k': 75}\n",
      "Score NMAE in train-validation: -2331773.9543751357\n",
      "Score MAE (train): 2251590.3404441564 | Score RMSE (train): 3384381.6752997166\n",
      "Score MAE (test): 2272204.415296306 | Score RMSE (test): 3314781.2564529474\n",
      "Time: 36.91520929336548\n",
      "\n",
      "\n",
      "16. Sected model: RandForest_pred\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Score NMAE in train-validation: -2447807.2894736845\n",
      "Score MAE (train): 866788.7991780821 | Score RMSE (train): 1249861.8142356414\n",
      "Score MAE (test): 2212594.97260274 | Score RMSE (test): 3157684.6842388203\n",
      "Time: 39.911582946777344\n",
      "\n",
      "\n",
      "17. Sected model: RandForest_pred_k\n",
      "\n",
      "Parameters: {'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'select__k': 75}\n",
      "Score NMAE in train-validation: -2436340.5286184214\n",
      "Score MAE (train): 859275.5293150685 | Score RMSE (train): 1230647.077689153\n",
      "Score MAE (test): 2219648.301369863 | Score RMSE (test): 3167880.67115327\n",
      "Time: 150.3789565563202\n",
      "\n",
      "\n",
      "18. Sected model: RandForest_select\n",
      "\n",
      "Parameters: {'model__n_estimators': 200, 'model__min_samples_split': 5, 'model__max_features': 'sqrt', 'model__max_depth': 11}\n",
      "Score NMAE in train-validation: -2388704.0372038735\n",
      "Score MAE (train): 1287528.379922953 | Score RMSE (train): 1779325.482904614\n",
      "Score MAE (test): 2100753.0185126793 | Score RMSE (test): 3046110.9140748647\n",
      "Time: 10.94435429573059\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAHWCAYAAAAciQ/OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUT0lEQVR4nO3deXQUZfr28avT6SV7yEpCQgKEnbAjhEX2VREUcVQEBFRAFMFRERUQdQR1FHHDBWVxg/mNy7gN7uDuOCjKKCKCCCiOKwQQAyT3+wdv16QhaKKBpvT7OafPSaq7n+fu6qrqq6ueqvaYmQkAAACuFBXpAgAAAPDrEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAHNXefvttnXjiiapdu7YCgYAyMzNVVFSkP//5z5EuDQCOCh5+zgvA0erpp5/WCSecoG7duunss89WVlaWtm7dqn//+99asmSJtmzZEukSASDiCHMAjlpdu3bVF198oY8//ljR0dFh95WVlSkq6sgcXPjxxx8VGxt7RPoCgKriMCuAo9Z3332ntLS0g4KcpIOC3EMPPaSioiLFx8crPj5eLVu21L333hv2mPvuu08tWrRQMBhUSkqKTjzxRK1ZsybsMWeeeabi4+O1evVq9enTRwkJCerZs6ckac+ePbrmmmvUqFEjBQIBpaena9SoUfrmm2+q+ZUDQOUR5gActYqKivT2229r4sSJevvtt7V3794KHzd9+nQNGzZM2dnZWrhwoR577DGNHDlSn3/+ufOYWbNmacyYMWratKkeffRRzZ07Vx988IGKioq0bt26sPb27NmjE044QT169NA//vEPzZw5U2VlZRo0aJBmz56t008/XU8//bRmz56t559/Xt26ddPu3bsP67wAgEMyADhKffvtt9a5c2eTZJLM5/NZx44dbdasWbZjxw4zM9uwYYN5vV4bNmzYIdv54YcfLCYmxgYMGBA2fdOmTRYIBOz00093po0cOdIk2X333Rf22Icfftgk2SOPPBI2/Z133jFJdscdd/zWlwsAv8rvZs/cK6+8ooEDByo7O1sej0ePP/54ldswM/31r39VgwYNFAgElJubq2uvvbb6iwVQKampqXr11Vf1zjvvaPbs2Ro0aJA++eQTTZ06VYWFhfr222/1/PPPq7S0VBMmTDhkO2+++aZ2796tM888M2x6bm6uevTooRdffPGg5wwZMiTs/6eeekrJyckaOHCg9u3b59xatmypmjVravny5dXxkgGgyg4eiOJSu3btUosWLTRq1KiDNsKVdcEFF+i5557TX//6VxUWFmr79u369ttvq7lSAFXVtm1btW3bVpK0d+9eTZkyRXPmzNH111+vpKQkSVJOTs4hn//dd99JkrKysg66Lzs7W88//3zYtNjYWCUmJoZN++9//6tt27bJ7/dX2AfbCgCR8rsJc/3791f//v0Pef+ePXt0xRVX6MEHH9S2bdvUrFkzXXfdderWrZskac2aNZo3b57+85//qGHDhkeoagBV5fP5NGPGDM2ZM0f/+c9/NHjwYEnSli1blJubW+FzUlNTJUlbt2496L4vv/xSaWlpYdM8Hs9Bj0tLS1NqaqqWLVtWYR8JCQlVeRkAUG1+N4dZf8moUaP0+uuva8mSJfrggw80dOhQ9evXzxn4/OSTT6pu3bp66qmnVKdOHeXn5+uss87S999/H+HKgT+uisKXJOcM1OzsbPXp00der1fz5s07ZDtFRUWKiYnRAw88EDZ9y5Yteumll5yzVX/O8ccfr++++06lpaXOnsLyN74EAoiU382euZ+zfv16Pfzww9qyZYuys7MlSRdddJGWLVumBQsW6Nprr9WGDRv0+eef6//+7/+0ePFilZaWavLkyTr55JP10ksvRfgVAH9Mffv2VU5OjgYOHKhGjRqprKxMq1at0o033qj4+HhdcMEFys/P12WXXaarr75au3fv1mmnnaakpCR99NFH+vbbbzVz5kwlJydr2rRpuuyyyzRixAiddtpp+u677zRz5kwFg0HNmDHjF2s59dRT9eCDD2rAgAG64IILdMwxx8jn82nLli16+eWXNWjQIJ144olHYK4AQLg/RJh79913ZWZq0KBB2PSSkhLn8EtZWZlKSkq0ePFi53H33nuv2rRpo7Vr1/KtG4iAK664Qv/4xz80Z84cbd26VSUlJcrKylKvXr00depUNW7cWJJ01VVXqX79+rr11ls1bNgwRUdHq379+po4caLT1tSpU5WRkaFbbrlFS5cuVUxMjLp166Zrr71W9evX/8VavF6vnnjiCc2dO1f333+/Zs2apejoaOXk5Khr164qLCw8bPMBAH7O7/IXIDwejx577DFnLM3SpUs1bNgwffjhh/J6vWGPjY+PV82aNTVjxgxde+21Ydex2r17t2JjY/Xcc8+pd+/eR/IlAAAAVMofYs9cq1atVFpaqq+//lpdunSp8DGdOnXSvn37tH79etWrV0+S9Mknn0iS8vLyjlitAAAAVfG72TO3c+dOffrpp5L2h7ebbrpJ3bt3V0pKimrXrq0zzjhDr7/+um688Ua1atVK3377rV566SUVFhZqwIABKisrU7t27RQfH6+bb75ZZWVlmjBhghITE/Xcc89F+NUBAABU7HcT5pYvX67u3bsfNH3kyJFauHCh9u7dq2uuuUaLFy/WF198odTUVBUVFWnmzJnOWJcvv/xS559/vp577jnFxcWpf//+uvHGG5WSknKkXw4AAECl/G7CHAAAwB/RH+Y6cwAAAL9HhDkAAAAXc/XZrGVlZfryyy+VkJBQ4c/vAAAAVAcz044dO5Sdna2oqKNrX5irw9yXX355yN9iBAAAqG6bN29WTk5OpMsI4+owF/ph682bNysxMTHC1QAAgN+r4uJi5ebmOtnjaOLqMBc6tJqYmEiYAwAAh93ROKzr6DroCwAAgCohzAEAALgYYQ4AAMDFCHMAAAAuRpgDAABwMcIcAACAixHmAAAAXIwwBwAA4GKEOQAAABcjzAEAALgYYQ4AAMDFCHMAAAAuRpgDAABwMcIcAACAixHmAAAAXIwwBwAA4GLRkS4AABB5hYsKq7W91SNXVzh9TaPG1dqPJDX+eE21twm4CXvmAAAAXIwwBwAA4GKEOQAAABcjzAEAALgYYQ4AAMDFCHMAAAAuRpgDAABwMcIcAACAixHmAAAAXIwwBwAA4GKEOQAAABeLeJj74osvdMYZZyg1NVWxsbFq2bKlVq5cGemyAAAAXCE6kp3/8MMP6tSpk7p3765//vOfysjI0Pr165WcnBzJsgAAAFwjomHuuuuuU25urhYsWOBMy8/Pj1xBAAAALhPRw6xPPPGE2rZtq6FDhyojI0OtWrXSPffcc8jHl5SUqLi4OOwGAADwRxbRMLdhwwbNmzdP9evX17PPPqtx48Zp4sSJWrx4cYWPnzVrlpKSkpxbbm7uEa4YAADg6OIxM4tU536/X23bttUbb7zhTJs4caLeeecdvfnmmwc9vqSkRCUlJc7/xcXFys3N1fbt25WYmHhEagaA36PCRYXV2t7qkasrnL6mUeNq7UeSGn+8ptrbBA5UXFyspKSkozJzRHTPXFZWlpo0aRI2rXHjxtq0aVOFjw8EAkpMTAy7AQAA/JFFNMx16tRJa9euDZv2ySefKC8vL0IVAQAAuEtEw9zkyZP11ltv6dprr9Wnn36qhx56SHfffbcmTJgQybIAAABcI6Jhrl27dnrsscf08MMPq1mzZrr66qt18803a9iwYZEsCwAAwDUiep05STr++ON1/PHHR7oMAAAAV4r4z3kBAADg1yPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcLKJh7sorr5TH4wm71axZM5IlAQAAuEp0pAto2rSpXnjhBed/r9cbwWoAAADcJeJhLjo6mr1xAAAAv1LEx8ytW7dO2dnZqlOnjk499VRt2LAh0iUBAAC4RkT3zLVv316LFy9WgwYN9N///lfXXHONOnbsqA8//FCpqakHPb6kpEQlJSXO/8XFxUeyXAAAgKNORPfM9e/fX0OGDFFhYaF69eqlp59+WpK0aNGiCh8/a9YsJSUlObfc3NwjWS4AAMBRJ+KHWcuLi4tTYWGh1q1bV+H9U6dO1fbt253b5s2bj3CFAAAAR5eInwBRXklJidasWaMuXbpUeH8gEFAgEDjCVQEAABy9Irpn7qKLLtKKFSv02Wef6e2339bJJ5+s4uJijRw5MpJlAQAAuEZE98xt2bJFp512mr799lulp6erQ4cOeuutt5SXlxfJsgAAAFwjomFuyZIlkeweAADA9Y6qEyAAAABQNYQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABc7KgJc7NmzZLH49GkSZMiXQoAAIBrHBVh7p133tHdd9+t5s2bR7oUAAAAV4l4mNu5c6eGDRume+65RzVq1Ih0OQAAAK4S8TA3YcIEHXfccerVq9cvPrakpETFxcVhNwAAgD+y6Eh2vmTJEr377rt65513KvX4WbNmaebMmYe5KgAAAPeI2J65zZs364ILLtADDzygYDBYqedMnTpV27dvd26bN28+zFUCAAAc3SK2Z27lypX6+uuv1aZNG2daaWmpXnnlFd12220qKSmR1+sNe04gEFAgEDjSpQIAABy1IhbmevbsqdWrV4dNGzVqlBo1aqQpU6YcFOQAAABwsIiFuYSEBDVr1ixsWlxcnFJTUw+aDgAAgIpF/GxWAAAA/HoRPZv1QMuXL490CQAAAK5S5T1zmzZtkpkdNN3MtGnTpmopCgAAAJVT5TBXp04dffPNNwdN//7771WnTp1qKQoAAACVU+UwZ2byeDwHTd+5c2elrxcHAACA6lHpMXMXXnihJMnj8WjatGmKjY117istLdXbb7+tli1bVnuBAAAAOLRKh7n33ntP0v49c6tXr5bf73fu8/v9atGihS666KLqrxAAAACHVOkw9/LLL0vaf2HfuXPnKjEx8bAVBQAAgMqp8pi5BQsWhAW54uJiPf744/r444+rtTAAAAD8siqHuVNOOUW33XabJGn37t1q27atTjnlFBUWFuqRRx6p9gIBAABwaFUOc6+88oq6dOkiSXrsscdkZtq2bZtuueUWXXPNNdVeIAAAAA6tymFu+/btSklJkSQtW7ZMQ4YMUWxsrI477jitW7eu2gsEAADAoVU5zOXm5urNN9/Url27tGzZMvXp00eS9MMPP3CdOQAAgCOsyr/NOmnSJA0bNkzx8fGqXbu2unXrJmn/4dfCwsLqrg8AAAA/o8ph7txzz9UxxxyjzZs3q3fv3oqK2r9zr27duoyZAwAAOMKqHOYkqW3btmrevLk+++wz1atXT9HR0TruuOOquzYAAAD8giqPmfvxxx81ZswYxcbGqmnTptq0aZMkaeLEiZo9e3a1FwgAAIBDq3KYmzp1qt5//30tX7487ISHXr16aenSpdVaHAAAAH5elQ+zPv7441q6dKk6dOggj8fjTG/SpInWr19frcUBAADg51V5z9w333yjjIyMg6bv2rUrLNwBAADg8KtymGvXrp2efvpp5/9QgLvnnntUVFRUfZUBAADgF1X5MOusWbPUr18/ffTRR9q3b5/mzp2rDz/8UG+++aZWrFhxOGoEAADAIVR5z1zHjh31+uuv68cff1S9evX03HPPKTMzU2+++abatGlzOGoEAADAIfyq68wVFhZq0aJF1V0LAAAAqqjKe+a8Xq++/vrrg6Z/99138nq91VIUAAAAKqfKYc7MKpxeUlIiv9//mwsCAABA5VX6MOstt9wiaf/Zq/Pnz1d8fLxzX2lpqV555RU1atSo+isEAADAIVU6zM2ZM0fS/j1zd955Z9ghVb/fr/z8fN15553VXyEAAAAOqdJh7rPPPpMkde/eXY8++qhq1Khx2IoCAABA5VT5bNaXX375cNQBAACAX6HKJ0AAAADg6EGYAwAAcDHCHAAAgIsR5gAAAFzsN4W5wsJCbd68ubpqAQAAQBX9pjC3ceNG7d27t7pqAQAAQBVxmBUAAMDFflOY69Kli2JiYqqrFgAAAFRRlS8aXN4zzzxTXXUAAADgV+AwKwAAgIsR5gAAAFyMMAcAAOBihDkAAAAXq3SY+9e//qXS0lLnfzMLu7+kpER/+9vfqq8yAAAA/KJKh7mioiJ99913zv9JSUnasGGD8/+2bdt02mmnVW91AAAA+FmVDnMH7ok78P9DTQMAAMDh85uuM3cgj8dTnc0BR5Ub/3R8tbf556VPVXubAIA/Fk6AAAAAcLEq7Zn76KOP9NVXX0naf0j1448/1s6dOyVJ3377bfVXB1TC7eNeqvY2J9zZo9rbBADgcKhSmOvZs2fYuLjjj99/2Mnj8cjMqnyYdd68eZo3b542btwoSWratKmmT5+u/v37V6kdAACAP6pKh7nPPvus2jvPycnR7NmzVVBQIElatGiRBg0apPfee09Nmzat9v4AAAB+byod5vLy8n7xMatWrarU40IGDhwY9v9f/vIXzZs3T2+99RZhDgAAoBJ+8wkQ27dv1x133KHWrVurTZs2v7qd0tJSLVmyRLt27VJRUdFvLQsAAOAP4VdfmuSll17Sfffdp0cffVR5eXkaMmSI7r333iq3s3r1ahUVFemnn35SfHy8HnvsMTVp0qTCx5aUlKikpMT5v7i4+NeWDwAA8LtQpTC3ZcsWLVy4UPfdd5927dqlU045RXv37tUjjzxyyAD2Sxo2bKhVq1Zp27ZteuSRRzRy5EitWLGiwvZmzZqlmTNn/qp+AAAAfo8qfZh1wIABatKkiT766CPdeuut+vLLL3Xrrbf+5gL8fr8KCgrUtm1bzZo1Sy1atNDcuXMrfOzUqVO1fft257Z58+bf3D8AAICbVXrP3HPPPaeJEydq/Pjxql+//mEryMzCDqWWFwgEFAgEDlvfAAAAblPpPXOvvvqqduzYobZt26p9+/a67bbb9M033/ymzi+77DK9+uqr2rhxo1avXq3LL79cy5cv17Bhw35TuwAAAH8Uld4zV1RUpKKiIs2dO1dLlizRfffdpwsvvFBlZWV6/vnnlZubq4SEhCp1/t///lfDhw/X1q1blZSUpObNm2vZsmXq3bt3lV/I4ZR/6dPV3ubG2cdVe5sAAOCPp8pns8bGxmr06NEaPXq01q5dq3vvvVezZ8/WpZdeqt69e+uJJ56odFu/5uxXAAAA/M9vus5cw4YNdf3112vLli16+OGHq6smAAAAVNJvvmiwJHm9Xg0ePLhKe+UAAADw21X6MOvo0aN/8TEej4dDpwAAAEdQpcPcwoULlZeXp1atWsnMDmdNAAAAqKRKh7lx48ZpyZIl2rBhg0aPHq0zzjhDKSkph7M2AAAA/IJKj5m74447tHXrVk2ZMkVPPvmkcnNzdcopp+jZZ59lTx0AAECEVOkEiEAgoNNOO03PP/+8PvroIzVt2lTnnnuu8vLytHPnzsNVIwAAAA7hV5/N6vF45PF4ZGYqKyurzpoAAABQSVUKcyUlJXr44YfVu3dvNWzYUKtXr9Ztt92mTZs2KT4+/nDVCAAAgEOo9AkQ5557rpYsWaLatWtr1KhRWrJkiVJTUw9nbQAAAPgFlQ5zd955p2rXrq06depoxYoVWrFiRYWPe/TRR6utOAAAAPy8Soe5ESNGyOPxHM5aAAAAUEVVumgwAAAAji7V8tusAAAAiAzCHAAAgItV+jArjoArkw5Dm9urv00AAHDUYM8cAACAixHmAAAAXIwwBwAA4GKEOQAAABfjBIg/oMJFhdXe5uqRq6u9TQAA8MsIc8Af2JVXXumKNgEAh0aYA45CWy59tdrbzJndpdrbBABEHmPmAAAAXIwwBwAA4GIcZsVhs6ZR42pvs/HHa6q9TQAA3Iw9cwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICL8dusAIDfndvHvVTtbU64s8dB02780/HV3s+flz5V7W3i940wB+Cwe/GletXeZs8e6w+aVvPlVdXez1fdWx40Lf/Sp6u9n42zjzt44pVJ1d6Prtxe/W0CiCgOswIAALgYe+YAADjKbbn01WpvM2d2l4OmXXnlldXez+FoE+HYMwcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDEuTQIAAI6oI3Uh8T+KiO6ZmzVrltq1a6eEhARlZGRo8ODBWrt2bSRLAgAAcJWIhrkVK1ZowoQJeuutt/T8889r37596tOnj3bt2hXJsgAAAFwjoodZly1bFvb/ggULlJGRoZUrV+rYY4+NUFUAAADucVSNmdu+ff8PQKekpFR4f0lJiUpKSpz/i4uLj0hdAAAAR6uj5mxWM9OFF16ozp07q1mzZhU+ZtasWUpKSnJuubm5R7hKAACAo8tRE+bOO+88ffDBB3r44YcP+ZipU6dq+/btzm3z5s1HsEIAAICjz1FxmPX888/XE088oVdeeUU5OTmHfFwgEFAgEDiClQEAABzdIhrmzEznn3++HnvsMS1fvlx16tSJZDkAAACuE9EwN2HCBD300EP6xz/+oYSEBH311VeSpKSkJMXExESyNAAAAFeI6Ji5efPmafv27erWrZuysrKc29KlSyNZFgAAgGtE/DArAAAAfr2j5mxWAAAAVB1hDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAFyPMAQAAuBhhDgAAwMUIcwAAAC5GmAMAAHAxwhwAAICLEeYAAABcjDAHAADgYoQ5AAAAF4tomHvllVc0cOBAZWdny+Px6PHHH49kOQAAAK4T0TC3a9cutWjRQrfddlskywAAAHCt6Eh23r9/f/Xv3z+SJQAAALhaRMNcVZWUlKikpMT5v7i4OILVAAAARJ6rToCYNWuWkpKSnFtubm6kSwIAAIgoV4W5qVOnavv27c5t8+bNkS4JAAAgolx1mDUQCCgQCES6DAAAgKOGq/bMAQAAIFxE98zt3LlTn376qfP/Z599plWrViklJUW1a9eOYGUAAADuENEw9+9//1vdu3d3/r/wwgslSSNHjtTChQsjVBUAAIB7RDTMdevWTWYWyRIAAABcjTFzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4GGEOAADAxQhzAAAALkaYAwAAcDHCHAAAgIsR5gAAAFyMMAcAAOBihDkAAAAXI8wBAAC4WMTD3B133KE6deooGAyqTZs2evXVVyNdEgAAgGtENMwtXbpUkyZN0uWXX6733ntPXbp0Uf/+/bVp06ZIlgUAAOAaEQ1zN910k8aMGaOzzjpLjRs31s0336zc3FzNmzcvkmUBAAC4RsTC3J49e7Ry5Ur16dMnbHqfPn30xhtvRKgqAAAAd4mOVMfffvutSktLlZmZGTY9MzNTX331VYXPKSkpUUlJifP/9u3bJUnFxcWHr1BJZSU/VnubFdZcYtXejyrop3R36WHo5uB+dpYemX5279l1RPr5ae/eI9KPJO0oOTKvqfz6dDj72bWr7Ij0U7Zr55Hp53e2TZCqf7twqGWb7cKv64dtwq/r53C0b3YY1svfyiLkiy++MEn2xhtvhE2/5pprrGHDhhU+Z8aMGSaJGzdu3Lhx48YtIrfNmzcfiZhUJRHbM5eWliav13vQXrivv/76oL11IVOnTtWFF17o/F9WVqbvv/9eqamp8ng8h7XeX1JcXKzc3Fxt3rxZiYmJ9HMU9kU/9HOk+6If+jmS/RzJvn5v/VSGmWnHjh3Kzs6OaB0ViViY8/v9atOmjZ5//nmdeOKJzvTnn39egwYNqvA5gUBAgUAgbFpycvLhLLPKEhMTj8gC93vr50j2RT/0c6T7oh/6OZL9HMm+fm/9/JKkpKRIl1ChiIU5Sbrwwgs1fPhwtW3bVkVFRbr77ru1adMmjRs3LpJlAQAAuEZEw9yf/vQnfffdd7rqqqu0detWNWvWTM8884zy8vIiWRYAAIBrRDTMSdK5556rc889N9Jl/GaBQEAzZsw46DAw/Rw9fdEP/RzpvuiHfo5kP0eyr99bP27nMTsaz7EFAABAZUT8t1kBAADw6xHmAAAAXIww9zvh8Xj0+OOPH9G2Nm7cKI/Ho1WrVoVNX758uTwej7Zt2/ab6qiudn6Lbt26adKkSRHrP+RQ8/pQfu49rEpboffgwQcfDJu+cOHCarssUEVtHenlOT8/XzfffHO19CdV/f2qrrYOtc4c7vfrSDnzzDM1ePDganm/Qm1VxqG2A1Wp45ceW51t/Rq/9L4ejj6r6sorr1TLli2PeFuHWlaOls8H6XcU5iqa2X//+98VDAZ1/fXX68orr5TH4znosierVq2Sx+PRxo0bJf1vwxkIBLRjx46wtqKiotS7d+8qt5WRkRHWliS1bNlSV155ZbXVH3LyyScf1GeonezsbHXr1q1StX/99ddh7Zx55pnyeDzOLSkpSVdccYV+jfJtRUdHq3bt2mrbtm1Y+x6PR927d5ck1ahRQx6PRx988EGl2g/Nq5+71apVS+PHj9cPP/xw2Oo/8Baat7+m/jp16kiSWrVq5bT1cx9GW7duVf/+/av0mn7ug61Xr16VbutACxcuDHstmZmZGjhwoAYPHuz0uWfPnrAPkkPVX5m2DvxQquq8qGyfH3744RFv6+uvv9bYsWNVu3ZtBQIB1axZU3379tWKFSuUlpam+++/v8LnPfXUUyouLtaePXucGurXr39QWy1atJDH45HX69U111xzyLa2b9+upKQkp63GjRsf9Li//e1v8ng8ys/P/9n6mzVrpvj4eKWlpR2yz1mzZiktLU2lpaXatGmTPv/8c/3lL3+pcv3l193FixfrmWeekcfjUYMGDSpV/4Ftff7555o8ebKzHajKNiU/Pz9sWfj888914YUX/mxgCtX/+eef689//rPTZ25u7kHbjOjo6CqHr+Li4ioFygP7zMnJCbv/SIe/oyFw/ha/JRz+bsLcgebPn69hw4bptttu0yWXXCJJCgaDuvfee/XJJ5/84vP37dunv/71r2Ft1apVS506dapyWzt27HDa+jllZf/7rbrfWn+oz/LtZGRk/Kba+/Xrp61bt6px48Y64YQT9OKLL/7i8w8l1NbGjRs1f/58bd26VYMHD9bWrVu1detW5eTkaNSoUZKkxYsXS5Jq1arlPH/Pnj2HbPuiiy5y2gm11bJlS7Vq1UrS/r0X8+fP15NPPqlzzz33Z9v6LfWHLrkTuuXm5mrv//8dx6rWP3nyZEn7L6odaiu0vFTUVs2aNav17K9f05aZad++fZL2X/Bz69at+vLLL/X0009r165deuGFF8KW+fIOrL8626pK/bt37z5kn8cdd1yll53qamvIkCF6//33tWjRIn3yySd64okn1K1bN+3cuVNnnHGGli1bVuHzXnvtNfl8Pvn9fklSXFycNm7cqNdffz2srd27dys9PV1xcXFauHBhhb9B+dprr8nr9TpfIuPi4vT111/rzTffDHvcfffdp9q1ax9U/6pVq8L6bNSokcxMZ5xxxiH7XLBggYYPHy6v1ytp/97W77//Xq+99lqV64+NjdXZZ5+tIUOGqHbt2k44qkz9BwoGg5o5c6azHQhtUyqr/DYiJyenUhfF7devn3JycjRt2jSnz++//14zZswI225kZWVVuo4D7a3k780euI177733fnXble3ztz7ndytCPyNW7UaOHGmDBg0yM7PrrrvOAoGA/f3vf3funzFjhrVo0cJ69+5tQ4cOdaa/9957Jsk+++wzMzP77LPPTJIVFBRYfHy8TZs2zWmrRYsWNmPGjEq1lZeXZ5MnTzZJ5vP5zOPx2F/+8hfnsS1atDBJNm/ePDvhhBPM6/U6v0k7cuRI83g8Fh0dbXXq1LGkpCTr2rWrJScnW1RUlAUCAatbt64FAgGrU6eO83txY8eOtaysLJNkRUVF5vf7zefzWZ06dSwQCJjf77e8vDxr3ry5U/snn3xiXbp0MZ/PZ5Js8eLFJslOO+00k2Rer9c8Ho/l5OQ487dFixbWq1cvi4+PN0lWv359+7//+z+bP3++JSUlOfXccMMNdvvtt1tBQYH5/X7zer3OfX6/3x566CGTZNnZ2U4/KSkp5vf7LSoqymJjYyv8XbyoqChnvnq9XktOTnYe26VLFzvnnHMsJyfH/H6/FRQUWFxcnAUCgYPaycjIMI/HYwkJCVazZk2nhlAfhYWF1r59e7vgggvMzOz111+39PT0g9rp2LGjeb1ei4qKsr59+1rNmjXD6szOzraEhASLioqyIUOGWFZWliUmJjo1hR4nyWrUqGF+v9+ysrIsPz/fAoGAeb1eS0hIMEmWnp7utJWXl2eBQMCCwaAzbz0ej/NetmvXzj777DN77LHHTJJFR0dbIBBwXmN8fLwlJyeb3++3mJgYy8rKcpaf0HsUExNjkqxevXp22WWXWZMmTZyaPR6PxcTEWPPmzW306NGWmJjoPDfUh9/vtxo1apjX67XMzEyLjo626OjosPkcFxd3yN9AjI6Odl7PhRde6DzW5/NZ69atLSoqypl/9erVs+bNm1fYzoABA5z34sD7fD6fJSUlOW1PnTrV6TMqKsqpv0GDBhYIBKxhw4YHLYvBYNDS09PN4/GYx+Nx1o0RI0Y4f48fP96pz+fzOfOiqKjIJNkHH3xgZmZvv/221a9f32krNTXVJNmwYcOceZKRkWF5eXkWDAYtPz/fFi1aFDYf27RpYy+//LL9+OOP1qFDB5NkcXFxZma2YMEC8/v9YfMgMTHRJk+ebIFAwC6++GKnLa/X67wHTZs2tdmzZ1c4f0PrkiSLjY218ePHWyAQsEsvvdTi4uJswIAB1qpVK+fxTZs2tYULF1q3bt0OaqtDhw6Wk5NjMTExVr9+fWfdPvPMM61evXphy1lMTIyZmd14443OOhAMBp11a/ny5WZmtm/fPps8ebJFR0c7bY0YMcIaNmzo1O3z+axVq1Z2wgknWG5urkmyhIQEZ92Oj4+3888/34YNG2ZFRUXOex8bG2vnnnuuvfPOOxUuX16v19lWpaamOtvl0H1ZWVl2ww03VDhfQ+t9aJ2KiYmxNm3aWF5enkmycePGOe+lz+ezwYMHW69evZzXVP5Wt25d8/l8FggEnHqioqIsGAw67+GBzwktg6FltW/fvrZ3714zM8vLy7NmzZo593u9XvN6vdarVy9nmSt/GzNmjNWpU8c8Ho+VlZWZJOvUqZNTf2pqqsXHx9tll13mvH/R0dEWExNjcXFxNnr0aOvUqZN5vV5LSUlx2j3vvPNs27ZtYduu0K28WbNmWUZGhsXHx9vo0aNtypQp1rhxYzv++OOdz5AmTZrY008/7Tznww8/tP79+zvbzjPOOMO++eYb+/e//23p6emWn5/vfD6YmZWUlNjFF19s2dnZFhsba8ccc4y9/PLLYXW89tprduyxx1pMTIwlJydbnz597Pvvv7eRI0ceVH8ol1TG7y7MTZkyxeLj4+35558Puz8UwFauXGlRUVH2r3/9y8wOHea6detmGRkZ5vP5nLYODHM/11ZeXp6zQXzsscesVq1a5vF47LnnnnPaCq1A9957r5100knWu3dvO+WUU0ySXXzxxbZ+/Xp77rnnnJUuKyvL/v73vztv9Lx582z+/PnO/0lJSdamTRuTZCeffLJ5PB7zer22cOFCW79+vRMAMzMzndrr1q1r3bp1syVLlpgk58M6tDF46qmnrGHDhpaRkeGEuYyMDEtOTnY2XDNnzrTo6Gjz+/2Wn59v8+bNcz4gPB6PzZ4922JiYiwYDFqzZs2sS5cuFhsb66zEM2fOtPj4eCeInHXWWRYVFeXMo/PPPz/sA3D8+PGWkJBgvXr1Mp/PZ9nZ2c7GrWbNmhYdHW1Lly619evX2+TJky0qKirsg97n85nf77fExESLjY21zMxMmzRpknm9XmvdurVdcsklNnfuXGeje95551lxcbGzgalfv37YB1PPnj2dwCrJRo0aZVFRUc4HVXp6ujN/hgwZYlOnTjWPx2OdO3e27Oxs53WGPuTy8/MtJibGPB6PTZgwISzY1qhRw9mw5OXlOQFi2rRplpOTY61bt3YCWJcuXax+/fpWo0YNk2RpaWkWHx/vhANpf6C78cYbrUuXLubxeCw5OdkefPBB69KliwWDQatXr55J+8N9dHS0M59TUlIsKirKjj32WOvQoUNYiMzKyrLo6GhLSkqys846y5o2beosn/Xr17cRI0Y4y1fjxo3t0ksvdf6fOXOm3XjjjWHL9CWXXOJs2NPS0iw2NtZZtnw+X1jAvOGGG+yss85y6giFuNCXntA6GQrJofBQfpkPfUgPGTLEnnrqKaeN7t2724YNG5wvPJJs0qRJtmjRIue5Y8aMsbvuusuSk5OdNqdPn24vv/yydejQwVJSUszj8dgNN9xg7du3dz5UJdmaNWts586dzns8ZcoUu+uuu5z1zOv1WkxMjI0ZM8batm1rubm59tZbb9nKlSstIyPDCZ6S7KqrrrJAIGBt2rRxvhgkJSWZmdm5554bFjQWL15skyZNsuTkZGvYsKG1bt3a+ZKQkJBgZ599tvn9frvrrrusV69eVqdOHQsGg5aYmGh9+/Z15lkgELCFCxdadna2+Xw+a9iwoc2ZM8fi4uIsKirK+QIzePBge+ihhyw7O9vOPPNMu+SSSywuLs4aNWrkbBPfe+89Gzt2rEVFRVlGRoYVFhbamDFjwr4IhALG5ZdfblFRUdawYUPr3r27EyCDwaANHz7czPZ/wU9KSrKaNWtaYmKijRkzxhISEpx1Njk52eLi4mzBggV2zjnn2NixY61Dhw7Oe1OvXj0bOnSotWrVyjIzM03a/8UgGAzaWWedZbGxsZaenu4Et1atWlnNmjWtXr16FhcXZw0aNHDmk8fjsVGjRpnP57Pk5GQLBAI2btw4q1mzpsXGxprP53PWkcLCQmvVqpXzJTI6OtqSk5OddTy0DkdFRdk555xjI0aMML/fbxdffLGlpaVZ586dneXw9ttvt7lz5zrLd69evWzp0qV23nnnOetEaJlu06aNE9CmTZvmLBM1atSwK6+80szM0tPTneW3sLDQ5s+fb5dffrkdc8wxVlBQYJLs+OOPt1GjRjnv21133WXvv/++E+b8fr9NmzbNXnjhBTv22GOdeXTFFVfYxRdf7Lzm8847zy6//HInjLdu3dqefvppe+CBB+yuu+6yTp06Wd++fS0jI8MuuOACGzdunNWoUcO+++47MzNbunSp+f1+u+eee+zjjz+2yy+/3BISEiwhIcF69+5tH3zwga1fv96efPJJW7FihZmZffnll5aWlmZTp061wYMHW9euXa13797WqlUrS0pKsjvuuMO6du0aFuZOP/1069ixo73yyiv26aef2g033GCBQMA++eQTJyMEAgEbP368rVq1yv7zn//Yrbfeat98841t27bNioqK7Oyzz7atW7fa1q1bbd++fZXOQL+rMBdaMV988cWD7g8FMDOzU0891Xr06GFmhw5z5b85ffrpp2Z2cJj7ubby8vKchfO9996zZcuWOR9+obZCK86B9Y8ZMyas9rS0NPN6vdaiRQt79tlnzePxWFpamvXv39/pU5INHDjQhgwZ4vyfn59/UP2NGjWy6OhoMzMnbGzevNlpZ+HChSbJ+bYWqj0UDCvai/Lqq686e4+2bdtmL7/8svNh6PV67dRTT7XOnTtbamqq7d6920aOHBm2Nyp0GzdunI0ZM8ZiY2MtLS3NJkyYYJLsySefdDZIY8aMsXnz5llqaqrdeeedVrt2bfN4PHbHHXc47QQCAXv22WfNzCw3N9fS0tKsXbt2Tp/lv7V27tzZevToYSkpKZaVlWVlZWXOfL/yyitNkg0ePNhOPfVUk2RTpkyxkSNHhu1lLN9WYmKixcfHW1pamk2bNs0k2c0332wtW7Y0n89nJSUlVqNGDYuPj7c777zTGjZs6GzYJNm//vUv8/l8lpCQYO3atXPaCgWKiy++2Fq1amU+n8+GDx9uXq/XmjZtavPnz3fauvrqq02S/e1vfzOfz+e8ZzVq1LCHHnrICduSbMKECVZUVGR169a1hIQE69Gjh61bt848Ho899thjzjy77bbbLD4+3glFo0aNctq94IILTJKddNJJJu3/InTOOefY/ffff9CezNByJe3f6zBo0CBbsGCB08+OHTusS5cuzmM8Ho99/PHHzv/Tp08/aL5L+/eO5OXlmZlZx44dze/326uvvuq0+5e//MUk2Z/+9CfnOaFlvfw6E1rnTz75ZGc5KL8XoPyHaCAQMDOzu+66y/mQOeuss8zMbPTo0c7jdu/ebWvWrDFJzl6luLi4sLZq1KjhtOX3+2306NFO/+Xfr/vvv9/Z+928eXObOnWqPfXUU879Xbt2NUm2cuVKi4+Pd/ZMjxw50glzoXlw6qmnOuGjY8eOFhsb67ynaWlp5vF4LDY21nbs2GE9e/a0P//5z05bMTExlpSUZIMGDXLWi5YtW9qiRYvsmWeeMWl/EJ8zZ47znq9evdr+/ve/W40aNczn81kwGLRLL73UrrrqKktKSrIrrrjCma87duywrKwsO+OMM0ySXX/99bZ3716LjY11gsGZZ57prMuBQMCSk5Nt7ty5NmfOHMvLy3P6CLUV+tJZ0d7gm266yam/rKzM6tWrZ926dbOioiJnHbzgggucoy0ZGRk2YsQIJ5CU356FQshbb71lZmb16tVztvcJCQmWm5trZubswQ/N59CetxYtWlhiYqL5fD5bvXq109bQoUOdL/YHLv+hPfpRUVHm9/stLi7OatSoYXPmzLGkpCSLiooys/17MENfYvv37+8sY9L+L8Iej8fOOeccZxkIHU0KLb/Dhg2zrKwsMzPni0NovYiLi7O5c+c6j42JibE5c+bYjBkzzOfz2QknnGADBgwwM7MXX3zRpP1f1EMWLFjgLMNmZkVFRc6ympaWZmbmrD9ffPGF87wXX3zREhMT7aeffrK8vDybM2eOM9/vuusup61x48aFfa62b9/egsGgE04PNG3aNOvTp4+Z/W9nUWjnyY033mhmFhbmPv30U/N4PGG1mZn17NnTpk6damZmp512mnXq1KnC/g5sr6p+V2Gubdu2lp+fb506dbLi4uKw+8sHsE8//dR8Pp89++yzhwxzTZo0cb7NhjbsFYW5Q7WVl5dnkyZNcgKRmVn9+vWdQx2hlfuBBx4Iqz+0Wzu0YS2/0SksLLSbb77ZcnJynMNW5cPcpEmTnA+m7Oxs51tgKISF/pdku3btcjae5Wt///33TZLVqlXLpP2Hpx544AHLzMy0zMxMe+SRR0xS2OGt0C20kQxtvAOBgPPtrvxGq/y369DzQh/IoQ/F0K77AwOA3+93Nsih+0N9lQ8Ad9xxh3399dfO/+XrDf3ft29fe/vtt529KIe6JScnO/XGxMQ4/ZfvO9RW+TpC9cXExDgb2VBNB9Z/YNhp0KCBs1EtPy8CgYBFRUWZz+cLCyYV3UK1lD8UHxMTExYiQn2GPkxC/R2qzdChmPKH6UKHccvP/5+rKfTcYDDo7LEtX9+hXoe0f290aO9y6L60tDRnT11cXFyF/Yf6DO1pDC1vksL2skr79+iFPhAPPNRfvn6v12u1a9d2vviFXntcXFzYtI8++sgef/zxsPf7wPchNTXVzMwmTZrk7LUOrf/lH5eZmWk9evSwqKgomz59etjhvlBN5Wtp27atxcbG2h133OGEufJ7PkPzqqIvJweuc+XbOjDMBYNBJ0yUf7+uu+468/v9FgwGnW3x7t27beDAgc56GHpsaJ75fD675ZZbTJJNnDjRJDmHvnJzcy0hIcEZ+hEMBsPWz9BrKX/oNNTWJZdcYl6v17p162br1q2z7t27O+9v9+7dbeDAgda+fXvncOyB86R8H8cee6yNHDnSgsGgXXbZZXb66acfNJQjNE8OfO6By2m7du1s3bp1lp2dbUlJSdalSxdnWx1qs/yRjLy8POfwa9OmTa1v375Wu3Ztu/zyy50hFxWtA7t27bJNmzY529mEhAR79NFHbe/evSb9bwhCaBsTWjfLfw6FluFdu3Y581+SDR061G6//Xb75ptvzMyc1xgKcwUFBXbzzTdbnTp1zMzs+uuvd/oKtR96fdHR0WF70MvX37JlS5NkOTk5dtZZZ9mjjz5qs2bNcj57PB6Ps+5ERUXZJZdcYmZmycnJtmjRorBMMGnSJMvJybHo6Gjr2LGjTZ8+3d5//33n/gEDBjhfhg/8zHrmmWfMLDx8/e1vfzNJzusJ3aKjo+2UU04xM7PGjRvb9OnTD5ljfkuY+12dAFGrVi2tWLFCW7duVb9+/Q46gzSkXr16Ovvss3XppZdWOEBWkjIyMrRixQrFx8fr73//u1577bVf3VbI8ccfr127doUNEo2Liwur3+/3q0aNGmrUqJFee+01rVq1SrVq1dIxxxyjqKgomZl8Pp+Kior0ww8/hPUZDAadv+fPny8zU2ZmpsrKyvTggw+qQYMGateunRo1aqRgMKjU1FQlJCSE1R4a1Hz55ZdLktLS0jR9+nTt2LFD//3vf7Vz505J0vDhw9W8eXNJ0qBBgyRJ48eP16pVqzR//nxJ0htvvKGPPvpI2dnZSk9Pl9/vV3p6uvr166e2bds6tU6dOlWSNGLECL366quSpJSUFP3pT3+SJM2dO1eSFBMTo7Fjx2rYsGFq3769hg4dqubNm+uFF17QQw895NT/4Ycf6vTTT3cGxKempqpp06bOCRDHHXecevbsqZKSEj355JN65513JEkJCQmKjY1V586d9cILL+iFF15QixYt1L59e8XExEiS7r77bg0cOFA9evRw6n/kkUectk499VRJ+08YiIrav3otWbJEgwYN0rHHHuvU1KhRo7D6Q5YuXaqRI0cqMzPTeU9SU1M1ZMgQSdJ1112nQYMGqVu3bs79d999tzp27KiUlBTFxcWpc+fOkqQ5c+Zo5MiRSktLc9q/5557tHTpUuf/yZMn65RTTtHu3bvl9/v1r3/9S8OHD3eWzcLCQklSUVGRPB6PCgoKJEnnnHOOYmNjnfokqV27dpKkqKgopaen65///KezHIXe+3fffVfvvPOOgsGgzExt2rTR9OnTnXqWLFniDNKXpMcff1xPPvmkJMnr9crn8ykqKko+n0+SFB0drTZt2mjXrl3Kz8/XqlWrlJaWJp/P57yHofkWeo9DNT7yyCOS5MzH0Pu1e/dujR07VqtWrXJO8gkGg3rhhRec+kPTHnjgAZ166qnOCRZNmzbVqlWrdMEFF0iSrr32WtWrVy9sPY2NjdUHH3ygDz74QImJierSpYvq1q0bVkuo/1WrVjnv19/+9jfdfvvtCgaDKisr03PPPacVK1aoa9eukvafWHHaaadJ2r/eJicn66efftLJJ5/sLL/S/nVLkkaOHKmhQ4dK2r9ujR49Wh06dJAkJSUlKSsrS4MHD1ZhYaHWrFkjj8dzUFshM2fO1Ouvvy6fz6dmzZpJkh588EHnfQptV0LzrVatWmrXrp3Wrl3rnAk+btw45eTk6KSTTnLW59D7Fx8f7zw/1FaXLl3k8/m0fft2xcfH66yzztLQoUMVFxen7OxsrVu3Lqytf/7zn8rPz1dSUpIKCgqUlJSkhg0byuv1Kjo6Wjt27NDbb7+tm2++Wd26dVNubq7atm2r2NhYxcbGqlu3bsrIyFCdOnWUlJTk1JKenq709HRlZ2fL5/OpUaNG8ng82rNnj8xMV155pXJycuT3++X1elWzZk2tWrVK2dnZKiwsVM2aNVVQUOAs26HXl5ycrDlz5ig6OlrvvfeeLrroIsXGxqpJkybOiSDdu3dXSUmJtm/f7pzt6/F4NGPGDKWnp2vcuHHy+/3KyspSMBhUbm6uTjrpJGVnZ8vj8ejcc8/Vscce67wWj8ej7OxslZWVqbS0VDNnznSWw8TERF1yySVat26dgsGgvF6vBg4cqKioKGVmZurqq6/WCSec4JyUUP49j4uLk5k500LbwTlz5jjtX3XVVZL2fx6sWrVKCQkJuvrqq5WQkKDrr79ewWBQgUBAgUBAt99+u2JiYnTuuedq3rx5YfP0oosu0qpVq7R27VpdfPHFBy2r5aWmpmrDhg0aPny4Vq9erbZt2+rWW291ahw4cKBWrVqlgQMHqlWrViooKFD37t2d9aS8srIyeb1erVy50nlNq1at0po1a8I+ww6X31WYk6TatWtrxYoV+vrrr9WnTx8VFxdX+Ljp06frk08+0ZIlS362rbfeekvx8fE6/vjjVVpaWqW2DjyzZ+vWrapZs6YuvfTSQ/bZpk0b9e7dW8XFxRo/frwyMjIUHR2t77//XpLUpEkTbdq0SXFxcSotLT1k/VlZWWrdurV+/PFH1ahRQ7fccosCgYBiYmKcoNGkSRPt2rVLa9euddp59913JcnZWEyePFkffPCBdu/erRo1amjRokXyeDzavn27pkyZImn/7+smJSXp7rvv1hdffOGcdVq3bl3Vr19fXbp0UUpKiuLj47Vlyxbt3LnTeV2S1LFjR0n/O3usVq1a2rdvn3N5iby8PEn7N24ffvihOnTooHXr1qlz587avHmz2rVr51wOwMz0xRdfKCkpSZmZmU5bwWDQCR/x8fGKjY3VjBkz9Ne//lWxsbFKTk7W3r17df/99+u1115Tq1at1LNnTyUnJ6tRo0bOGcVz585VYmLiQSE81Nbq1asVFxenYDDoBLCkpCTnOZmZmUpOTtbGjRvD6g+pXbu2OnbsqA8//FDvv/++4uLitG/fPueLSc2aNZWYmKjY2FjFxMQoGAzqq6++0plnnikz0+LFi50vHllZWerYsaNz1nJ6ero2bNigL7/80unvhBNO0KJFi1SrVi2VlJTI6/U6AWzmzJlavXq1JGnAgAEyM+cSGunp6Qd9eQltqHv16qVvvvlGGRkZGjFihLM8fffdd4qOjtbevXv1008/qbS0VHv27FFWVpbz3NBlXkK6du2q+vXrS5JKS0u1efNmRUVF6YsvvpAk7dq1S926dVNZWZm+++47FRQUqH79+iorK1PPnj3Vs2dP57mSnEu8lJWVOaEstHyFPmB27Nihf/7znyooKFCHDh2c5bBnz55q0qRJ2BnJ3377rTp37uycadu4cWMVFBQ462tmZqb8fr8aNWqkffv2KSEhQWVlZU4oLi4u1oABA7R27Vo99thjatKkifbt26fVq1eroKBABQUFzvtVv359DRkyRDfeeKMk6a233tLq1avVvn17p61QyPj222/VtWtX/ec//3HmQXler1der1dLly5V//79tXPnTg0YMEDdunVz7v/vf/+rIUOGaOXKlfr444/1zjvvaMyYMc57XX57+N5776lt27YaNGiQVq5cKY/Hox49esjj8SgqKkq7d+8OO3u+devWWrdunTIyMtSwYUOZmVJSUrR161YNHTpUb731lmrUqKGPPvrIuXTIvn379N133zltHHPMMXr22Wfl8Xi0Y8cOjR07Vh06dFBpaamio6NVUFCg8ePHO22tXr3aWZb27dunlStXStofLl999VU9+OCDio+Pl5np1ltvVceOHbV9+3aVlZXJ4/GoefPmevXVV/XVV1/pP//5z0HzNCEhQaWlpdqwYYPMTLVq1VJSUpJmzJihFi1aaM+ePfL7/frpp59UUFCg6OhoBYNB50tEaL6bmYLBoLZt2+a87m3btmndunVKSUnRnj17nOsIfvDBB5oxY4aKi4u1fft2paamKj09XTNmzFBycrIKCgoUExOjkpISpx+v16t9+/apS5cuWr58edhZvB6Px9luhd7XgoIClZaWqri4WOnp6SooKHDaio6OVllZmYYPH+609eSTT8r2H/ULW0beeOMN5xI2rVu3dmoJLeeZmZmS9l8mq6CgQM2aNdO7776rHTt2qGvXroqKitKWLVvk8Xh0wgkn6JZbbtHy5cu1adMmffXVV4qOjlZsbKxSUlKcNkNfZBs3bqy33nor7P0K/Z+bm6tx48bp0Ucf1Z///Gfdc889To0ffvih8vPzlZiYqNzcXL3++uv66quvNHr06IPOpG3VqpVKS0v19ddfO/2HbjVr1pQkNW/e/GevAuH3+w+ZM37Rr9qfdxQqfzarmdmWLVusfv361r59e9u2bVvYodGQadOmObuJKzoBIuSVV15xdo9PmTKlUm3l5eU5Z7E9/vjjdtttt5nX67X58+dbdHS089jHHnssrP5ly5ZZdHS0TZ482TnzNCUlxTnrac2aNc7Yhv79+4cd7rr00kudw6yhsW5er9cZY+P3+61x48aWkZFhZmalpaXO4eTQ7uxmzZqZJOdEjKefftoZj9ahQwdn0HFMTIz99a9/NUnWp08fO/30083r9Zrf73cO344dO9YGDx7sDD4N7aLv0KGDNWzY0JkHV111lZ100kkWHR1tTZo0sZNPPtkkOWcNhg7jZWRkWExMjDP+Z+DAgZaenm6pqalWu3Ztk/afWRofH2/33HOPbdiwwS666CKTZLm5uc5g4Pr161ujRo1sx44dlpOTY3369LFp06aZx+OxxMRES0pKsqefftqmTJliiYmJNnr0aNu+fbtzuCs1NdXZ3R96/WvXrnXGc5x33nnm8XicQ9VLliyxjh07WtOmTc3MnMM+bdq0sezsbGdwtLT/LLvTTjvNgsGgcwKE9L/Dj9dff7116tTJmjZtaiNHjnROrhgxYoSlp6eHDY6++uqrbfz48U5d48aNcw5LhvobNWqUXXbZZVa/fn2nphtvvNHatm0b9p6FDlGFToA47rjjnENkl156adihpIEDBzrr0JgxY5whBSkpKdagQQO79tprncH8fr/fGY8Y6j/UnrT/RJ7nn3/eOQwUWq9Cbfp8Pps2bZoz/mjo0KE2fvx45xBUnz59TPrfuL7Qch4aTxpa/srXf9lll5m0/0y79957zxkL2KVLF1u7dq0tX77ceXzNmjXtpptucp7bqVMnu+WWW5yTTELjac3MevXq5Yy/u+iii5wxO6eddpp17drVCgsLrbi42JKTk52xprfccouzbLdq1cqOOeYYu/HGG51l64orrrDU1FRneenXr59J+4dJhMYxZWZm2rXXXuscZh0zZoxzSLNPnz42ePBg8/v9NnbsWIuLi7PU1FRnLGaDBg0sPT3dgsGgpaSk2D//+U9bsGCBs23r2LGjMy/Gjh1r99xzj+Xm5lrHjh3t8ssvd06ASE1NtUaNGlmLFi3spptusptuuskyMzOtSZMmziHDPn36OIe8cnNznfeqc+fOtmbNGjv77LMtOjraWZ4LCgrs/vvvt9tuu82k/YegU1JSrEWLFpaZmWkTJ060zZs3W0FBgTPUoXv37tazZ087++yznbFwcXFxVlhYaCeddJJzNv2yZcvsH//4h7OMx8TE2IgRI+wf//iHcyJZ48aNnXFhEyZMsOzsbGvWrJlz6Dc0lKJPnz7OUIdQexMmTLCUlBRLSUmxJk2amNn+s0MbNGhgdevWtQYNGjjbkGbNmjknuNSqVcsSExOddTx0gk3opIv27dubtH9sW8uWLZ2xg9L+IQqzZs2y/Px8k2QPPvigXX755U5btWrVsujoaDvhhBOsa9euziHoM844w1q3bm3BYNBGjBhhl19+uZmZpaam2jHHHGPR0dHWvHlzO/PMMy0QCFjbtm2d+kPTMzMzzev1Omd2hsYJ5+fn27Jly+yzzz6zyy67LOxEotAwpYyMDBs3bpxNnz7dObt69erVtn79eqf+9u3bW4sWLax169bWq1cve/zxx23y5Mn2zjvvmJnZkiVLLBAI2L333mtr16616dOnW0JCgqWlpdmyZctsw4YNtnLlSjvmmGOcQ6JffPGFpaen28knn2wDBgywXr162bPPPmunnnqqNWzY0IYMGWLHHnts2GHRYcOGWX5+vj3yyCO2YcMG+9e//mWzZ892hgmsXbvW/H6/jR8/3t5//31bs2aN3XHHHc7h6bPPPtu5CsE333xjpaWllYk/ZvY7GzNXPsyZ7T8bpWHDhtauXTu74IILDgpgxcXFzgfbz4U5M3MG4mZnZ1eqrfJj5oLBoGVmZtrNN99sZuaMhaoozJmZLVu2zDp27GjBYNAZO1G3bl3n9Om0tDSrU6dO2JlwFYW5UFtt27Z1HhMXF2c5OTlO3WvXrg07jTw0KDz04R4IBKx58+bWtWtXGzRokFN7v379rG7dus7zjj32WLviiivCTs1v1qyZNW3a1GrUqGGBQMA5QzO0URs6dKhJcl5L+ZNOQpcCkP53plkoWGRlZTkb59Cg4dAHQmjjl5mZ6VyaJD4+3um7fA0jR460MWPGONNDY/xC9QeDQatRo4YzcPb111+v8PT3hg0bOmM/ygevUNBOTEy0zMxMa9eunTPfZ8yY4YTZ8mMxQuNVMjIyrHbt2s4lXUKBPPThfMwxx1R4Knv59jIzM+3ss8+2Bx54wCQ5Z6OWH0MXGuNUPuCVv4WWr6SkJGvbtq0zZi40pkb638kF5ceJBQIB5+zF0OVQQgOxQ+NCf25sXfn+Q8vBpEmTrLCw0HmfQ48p/wF/qFsohJYfHxmqNzT+LvT/K6+8Ynfeeaczb0L1h8bShQZ+lx/PWr7d0JhGSXbiiSeGbY9C9YfWXY/HYwUFBc5JFEuXLrU333zTuTTJgZeOCI1LC60jofk6f/58i4uLc+ZDaJ5NnDjRzj//fEtKSrKEhAQzMzv//PMrHLMZDAbtuOOOs1mzZllSUpLVrl07bExbSkqKPfXUU7ZgwQJLSkqycePGhV0Gp/yYp9atW9vdd9/thLn+/fvbiBEjnNAZGkMaCibl++nTp4+zPqekpFhCQoIlJyfbhRdeGHZpkp49e1rr1q0tKSnJCX4+n895bWeffbZt377drr32Wid4hs6Iv/DCC23YsGHOeLvQcj5ixAgbPny4JSUlWXJysjVv3ty5z+fzWfPmza1Vq1bWo0cPCwaDFh0dbXPmzLHzzjvP0tPTLScnp8LlOiYmxmJjY61GjRphYwVDy5XZ/jB3wQUXOCefhLYdB64PzZo1c5bnSy65JOyLZb9+/ax3794VjoGsW7euM943NMasQ4cO9sILLzjrVFxcnDVv3jxsrF/orHGPx2O1a9e2u+++28zM+SIdWnZC288ePXrYxo0b7eKLLw7b2bB48eKwz0xp/5js0NnPKSkp5vP5bOLEic77GXpvAoGAjRw50rmUTGJiYlj9xcXFdv755x+0Hdu0aZPT31/+8hfnjP6RI0faJZdcYqmpqVavXj0LBAKWnp5uw4cPt2+//dZ5zieffGInnniisx1u1KiRTZo0yb744gvni87EiROdx+/Zs8emT59u+fn55vP5rGbNmnbiiSc6lx0yM1u+fLl17NjROWmnb9++9sMPP4R9Hoe2rX/IS5McbcqfVXM0tXU0eeCBB8zn89mPP/54VLVVWaEPruroszrb+qPYvHmzSbIXXnihUo+X/vfl6XC2VVlV7fNItVUVFR2lOBrawpERCvZHW1t/RPsHLQFHwOLFi1W3bl3VqlVL77//vqZMmaJTTjnlVw0Krc62fm2f0v7xftVR/29p64/ipZde0s6dO1VYWKitW7fqkksuUX5+vjOAO1JtRaLPSNQP4CgW6TTpRq+88spBpx+Xv5lVfm9adbZVnfWb7d8tfajH9OvXr9LthFx33XXOrxbk5+fbpEmTbNeuXb/qNVRHW59//vkhaw8EAmGXhwldbiJ02CE07mTJkiW/2M8DDzxwUPu/tq3KqqjP0C00RsfMnHFSFd3Gjh1bpbYOt2XLllnTpk0tJibGMjIybPDgwbZx48ZfrDE/Pz/sUgeh9zd0KKsqbYVer37FnrlfW39F71f5+vX/D7+dfvrpVWqrMpo0aXLIth544IEq7U2rbFtV3a78lj7Nfn47EBcXZ59//nml2zqa9evX75D1l/91oqo8pyp706qzrcqq7Gv+uff/lVdeqdaaDheP2S9cTwMH2b17t3M2XUVCZ6od6baqu8/vv//eOSvvQDExMUpJSTnitVenffv2aePGjRXet3PnTgWDQeeM2/J8Pp9zBmRlhC7rUpGqtlXdfX799deHPOM7MTFRGRkZEam/qn6uxtLSUufs7IocuJzyfv3P559/fsjfv8zMzHQu9VKdbVXnNrEyff7cdkDa/+Pt0dHR1TovIuGLL75wfh/4QCkpKc4la37rc6qz/9+qsn1++umnh2yjVq1arjhiQpgDAABwsd/ddeYAAAD+SAhzAAAALkaYAwAAcDHCHAAAgIsR5gBA0vLly+XxeJzfvayM/Px83XzzzYetJgCoDMIcAFc488wz5fF4NG7cuIPuO/fcc+XxeHTmmWce+cIAIMIIcwBcIzc3V0uWLAm7dtRPP/2khx9+WLVr145gZQAQOYQ5AK7RunVr1a5dW48++qgz7dFHH1Vubq5atWrlTCspKdHEiROVkZGhYDCozp0765133glr65lnnlGDBg0UExOj7t27V3jh2DfeeEPHHnusYmJilJubq4kTJ2rXrl2H7fUBwK9BmAPgKqNGjdKCBQuc/++77z6NHj067DGXXHKJHnnkES1atEjvvvuuCgoK1LdvX+cXTTZv3qyTTjpJAwYM0KpVq3TWWWfp0ksvDWtj9erV6tu3r0466SR98MEHWrp0qV577TWdd955h/9FAkAVEOYAuMrw4cP12muvaePGjfr888/1+uuv64wzznDu37Vrl+bNm6cbbrhB/fv3V5MmTXTPPfcoJiZG9957ryRp3rx5qlu3rubMmaOGDRtq2LBhB423u+GGG3T66adr0qRJql+/vjp27KhbbrlFixcv1k8//XQkXzIA/KyDf3gSAI5iaWlpOu6447Ro0SKZmY477jilpaU5969fv1579+5Vp06dnGk+n0/HHHOM1qxZI0las2aNOnToII/H4zymqKgorJ+VK1fq008/1YMPPuhMMzOVlZXps88+U+PGjQ/XSwSAKiHMAXCd0aNHO4c7b7/99rD7Qj83XT6ohaaHplXmJ6nLyso0duxYTZw48aD7ONkCwNGEw6wAXKdfv37as2eP9uzZo759+4bdV1BQIL/fr9dee82ZtnfvXv373/929qY1adJEb731VtjzDvy/devW+vDDD1VQUHDQze/3H6ZXBgBVR5gD4Dper1dr1qzRmjVr5PV6w+6Li4vT+PHjdfHFF2vZsmX66KOPdPbZZ+vHH3/UmDFjJEnjxo3T+vXrdeGFF2rt2rV66KGHtHDhwrB2pkyZojfffFMTJkzQqlWrtG7dOj3xxBM6//zzj9TLBIBKIcwBcKXExEQlJiZWeN/s2bM1ZMgQDR8+XK1bt9ann36qZ599VjVq1JC0/zDpI488oieffFItWrTQnXfeqWuvvTasjebNm2vFihVat26dunTpolatWmnatGnKyso67K8NAKrCY5UZPAIAAICjEnvmAAAAXIwwBwAA4GKEOQAAABcjzAEAALgYYQ4AAMDFCHMAAAAuRpgDAABwMcIcAACAixHmAAAAXIwwBwAA4GKEOQAAABcjzAEAALjY/wONbh4agyoQDwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAHWCAYAAAD+VRS3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXY0lEQVR4nO3dd3gU1f4/8PdszaZsSN10AiT00GsASeiRIiAKUgRFBVEg0ouG2IKCAgoXFKREBbGBFxWlWFDAQgsgcCkCkZZv8IoJJSRAPr8/uHt+WRIwYEgy+H49zzywM7PnnNkp+87MnFlNRAREREREpFuGsm4AEREREf09DHREREREOsdAR0RERKRzDHREREREOsdAR0RERKRzDHREREREOsdAR0RERKRzDHREREREOsdAR0RERKRzDHREdEfQNK1Yw7fffotBgwYhMjKyrJtMRFRiNP70FxHdCX788UeX188//zy++eYbfP311y7ja9asidOnTyM7Oxv169cvzSYSEd02prJuABFRSWjWrJnL64CAABgMhkLjAcBut5dWs4iISgUvuRLRP05Rl1w1TcOTTz6JxYsXo1q1arDZbGjUqBF+/PFHiAimT5+OSpUqwdPTE23atMGhQ4cKlbt+/Xq0bdsWdrsd7u7uaNGiBb766qtSWioi+idjoCMi+p/PPvsMb731Fl566SW89957OHv2LDp37ozRo0dj06ZNmDNnDubPn4+9e/fi3nvvRcE7Vt5991106NABdrsdqamp+OCDD+Dr64uOHTsy1BHRbcdLrkRE/5Obm4u1a9fCw8MDwNWzdt27d8c333yD7du3Q9M0AMDp06eRmJiIX375BTExMbhw4QJGjhyJLl26YOXKlaq8u+++Gw0aNMCkSZPw008/lckyEdE/A8/QERH9T3x8vApzAFCjRg0AQEJCggpzBcenp6cDADZv3ow//vgDAwcOxOXLl9WQn5+PTp06YcuWLTh//nwpLgkR/dPwDB0R0f/4+vq6vLZYLDccf/HiRQDA//3f/wEAevXqdd2y//jjD5ewSERUkhjoiIj+Jn9/fwDA7Nmzi+xVCwAOh6M0m0RE/zAMdEREf1OLFi1QoUIF7N27F08++WRZN4eI/oEY6IiI/iZPT0/Mnj0bAwcOxB9//IFevXohMDAQp0+fxs6dO3H69GnMmzevrJtJRHcwBjoiohLQv39/REREYNq0aRgyZAjOnj2LwMBA1KtXD4MGDSrr5hHRHY4//UVERESkc3xsCREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RyfQwcgPz8fJ0+ehJeXl8sPcBMREREBgIjg7NmzCAkJgcFQ/s6HMdABOHnyJMLDw8u6GURERFTOHTt2DGFhYWXdjEIY6AB4eXkBuLqS7HZ7GbeGiIiIypvs7GyEh4erzFDeMNAB6jKr3W5noCMiIqLrKq+3ZpW/i8BEREREdFMY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0joGOiIiISOcY6IiIiIh0zlTWDSAiIqLyJzk5uVyXR654ho6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSOgY6IiIhI5xjoiIiIiHSuTAPdd999h65duyIkJASapuGTTz657rxDhgyBpmmYNWuWy/jc3FwMHz4c/v7+8PDwQLdu3XD8+PHb23AiIiKicqRMA9358+dRt25dzJkz54bzffLJJ/jpp58QEhJSaFpiYiJWrlyJ5cuXY+PGjTh37hy6dOmCK1eu3K5mExEREZUrprKsPCEhAQkJCTec58SJE3jyySexZs0adO7c2WVaVlYWFi5ciHfeeQft2rUDALz77rsIDw/H+vXr0bFjx9vWdiIiIqLyolzfQ5efn48BAwZg7NixqFWrVqHp27Ztw6VLl9ChQwc1LiQkBLVr18bmzZuvW25ubi6ys7NdBiIiIiK9KteB7uWXX4bJZMKIESOKnJ6RkQGLxQIfHx+X8Q6HAxkZGdctd+rUqfD29lZDeHh4ibabiIiIqDSV20C3bds2vPbaa1iyZAk0Tbup94rIDd8zceJEZGVlqeHYsWN/t7lEREREZabcBrrvv/8emZmZiIiIgMlkgslkQnp6OkaPHo3IyEgAQFBQEPLy8nDmzBmX92ZmZsLhcFy3bKvVCrvd7jIQERER6VW5DXQDBgzArl27kJaWpoaQkBCMHTsWa9asAQA0bNgQZrMZ69atU+87deoUfvnlF8TGxpZV04mIiIhKVZn2cj137hwOHTqkXh85cgRpaWnw9fVFREQE/Pz8XOY3m80ICgpCtWrVAADe3t4YPHgwRo8eDT8/P/j6+mLMmDGIiYlRvV6JiIiI7nRlGui2bt2K+Ph49XrUqFEAgIEDB2LJkiXFKmPmzJkwmUy4//77kZOTg7Zt22LJkiUwGo23o8lERERE5U6ZBrq4uDiISLHnP3r0aKFxbm5umD17NmbPnl2CLSMiIiLSj3J7Dx0RERERFQ8DHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOMdARERER6RwDHREREZHOlWmg++6779C1a1eEhIRA0zR88sknatqlS5cwfvx4xMTEwMPDAyEhIXjwwQdx8uRJlzJyc3MxfPhw+Pv7w8PDA926dcPx48dLeUmIiIiIyk6ZBrrz58+jbt26mDNnTqFpFy5cwPbt2/HMM89g+/btWLFiBQ4cOIBu3bq5zJeYmIiVK1di+fLl2LhxI86dO4cuXbrgypUrpbUYRERERGXKVJaVJyQkICEhochp3t7eWLduncu42bNno0mTJvjtt98QERGBrKwsLFy4EO+88w7atWsHAHj33XcRHh6O9evXo2PHjrd9GYiIiIjKmq7uocvKyoKmaahQoQIAYNu2bbh06RI6dOig5gkJCUHt2rWxefPm65aTm5uL7Oxsl4GIiIhIr3QT6C5evIgJEyagb9++sNvtAICMjAxYLBb4+Pi4zOtwOJCRkXHdsqZOnQpvb281hIeH39a2ExEREd1Ough0ly5dQp8+fZCfn4+5c+f+5fwiAk3Trjt94sSJyMrKUsOxY8dKsrlEREREparcB7pLly7h/vvvx5EjR7Bu3Tp1dg4AgoKCkJeXhzNnzri8JzMzEw6H47plWq1W2O12l4GIiIhIr8p1oHOGuYMHD2L9+vXw8/Nzmd6wYUOYzWaXzhOnTp3CL7/8gtjY2NJuLhEREVGZKNNerufOncOhQ4fU6yNHjiAtLQ2+vr4ICQlBr169sH37dnz22We4cuWKui/O19cXFosF3t7eGDx4MEaPHg0/Pz/4+vpizJgxiImJUb1eiYiIiO50ZRrotm7divj4ePV61KhRAICBAwciOTkZq1atAgDUq1fP5X3ffPMN4uLiAAAzZ86EyWTC/fffj5ycHLRt2xZLliyB0WgslWUgIiIiKmtlGuji4uIgItedfqNpTm5ubpg9ezZmz55dkk0jIiIi0o1yfQ8dEREREf01BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIiItK5Mg103333Hbp27YqQkBBomoZPPvnEZbqIIDk5GSEhIbDZbIiLi8OePXtc5snNzcXw4cPh7+8PDw8PdOvWDcePHy/FpSAiIiIqW2Ua6M6fP4+6detizpw5RU6fNm0aZsyYgTlz5mDLli0ICgpC+/btcfbsWTVPYmIiVq5cieXLl2Pjxo04d+4cunTpgitXrpTWYhARERGVKVNZVp6QkICEhIQip4kIZs2ahcmTJ6Nnz54AgNTUVDgcDixbtgxDhgxBVlYWFi5ciHfeeQft2rUDALz77rsIDw/H+vXr0bFjx1JbFiIiIqKyUm7voTty5AgyMjLQoUMHNc5qtaJ169bYvHkzAGDbtm24dOmSyzwhISGoXbu2moeIiIjoTlemZ+huJCMjAwDgcDhcxjscDqSnp6t5LBYLfHx8Cs3jfH9RcnNzkZubq15nZ2eXVLOJiIiISl25PUPnpGmay2sRKTTuWn81z9SpU+Ht7a2G8PDwEmkrERERUVkot4EuKCgIAAqdacvMzFRn7YKCgpCXl4czZ85cd56iTJw4EVlZWWo4duxYCbeeiIiIqPSU20BXqVIlBAUFYd26dWpcXl4eNmzYgNjYWABAw4YNYTabXeY5deoUfvnlFzVPUaxWK+x2u8tAREREpFdleg/duXPncOjQIfX6yJEjSEtLg6+vLyIiIpCYmIiUlBRER0cjOjoaKSkpcHd3R9++fQEA3t7eGDx4MEaPHg0/Pz/4+vpizJgxiImJUb1eiYiIiO50ZRrotm7divj4ePV61KhRAICBAwdiyZIlGDduHHJycjBs2DCcOXMGTZs2xdq1a+Hl5aXeM3PmTJhMJtx///3IyclB27ZtsWTJEhiNxlJfHiIiIqKyoImIlHUjylp2dja8vb2RlZXFy69EREQAkpOTy3V5pa28Z4Vyew8dERERERUPAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREemc6VbfeOzYMRw9ehQXLlxAQEAAatWqBavVWpJtIyIiIqJiuKlAl56ejjfeeAPvvfcejh07BhFR0ywWC1q1aoXHHnsM9957LwwGnvwjIiIiKg3FTl0jR45ETEwMDh48iOeeew579uxBVlYW8vLykJGRgdWrV6Nly5Z45plnUKdOHWzZsuV2tpuIiIiI/qfYZ+gsFgt+/fVXBAQEFJoWGBiINm3aoE2bNpgyZQpWr16N9PR0NG7cuEQbS0RERESFFTvQTZ8+vdiF3n333bfUGCIiIiK6ebd0o1tOTg4uXLigXqenp2PWrFlYs2ZNiTWMiIiIiIrnlgLdPffcg7fffhsA8Oeff6Jp06Z49dVX0b17d8ybN69EG0hEREREN3ZLgW779u1o1aoVAOCjjz6Cw+FAeno63n77bbz++usl2kAiIiIiurFbCnQXLlyAl5cXAGDt2rXo2bMnDAYDmjVrhvT09BJtIBERERHd2C0FuqioKHzyySc4duwY1qxZgw4dOgAAMjMzYbfbS7SBRERERHRjtxTokpKSMGbMGERGRqJp06Zo3rw5gKtn6+rXr1+iDSQiIiKiG7uln/7q1asXWrZsiVOnTqFu3bpqfNu2bdGjR48SaxwRERER/bVb/i3XoKAgBAUFuYxr0qTJ324QEREREd2cYl9yHTp0KI4dO1ased9//30sXbr0lhtFRERERMVX7DN0AQEBqF27NmJjY9GtWzc0atQIISEhcHNzw5kzZ7B3715s3LgRy5cvR2hoKObPn387201ERERE/1PsQPf8889j+PDhWLhwId544w388ssvLtO9vLzQrl07vPXWW6rXKxERERHdfjd1D11gYCAmTpyIiRMn4s8//0R6ejpycnLg7++PKlWqQNO029VOIiIiIrqOW+4UUaFCBVSoUKEEm0JEREREt+KWnkNHREREROVHuQ50ly9fxtNPP41KlSrBZrOhcuXKeO6555Cfn6/mEREkJycjJCQENpsNcXFx2LNnTxm2moiIiKh0letA9/LLL+ONN97AnDlzsG/fPkybNg3Tp0/H7Nmz1TzTpk3DjBkzMGfOHGzZsgVBQUFo3749zp49W4YtJyIiIio95TrQ/fDDD7jnnnvQuXNnREZGolevXujQoQO2bt0K4OrZuVmzZmHy5Mno2bMnateujdTUVFy4cAHLli0r49YTERERlY5bDnSXL1/G+vXr8eabb6qzYSdPnsS5c+dKrHEtW7bEV199hQMHDgAAdu7ciY0bN+Luu+8GABw5cgQZGRkuj0mxWq1o3bo1Nm/eXGLtICIiIirPbqmXa3p6Ojp16oTffvsNubm5aN++Pby8vDBt2jRcvHgRb7zxRok0bvz48cjKykL16tVhNBpx5coVvPjii3jggQcAABkZGQAAh8Ph8j6Hw4H09PTrlpubm4vc3Fz1Ojs7u0TaS0RERFQWbukM3ciRI9GoUSOcOXMGNptNje/Rowe++uqrEmvc+++/j3fffRfLli3D9u3bkZqaildeeQWpqaku8137/DsRueEz8aZOnQpvb281hIeHl1ibiYiIiErbLZ2h27hxIzZt2gSLxeIyvmLFijhx4kSJNAwAxo4diwkTJqBPnz4AgJiYGKSnp2Pq1KkYOHAggoKCAFw9UxccHKzel5mZWeisXUETJ07EqFGj1Ovs7GyGOiIiItKtWzpDl5+fjytXrhQaf/z4cXh5ef3tRjlduHABBoNrE41Go3psSaVKlRAUFIR169ap6Xl5ediwYQNiY2OvW67VaoXdbncZiIiIiPTqlgJd+/btMWvWLPVa0zScO3cOU6ZMUR0WSkLXrl3x4osv4vPPP8fRo0excuVKzJgxAz169FD1JiYmIiUlBStXrsQvv/yCQYMGwd3dHX379i2xdhARERGVZ7d0yXXmzJmIj49HzZo1cfHiRfTt2xcHDx6Ev78/3nvvvRJr3OzZs/HMM89g2LBhyMzMREhICIYMGYKkpCQ1z7hx45CTk4Nhw4bhzJkzaNq0KdauXVuiZwqJiIiIyjNNRORW3piTk4P33nsP27dvR35+Pho0aIB+/fq5dJLQi+zsbHh7eyMrK4uXX4mIiAAkJyeX6/JKW3nPCrd0hg4AbDYbHn74YTz88MMl2R4iIiIiukm3HOhOnDiBTZs2ITMz0+W3VQFgxIgRf7thRERERFQ8txToFi9ejKFDh8JiscDPz8/lmW+apjHQEREREZWiWwp0SUlJSEpKwsSJEws9VoSIiIiIStctpbELFy6gT58+DHNERERE5cAtJbLBgwfjww8/LOm2EBEREdEtuKVLrlOnTkWXLl3w5ZdfIiYmBmaz2WX6jBkzSqRxRERERPTXbinQpaSkYM2aNahWrRoAFOoUQURERESl55YC3YwZM7Bo0SIMGjSohJtDRERERDfrlu6hs1qtaNGiRUm3hYiIiIhuwS0FupEjR2L27Nkl3RYiIiIiugW3dMn1559/xtdff43PPvsMtWrVKtQpYsWKFSXSOCIiIiL6a7cU6CpUqICePXuWdFuIiIiI6Bbc8k9/EREREVH5wJ96ICIiItK5Yp+ha9CgAb766iv4+Pigfv36N3ze3Pbt20ukcURERET014od6O655x5YrVYAQPfu3W9Xe4iIiIjoJhU70E2ZMgUPP/wwXnvtNUyZMuV2tomIiIiIbsJN3UOXmpqKnJyc29UWIiIiIroFNxXoROR2tYOIiIiIbtFN93K9UWcIIiIiIip9N/0cuqpVq/5lqPvjjz9uuUFEREREdHNuOtA9++yz8Pb2vh1tISIiIqJbcNOBrk+fPggMDLwdbSEiIiKiW3BT99Dx/jkiIiKi8oe9XImIiIh07qYuuebn59+udhARERHRLbrpx5YQERERUfnCQEdERESkcwx0RERERDrHQEdERESkcwx0RERERDrHQEdERESkcwx0RERERDrHQEdERESkcwx0RERERDrHQEdERESkcwx0RERERDpX7gPdiRMn0L9/f/j5+cHd3R316tXDtm3b1HQRQXJyMkJCQmCz2RAXF4c9e/aUYYuJiIiISle5DnRnzpxBixYtYDab8cUXX2Dv3r149dVXUaFCBTXPtGnTMGPGDMyZMwdbtmxBUFAQ2rdvj7Nnz5Zdw4mIiIhKkamsG3AjL7/8MsLDw7F48WI1LjIyUv1fRDBr1ixMnjwZPXv2BACkpqbC4XBg2bJlGDJkSGk3mYiIiKjUleszdKtWrUKjRo1w3333ITAwEPXr18eCBQvU9CNHjiAjIwMdOnRQ46xWK1q3bo3NmzeXRZOJiIiISl25DnSHDx/GvHnzEB0djTVr1mDo0KEYMWIE3n77bQBARkYGAMDhcLi8z+FwqGlFyc3NRXZ2tstAREREpFfl+pJrfn4+GjVqhJSUFABA/fr1sWfPHsybNw8PPvigmk/TNJf3iUihcQVNnToVzz777O1pNBEREVEpK9dn6IKDg1GzZk2XcTVq1MBvv/0GAAgKCgKAQmfjMjMzC521K2jixInIyspSw7Fjx0q45URERESlp1wHuhYtWmD//v0u4w4cOICKFSsCACpVqoSgoCCsW7dOTc/Ly8OGDRsQGxt73XKtVivsdrvLQERERKRX5fqS61NPPYXY2FikpKTg/vvvx88//4z58+dj/vz5AK5eak1MTERKSgqio6MRHR2NlJQUuLu7o2/fvmXceiIiIqLSUa4DXePGjbFy5UpMnDgRzz33HCpVqoRZs2ahX79+ap5x48YhJycHw4YNw5kzZ9C0aVOsXbsWXl5eZdhyIiIiotKjiYiUdSPKWnZ2Nry9vZGVlcXLr0RERACSk5PLdXmlrbxnhXJ9Dx0RERER/TUGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKdY6AjIiIi0jkGOiIiIiKd01Wgmzp1KjRNQ2JiohonIkhOTkZISAhsNhvi4uKwZ8+esmskERERUSnTTaDbsmUL5s+fjzp16riMnzZtGmbMmIE5c+Zgy5YtCAoKQvv27XH27NkyaikRERFR6dJFoDt37hz69euHBQsWwMfHR40XEcyaNQuTJ09Gz549Ubt2baSmpuLChQtYtmxZGbaYiIiIqPToItA98cQT6Ny5M9q1a+cy/siRI8jIyECHDh3UOKvVitatW2Pz5s2l3UwiIiKiMmEq6wb8leXLl2P79u3YsmVLoWkZGRkAAIfD4TLe4XAgPT39umXm5uYiNzdXvc7Ozi6h1hIRERGVvnId6I4dO4aRI0di7dq1cHNzu+58mqa5vBaRQuMKmjp1Kp599tkSaycREVFpOT7h+xIvM+ylViVeJpWucn3Jddu2bcjMzETDhg1hMplgMpmwYcMGvP766zCZTOrMnPNMnVNmZmahs3YFTZw4EVlZWWo4duzYbV0OIiIiotupXJ+ha9u2LXbv3u0y7qGHHkL16tUxfvx4VK5cGUFBQVi3bh3q168PAMjLy8OGDRvw8ssvX7dcq9UKq9V6W9tOREREVFrKdaDz8vJC7dq1XcZ5eHjAz89PjU9MTERKSgqio6MRHR2NlJQUuLu7o2/fvmXRZCIiIqJSV64DXXGMGzcOOTk5GDZsGM6cOYOmTZti7dq18PLyKuumEREREZUK3QW6b7/91uW1pmlITk5GcnJymbSHiIiIqKyV604RRERERPTXdHeGjoiI6Fb8a+jXJVreE2+0KTTu1d5dSrSO0e9/VqLl0Z2LZ+iIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdM5U1g0gIqJ/tn3Va5R4mTX+s6/EyyQqz3iGjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjnGOiIiIiIdI6BjoiIiEjn+Bw6IiqW5OTkcl0eEdE/Gc/QEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzpXrQDd16lQ0btwYXl5eCAwMRPfu3bF//36XeUQEycnJCAkJgc1mQ1xcHPbs2VNGLSYiIiIqfeX6t1w3bNiAJ554Ao0bN8bly5cxefJkdOjQAXv37oWHhwcAYNq0aZgxYwaWLFmCqlWr4oUXXkD79u2xf/9+eHl5lfES3HliUmNKtLzdA3eXaHlERET/ROU60H355ZcurxcvXozAwEBs27YNd911F0QEs2bNwuTJk9GzZ08AQGpqKhwOB5YtW4YhQ4aURbOJiIiISlW5vuR6raysLACAr68vAODIkSPIyMhAhw4d1DxWqxWtW7fG5s2by6SNRERERKWtXJ+hK0hEMGrUKLRs2RK1a9cGAGRkZAAAHA6Hy7wOhwPp6enXLSs3Nxe5ubnqdXZ29m1oMREREVHp0M0ZuieffBK7du3Ce++9V2iapmkur0Wk0LiCpk6dCm9vbzWEh4eXeHuJiIiISosuAt3w4cOxatUqfPPNNwgLC1Pjg4KCAPz/M3VOmZmZhc7aFTRx4kRkZWWp4dixY7en4URERESloFwHOhHBk08+iRUrVuDrr79GpUqVXKZXqlQJQUFBWLdunRqXl5eHDRs2IDY29rrlWq1W2O12l4GIiIhIr8r1PXRPPPEEli1bhn//+9/w8vJSZ+K8vb1hs9mgaRoSExORkpKC6OhoREdHIyUlBe7u7ujbt28Zt56IiIiodJTrQDdv3jwAQFxcnMv4xYsXY9CgQQCAcePGIScnB8OGDcOZM2fQtGlTrF27ls+gIyIion+Mch3oROQv59E0DcnJyUhOTr79DSIiIiIqh8r1PXRERERE9NcY6IiIiIh0joGOiIiISOfK9T10RPTXjk/4vsTLDHupVYmXSUREtw/P0BERERHpHAMdERERkc4x0BERERHpHAMdERERkc4x0BERERHpHAMdERERkc4x0BERERHpHAMdERERkc4x0BERERHpHAMdERERkc4x0BERERHpHAMdERERkc6ZyroBRERE9M/01ddVSrS8tm1+LdHy9IRn6IiIiIh0joGOiIiISOd4yfVOkuxdwuVllWx5REREdFvwDB0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcAx0RERGRzjHQEREREekcHyxM5dK+6jVKtLwa/9lXouURERGVJzxDR0RERKRzDHREREREOsdAR0RERKRzDHREREREOsdAR0RERKRzDHREREREOsdAR0RERKRzfA4d0W30au8uJVre6Pc/K9HyiIjozsAzdEREREQ6d8ecoZs7dy6mT5+OU6dOoVatWpg1axZatWpV1s0ionIm6Ju0Ei8zI75eiZdZLMneJVxeVqFRMakxJVrF7oG7S7Q8Irrqjgh077//PhITEzF37ly0aNECb775JhISErB3715ERESUdfOI6B8ocsLnJVre0Zc6l2h5RHRnuSMuuc6YMQODBw/GI488gho1amDWrFkIDw/HvHnzyrppRERERLed7s/Q5eXlYdu2bZgwYYLL+A4dOmDz5s1l1CrSg38N/bpEy3vijTYlWh4REVFx6T7Q/f7777hy5QocDofLeIfDgYyMjCLfk5ubi9zcXPU6K+vqfSPZ2dm3rZ21p6wp0fJ+ebZj4ZG5UqJ1oIjP40rOlRKuoujP/NyV219PTt75217HxUuXbnsdZ3NLdjmuV0/BfeZ21fHthrolWkdc652FxuWfP1eidQBFL0t+7oXbXsedss+X9P5+vXq4z99cPaWxz58/n3/b6yjpskVKeL8rKaJzJ06cEACyefNml/EvvPCCVKtWrcj3TJkyRQBw4MCBAwcOHDjc1HDs2LHSiDc3Tfdn6Pz9/WE0GgudjcvMzCx01s5p4sSJGDVqlHqdn5+PP/74A35+ftA07ba290ays7MRHh6OY8eOwW63s45yUM+dUkdp1cM6yl89d0odpVUP6yh/9ZTWsvwVEcHZs2cREhJSZm24Ed0HOovFgoYNG2LdunXo0aOHGr9u3Trcc889Rb7HarXCarW6jKtQocLtbOZNsdvtt32jvVPqKK167pQ6Sqse1lH+6rlT6iitelhH+auntJblRry9vcu0/hvRfaADgFGjRmHAgAFo1KgRmjdvjvnz5+O3337D0KFDy7ppRERERLfdHRHoevfujf/+97947rnncOrUKdSuXRurV69GxYoVy7ppRERERLfdHRHoAGDYsGEYNmxYWTfjb7FarZgyZUqhy8Gso+zquVPqKK16WEf5q+dOqaO06mEd5a+e0loWvdNEymv/WyIiIiIqjjvilyKIiIiI/skY6IiIiIh0joGOFE3T8Mknn5RaOUePHoWmaUhLS1Pjvv32W2iahj///POW6y+JMv6uuLg4JCYmlln9TkV9xgUVZ139VRkFyynqs1+yZEmJPBaoYDmlva06RUZGYtasWX+7XqfifLYlXU5praPSNmjQIHTv3v1vrSNnGcVxvX28OPX/1TzFXYaS3h6drrceb1d9tyI5ORn16tUr1XKK2j7Ky7EeYKBzUdTK+uijj+Dm5oZp06YhOTkZmqYVehxKWloaNE3D0aNHAQC9evWCpmkIDAzE2bNnXcoJCQlBXFxcscpxHqQLluNUr149JCcnl1i7Bw0aBADo0aOHqq9gGUFBQcVuMwAMHDgQZ8+exaBBg6Bpmhq8vb3x+OOP48yZM9dbDYUULMNkMiEiIkKV4Vy2gkN8fDwAwMfHR427UbgrqoyiBueyFdfatWuLbPf48eNLpK7itPv48eMAgKeeeqrIMk6dOoWEhIRiLU9SUtJ1v+xuppzrWbJkiUvbbTYbgoKCsGfPnkLzeXl5Xbe+kirnVtvtcDjQtWvXQvWVRjkvvPACIiIiYLVaERQUhI4dO2LDhg3w9/fHCy+8UOR7pk6diuHDh0NE8Prrr0PTNJjN5kJl2O12aJqGyMjIIsvw9/fH5cuXkZeXB03TYDQaC833wQcfFCojMzMTQ4YMKbLdXl5ecHNzu267/f39kZeXh9dffx2pqalYtWoV0tPTkZSU9Jftvva44ufnh9TUVKxfv75Y7b5eOcePH8eHH354U8e4yMhIl3Wfnp6uju/XhqiC9aWnp+PZZ59Vx8Nry9E0DWFhYbcUxLKzs4sVTIuq79p5SjMElqfQeSv+TkBkoLuBt956C/369cOcOXMwbtw4AICbmxsWLlyIAwcO/OX7z549i1deecWlnMDAwFsupzguXbpUIu3u06dPoTJMJlOxy7h48aJqc6dOnXDq1CnUqFED3bp1w6effnrTPZKdZRw9ehRvvfWWKmPMmDE4deqUGsLCwvDQQw8BAP7zn//g448/diknLy+vUNnXluHu7o6oqCjs3LkT27ZtwzPPPAMAGD169HXLuJl2Hz58uFCbnY/ccQ7h4eEubb5UxO9DFrXs15YTHBys5j9/vvDvPwYFBZVIz7G/U46I4PLlywCuPjj01KlTOHnyJNq2bYsrV66gc+fOhT5zg8FQqL6SKufvtvvzzz/H+fPni6zvekqqnAMHDiA1NRUHDhzAqlWrEBcXh3PnzqF///5YsmRJkb9BuXjxYsTGxkLTNMyZMwcGgwE2mw3vvfeeSxk+Pj4wmUzXLWPAgAEwma4+OMFqtUJE8MMPP7jMt2jRIkRERLiMu/fee7Fz506kpqbil19+camzefPmuHTp0g3rtFgsmDNnDoCr69Pf3x+DBw8uVrvd3d3x6KOP4ujRo+q4ceHChWK1u6CC+7mfnx/27Nlz08e4gvtuWFgYxowZ85f1hYaGonfv3i7H1Oeeew6//fabKmvHjh031Y6CrhTjN3avPebcTH3XHteKOs7dSjn/WGXzi2Pl08CBA+Wee+4REZGXX35ZrFarfPTRR2r6lClTpG7dutK+fXu577771PgdO3YIADly5IiIiNx7770CQMaOHSsWi8WlnLp160rr1q2LVU5oaKgAkOrVqwsACQwMlNdff12V4/xN2mbNmklQUJC4u7tL27ZtxWq1yoQJE6RBgwZitVpF0zTx9PQUh8MhRqNRgoOD5emnn5b69esLAKlSpYrL79QZDAYBIAsXLpRVq1ZJgwYN1PjKlStLr169VJs/+eQTASAWi0Vq1Kghb7/9tgAQDw8PASBWq1WCg4NVm5OSkqRVq1ZiMBjEarUKALnvvvukevXqYrVa1fsmTZokUVFRYrVaxWQyqbaZzWa5++67BYBomiZubm4SExMj9erVU/M5279z584if4fPbDZLmzZtBIB4enqKr6+vdOnSRR577DEJCwtTyzNo0KBCn41z2ebPny/e3t5qnKZpUqNGDbXu6tWrpz57Nzc3MRqNAkAqV64sAGTu3LnSoUMH0TRNlWEymaRbt25q++nTp49aJpPJJHXq1JGoqCg1v8VikaioKHFzc5PIyEgJCAiQ9u3bq88VgPj7+6v/+/n5yRNPPCFeXl4uyxMRESFHjhyRI0eOCAB56aWXiizDzc1NNE0TX19fcXd3V9Od5fn4+Iibm5sa7+bmJmazWb3+8ssvZcqUKRIQEOCyngCIu7u7xMfHi8VikZCQEHF3d3dZ70ajUapWrepSb8HPwfn/oKAgVafFYpGIiAgJCgpyaZPFYlFtKDiEh4e71FdwWkBAgEyePFkASNWqVQvNZ7FYRERk0aJFEhwc7NK24OBgsVqtEhQUJJGRkWqap6en+n/VqlXFaDSKwWAQNzc38ff3dyln0qRJap/btGmT1KtXT207AQEBsmDBAgEgvr6+YjabxWq1itFolMjISFm6dKkqy8/PT62jTz/9VL777jtVv3N9mM1m8fT0FE3TxGw2i9FolPDwcDXd3d1draOAgAC1HFWqVJGRI0e6rI9rjynO41XFihVFROSBBx4QAFKtWjU1T61atWTJkiUSFxdXqByTySS9evWSTz/9VH2GzvVtMBjEYDCIpmkyc+ZMOX78uHTp0sVlv3funyIiHTt2dDkGJCQkqPcHBweLh4eHmM1mVb6vr6/4+PjIpk2b1DHMZDKJp6en1KhRQ3x8fNT+3qBBAzXN3d3dZT+3WCzi7u4ulStXFjc3NwkLCxOj0aiOE855W7RoIa1atSryGKZpmrz44otSsWJFmTlzpjrWOt9rNBrF3d1dLBaLS90F3+/h4SG1atVyWa8AZN68eS7b5rX7mY+PjyQnJ8ulS5dU/VOmTBFfX1813dvbW6xWq9hstkLl1K1bVxYuXCiVKlVSx8KEhAQxmUzi7u4ubm5uYjAYJCwsTLW9cuXKMnbsWAkMDFTfZc52O/fB/Px8adGiRaH60tLSXL7np06dqsp5+OGHZejQoWK326VChQri7u4uNWvWlM8//1zNv2fPHklISBAPDw+1vk6fPi0iIlu3bhWz2SzNmzdX8+fm5srYsWPVPtKkSRP55ptvXNqwceNGueuuu8Rms0mFChWkQ4cO8scff8jAgQMLtb/gNvtXGOgKcAa68ePHi6enp6xbt85lujPQbdu2TQwGg/z8888icv1AN2jQIDEYDNKtWzdVRsFA91flOAPd8OHDpUaNGtKqVSsxGo2ydu1al0Dn5uYm9erVkyFDhoiHh4ekpKSI3W6XJUuWyK+//qpCUuPGjcVgMMioUaMEgERHRwsAWb58ucsGZLPZJCIiQrp27arK8ff3Fx8fHwkODhZN0+Tnn3+WK1euqMDz+eefy4YNG1Rg6d+/v9SsWVMiIyMlJiZGLXujRo3EYrGIj4+PbNiwQdWZlJQknTp1EofDoQ44y5YtkxUrVqg2rV69Wl555RW1I3t5ecmvv/6qviT79OkjDodDGjVqJABkzpw5Ll8KVatWlVdffVVSUlLUgeKDDz6QvXv3SkREhJhMJnn//ffF3d1d/Pz8xMfHRz788EOpV6+eKmPChAkyfvx48fLyEoPBIHFxcfL000+Lp6enREVFSbVq1eT3338Xk8mkwkP37t1Vfc62+/n5SYMGDVyC7YgRI8TT01O1393dXdzd3aVNmzbyxRdfiLe3d6EAqGmavPDCC/L000+r8S1atJDU1FSXdVqnTh0ZMmSIVKhQQQwGg8TGxsr06dNVOUFBQbJ//3712ZvNZpk4caI0bNjQ5aDavHlzMZvNYrPZZOnSpfLxxx+rQPfiiy/Ku+++q+oMCwuTyMhI9UUTEBAgXl5e8vDDD6t6mjRpIi+99JIEBgaK2WwWTdPk22+/dQnowNU/joKDg8VoNKrPq1OnTqr9ACQ4OFhtp8DVcFe7dm2XcNarVy9ZsGCBLFq0SC3X1KlTZdWqVS7Bz2azqVDkDDfVqlVz+UydB3h/f38xm80yf/58CQ4OlsGDB0uTJk3UfAEBAdKwYUMVDOrUqaMChnOeZ599VqKiosRgMMiECRPE399fqlevrrYXb29vWbJkiezatUs8PT3Fw8ND7r77bnnnnXekcuXK6jOJi4uT2NhYqVq1qkyYMEG2bdsmrVu3FqPRKBaLRTp16qTWkdVqla5du4qnp6fUrFlT7Ha7atOQIUMEgEycOFFefPFFGThwoNhsNjGbzWIwGNQ6cjgcommaVK9eXT799FN56qmnxGaziZubm8sfWJMnT5b77rtP7RPe3t4iItK/f38VFv71r3/J6tWr5cMPP5SQkBAZNGiQxMbGqraGhYXJp59+KlFRUeLr6ytGo1E++ugj6datm/ocGzRoIJqmyfPPPy/R0dESGhoqJpNJ/Pz8xGQySbVq1SQ3N1dERPz8/ASAfPTRR7J371613znXzU8//SRPPPGEtGvXTpo2bSr9+/cXTdPEarXKzJkzpXHjxlKxYkXVPnd3dxX6ncF879694uXlJUajUR599FGZN2+e2l/q168vBw4cUPuhpmnSu3dvWblypXh4eIjFYpGZM2eqoOTh4SGhoaHqGGs0GsVms6k6ndvtI488In379pUuXbqIp6enDBw4UDRNk5o1awoAadu2rfTo0UOt66eeekoWLVqkgn5gYKD07dtXHadGjRolmqaJl5eXuLm5ydChQyUyMlKSk5OlYsWKMmjQILHb7fLUU0+JyWSS6tWry/jx42X69OmiaZoYjUYZMWKETJkyRQXejh07yvbt21V9UVFR0qZNG1m1apXL8WHx4sUyZ84ctS0tWLBAZs2apfZpDw8PefvttyUpKUny8/OlSZMm4ubmJkOGDJFNmzbJ0KFDxc/PT/773/+KiMj7778vFotFFixYIP/5z39k8uTJah/ftWuX/Prrr/Lpp5/Khg0bRETk5MmT4u/vLxMnTpR9+/ZJly5dJCAgQOLj4+Wbb74Rb29viY6OlpEjR6rv+L59+0psbKx89913cujQIZk+fbpYrVY5cOCA+p63Wq3y+OOPS1pamvzyyy8ye/ZsOX36tPz555/SvHlzefTRR+XUqVNy6tQpuXz5crEzDANdAQMHDlR/hXz11VeFpjsDnYhInz59pE2bNiJy/UAHXD3bYTab5dChQyLiGuj+qhxnoNuxY4d8+eWXYjabpXPnzpKQkOAS6GrUqOHS7latWklKSopqt7e3t7i5uUlwcLD06dNH/XXvPIA5z8w4hzfffFO+/PJL0TRNRo8eLSIiDodDHA6HvPPOO+Lm5iZt2rSRNWvWqC8cZ5uffPJJASApKSmqDKPRKB4eHi5hZMaMGape5xdDixYt1F/eBoNBsrOzpWnTpmIwGFQZBc8AjRw5UoWQOnXqyAMPPCAVK1aUJ554QgVY51/hVqtVcnJyRERk4cKF6iD5448/qjKsVqusWbPG5exiwfratGkjzZs3l/DwcKlVq5a4u7vLlStXRETk+eefl2bNmonNZpPhw4eLyWRSgatg6HAOQ4cOVV+kFStWlIiICHn88cfl+eefV23r2bOn+Pn5SU5OjixcuFBMJpM88sgjqoxHH31UzGaz1KhRQ0REfW7nz59Xn62z3ri4ONWu4OBgyc/PV+/p3bu3GAwGFQKdB1KRq3+dOuurUKGChIWFSa1ataRNmzaSn58vhw4dUtPff/99+eabb9RrLy8v6dmzp0yaNEmNi4yMlNq1awsA6dChg9pGX3nlFTVPwbODwNU/PEREnnnmGQEgLVu2FODqmUVn2AOunll4+eWXXd5bcPDx8VH1DRgwQAX1999/X0REPvjgAzVv7969CwXitm3bqi85AGK322XXrl0yceLE67a9cePGEhMTIwAkNjZWjEajdO7c2aXdANQfLs7Pv2A5tWvXlueff16aN28uAwYMkFatWomvr6+cP39eRES+//57l5DpbO/EiRNl586dsn79egEgnTt3Fg8PD1m9erUAkCZNmoimaVK/fn1ZsGCBeHt7qwBlMBjEbDZLly5dJC0tTapUqSIPPfSQat8nn3wiBoNBtm/fLkajUTp16iQiIosXLxabzaYCsbPe/Px8qVKlijpmGQwGERFp3769+izd3NwkNjZW7r77bqlYsaLk5+fLPffcIwDUmZs1a9aozyohIUEdt51ngpxn2EJCQlSQeu2116RXr14qTKxZs0bOnj2rluXa44rBYJCIiAhJTU1V7f73v/8tM2fOFJPJJJUqVRIRkdatW0uNGjVUMHJzc3Mp54EHHpAlS5YIAPnuu+/UtucMoKGhoSIi0rx5c5ezZM5jZWhoqPTu3VuFaOfxyhnQrt2+AwMDpWLFimKxWMTDw0MMBoNYLBZ57bXX1JnCuLg4CQ4OloEDB4qPj494eHioz/G+++4TAJKYmChTp04VAPLggw+K1WqV5s2by969ewWAzJw5U9555x0JDg6WihUrqrOKzvX91FNPiYhIbGysS5kiIjVr1hRN0yQzM1Mdf+69916x2+1y8eJFERF1Bjw0NFTefPNNERG1r//000/y6quvqn2wVq1a6nP96quvxG63S0REhMycOVONr1KliiqnefPmMnToUCnIZrOJw+GQojzzzDMux6mBAwdKhw4d1L62bNkyad26tQp0hw4dEk3T5MSJEy7ltG3bViZOnCgiV89Kt2jRosj6nNtVwYB4MxjoChg4cKA0atRIIiMjpUWLFpKdne0yvWCgO3TokJjNZlmzZs11A11ISIg6bf7AAw+ISOFAd6NyCgY6EZH4+Hhp0KCBREZGugS6Vq1aubTb+Reyh4eHOsA7h927d4vRaBQvLy91GebaQFevXj3Jzs5WlzAKluE8YJnNZhk6dKiEhIS4tHnz5s1qY+/fv794e3tLYGCgHDx4UO2UzssB156OL3hgNRqN4u/vr4KqwWAQm83mcjnHYrG4vHYezJ0hJiAgQAU654Hbw8PDJVxZrVZ1INI0TebOnasuPVx7ycBisajLj9dekiv4ZdymTRux2+3XrQOAzJ49u9D7nGfrnPPef//9Eh8fLyKivkyLGjw9PSUzM9Plc3Qug7O+uLg49cV+veH5559X/7fZbC7lOAeTyaSW3RnWC34+134xenp6uqyjoi51Xjs414+z7TabzaWc6332VqtVfbk6Lxn5+vpKs2bN1Puc28C1l8CcZ0Sc4wqePQOuntmrW7duofqufd+1twgUHJzbp7Pugp/VjBkz1OflLMdZrvMSamBgoNSsWVOMRqPLshRcR87trnfv3tKsWTMxGo0ybNgwl2Uq2D5N0+SPP/6QxYsXi7e3t7z66qt/uV6cn6WmaaqNPXr0EJGiA53zbJWmaS770/nz56Vhw4bi5uYmOTk5snbtWnn22WfVWXqLxVJoXc+dO1eF9pdfflkdt52fS/PmzV0+V+BqSCq4PufOnSuvv/66AFePdQcPHpSdO3dKu3btRNM0dfm5QoUK0qJFCzGZTC7HIuexpOBlZADyxRdfyM6dO9VlWqPRqM76mkymQvM799Vryzh48KCEhIRI8+bNJT4+3mVbdd6K4BxnNpvVZdnBgwdLxYoVZfLkyfLss88WGfqcn0O/fv2kTZs2UqFCBTEajfLII4+oPzTeffddGT58uEt9zu+Ta/fziIgIGT58uAQFBaltLzU1VS5duiQ+Pj6yZMkS0TRNff917NhRTCaT+k4Frl5ZcX7PXPt5mM1ml3Fvvvmm/Pbbb2K329XtHytWrJBLly7JtGnT1D7m3Ked62ncuHEiIlKhQgVJTU11+V5v166dAFf/4EpKSpKdO3eqaXfffbdqg/O7w/m5Pv300yLiGsCcfxQ65y/4vvvvv19ERGrUqCFJSUnXzSF/J9CxU8Q1QkNDsWHDBpw6dQqdOnUq1LvUqUqVKnj00UcxYcKEIm+2Ba52qjh16hSysrKwfPnyIm8WLU45Ti+99BJ27NhR6AZpk8nk0u6LFy9i0qRJSEtLQ1paGry8vODv74+DBw+iZs2aaNasGS5cuABN04qs5/fff0enTp1gNBohIli6dCn8/Pzg7++P3bt34+DBg3jkkUfw6aefFnqvp6cnAKB///4IDg5GXl4eMjMzcfLkSXXzeUxMDAYNGoR3330XANC0aVNYLBbMmzcPb731FgDgp59+wnvvvad6TlmtVmzcuBFLly5VdXXt2lX13Hv55Zfx7bffIjg4GL179wYArFu3Ts0bHBysPo/77rsP0dHRAIClS5fitddeg8FgwJ49e9C3b1/1noULF2LXrl1o1aoVAGDAgAH4/PPPAQCtW7dGrVq1MHnyZCQkJMDd3R2tWrXCgQMHULVqVZd107NnT3zwwQcAgFq1agGAWtcLFiyAj48P/Pz8oGka4uLiVC9dk8mk1pHz5uRRo0apsseNG4f169dj48aNyM/PBwCYzWakpaWpdjrrA4DatWsDABwOBxISEuDh4QEAePbZZ/H111+jW7duat4FCxYgLS0N33//vRpXp04dtS5iYmIwffp0NG7cWE1/5ZVX1M3pwNWOOEuXLsXw4cPVuHfeeUf1fnRzc0PNmjXxxRdfYPLkyQAADw8PjBs3Dg6HA2azGZ6enoiMjMSWLVtUOY0aNQJw9QZ4AHjzzTcLrUvnNJPJhGrVqqmyndtApUqVEBsbq9q9efNml96UvXv3VmU415dzXfj4+AAA7r//fqSlpeG5555T2/2//vUveHl5qTrHjBmD1NRUAEBUVBQcDgeqV68OAPjwww9xLWedCxcuxJ49e1Svz19++QU//vgj8vPzUbt2bTRq1Egty86dO7Fq1SoAV3vYGwwG9WiSBx98UG17Y8aMQffu3VG5cmUAgL+/P8xms+oJDQC+vr7w9vaG2WxW69ZkMsHDwwOvvPKK6jUcEhKCoKAgxMTEoEePHpg7d26hZSm4THXq1MHgwYOxadMmVbebmxuMRiM0TYObmxvat2+PpKQk9OjRAwEBAfD391dPBOjevTsaNmyIvn37qs/NZrOpOqxWq3oigL+/v1pXFosFO3fuxNixY2Gz2VQZy5YtA3D1eBUVFYU6deqgX79+qrwffvgB2dnZ2LRpE65cuYIJEyZgzJgx0DQNfn5+SEtLQ6NGjRAUFASDwYDQ0FDEx8ejTp06arkee+wxhIaGArja6eW+++7DJ598gvDwcNV5Iy0tTX3eVatWRZs2bRAVFQWz2Qyz2az2a4vFApPJhB07dqBr166Ijo5GeHg43N3d0bNnTwDAzp07AQDHjh3D1KlTYTQaMWLECKxfvx7u7u7QNA0vvvgiDh48CKPRCC8vL0yaNAkBAQGw2Wz45ptv1GfpVLVqVVy5cgWjRo1CWloa7HY7xowZo74HNE1D5cqVcfjwYdX7dvz48bjrrrsAQK2Hgt81Bfcr4Ooxq+Dx2WQywWAwYO3atdi4caP6DnNzc4PFYkF4eDiefPJJeHp6wmAwYNiwYbjrrrtw6dIlBAcHIyQkBGPGjFHl7d+/H2PHjr3u9lm7dm3UqFEDAwYMwO7du9GoUSPMnj0bAJCfn4+uXbuqsrp27Yr69esjKioKW7duLfRdnJ+fD6PRiG3btqn3pKWlYd++fXjttdcKbbcljYGuCBEREdiwYQMyMzPRoUMHZGdnFzlfUlISDhw4gOXLlxc5PTg4GBs2bMCFCxfg4+Nz3V5Lf1WOU5MmTRAWFnbdHm/OdlutVsyePRuBgYGIioqCwWBAbm6u+v/w4cNx5coV1SPtWm+99RYyMzNhtVoRHh6OuXPnwmQywWg0IioqClFRUZgyZQr++9//4tSpUy7v3b59OwCgWrVqmDZtmjrYjBgxQh3oEhISsGjRInWwa9CgAV555RU8/vjjOH36NICrQbddu3aoU6cOACAnJwdHjx5Fx44dVbs/++wzdeDYu3cvWrVqBbPZrJ6fVLFiRXXwyMzMRHh4OKKiohAfH48TJ06oejp27AgRwYkTJ+Dt7a0eP3D48GFERUWpL+ulS5ciLCwMoaGh8PT0xMmTJzFu3DisXr0aK1aswPfffw9fX1/UrVsXOTk56lEl3377repGP3LkSADA1q1bERoailOnTsFut8PDwwOdOnXCmjVrYDabAVztfr9r1y7k5uaiZcuW0DQN//nPf9RnffbsWbRt2xZ169aFw+EAcPWLIzQ0VD1eoeC24nA4UKFCBWRnZ2P58uWqB3ClSpUQHx8Pu92u5t2/fz+ioqLUl7/z83Q4HKhTpw52796N+Ph4FVYAoEKFCqq3JnC19+IjjzyC9PR0Nc5qtapAU7t2bezduxeBgYF48MEHAVw98Hfo0AGZmZnIy8tDkyZNcOLECezbt0/th85txLn9NGvWTK3L+Ph45OfnqwB8+vRpnDx5EgBw7tw57N69G1FRUWjWrBmysrIAAOHh4bh06ZLLfn758mX1Zercvvz8/AD8/zD+8ccfY+XKlXA4HDAajQgNDcXWrVtx5swZrFixAgCwe/dutQ3m5ubi9OnT6jMt2GsyMjIS+fn5yM/PR2hoKA4fPuzynt27d6NSpUpo0KABLl68iIMHDyI0NFTtj85l7NKlC/Lz8/Gvf/0LP/zwAypUqKC2gbNnzyIxMVH1Uv/999/Ro0cPtG3bVu0PTo0bN0ZMTAwSEhJw+fJlGAwGJCQkQERgs9lw7NgxZGRkYNu2bUhMTERQUJDL+zVNU59fcHAwfv75Z4wePRqZmZkqwBkMBvj4+CAnJ8el53yDBg1w7tw5XLx4Ed7e3hAR9O/fH9u2bcP333+PrVu3Ari6TzuJiFrnRqNRPTojLy8PK1euREBAAOx2uyrjxx9/hMViwR9//KHKuHLlCkQEhw4dQlhYmFpPCQkJ2LBhAwICAqBpGi5evIioqCjYbDb4+PjA4XDg999/V73ggavBePHixXjggQcAAN7e3rhw4QLuuece1K1bF/n5+bBYLIiKikL9+vUhIrBYLLBYLLiWyWRCXl4eLl++jD///BN2ux3nzp1D5cqV1TYMXD32Xr58GYcPH0ZsbCyaNGmCc+fOoW3bthARmEwmHDx4EFFRUSpgbdmyBQ0bNsTrr7+OXr16AQDS09NV7/iWLVvC19cXc+bMwcmTJ5GdnY2AgAC13TnZbDa1HK+//jp++OEHRERE4LPPPoOIwN/fH8DVsHltr/LKlSsjIyMDJpMJUVFRal/w9vZGkyZNEBUVhSpVquDixYuoWbMmgKsh8MqVKwgNDcW3336rtvWMjAyYzWb4+vqqNkZFRan6a9SogR9//NGlfue2MHToUKxYsQKjR4/GggUL1La4Z88eREZGIioqCna7HeHh4di0aRPS09PRu3dvlxMx9evXx5UrV5CZmelSf1RUlNpH6tSpg6+++qrQenayWCzF6l1cpFs6r3eHKtjLVUTk+PHjEh0dLU2bNpU///zT5ZKr0zPPPKNOP197ydV5qfT48ePqxn2r1epyyfVG5TgvuTrvFZszZ466n8zNzU1dco2Pj3dpt/Om59DQUPnhhx/UTd1t2rSR/fv3q8t9zlPH77//vstp7h07dsjx48dV/c5La35+frJ8+XKZPHmyiIg8/fTTqozPP/9cvvvuO3VZdfTo0XL06FF1uct52r5Vq1bi5+cnkZGR0r17dzWtb9++MnHiRHVZo3PnzrJjxw756KOPVLtmzZolCxcuVDcVh4SESP/+/dVN5q1atZLAwECJj48XAPLCCy+oeziAq73wli5dKnPnzlWXjxYtWiSHDx+WTp06iaenpyxYsEDc3d3VJZZZs2apm+/9/f2lSZMmMnv2bDGbzeLl5SUxMTEydepUady4sbp/bu/evWp5DQaD9OnTR106Sk5OVpfbGjVqpC6nAZB27dqJ3W5X91x9//334uvrKw8++KBs27bNpVct/ndZsUaNGjJs2DBJSkpS4xs0aCCLFi1yucTSqFEjGT16tLp/JygoSJo2bSoApHv37tKqVSt1udxms4nRaJQJEybIrFmzXD6/mJgYddnwueeek7lz56rLqGPHjpU33nhDzZ+UlCRdu3Z1udQ0ZswYeeqpp9SlOKPRKEuWLHG5+fvjjz9WPas9PDykXr164uPjo9a7c9052++8ZPLxxx/L8uXLxd/fX9VZtWpVdZlE0zRxd3eX8ePHu9xYPXToUPniiy9cLu95eXkV6q3p7G3uLPvZZ58Vd3d3adWqlbrR2tlTcfDgwWrfcV5GdZbvvIfwsccec9nnnJcNJ02aJFarVaKjo9V2EhYWJq+88ors3LlT3VLRqVMnWb16tcuxY/jw4VKvXj3x9/cXk8mkOjIZjUbx9fWVjz/+WF3S9PX1lc8//1wSExPFbreLp6enBAcHi9lslqeffloMBoO6n6lLly6yfPlyCQoKUpcSjUajmEwmGTx4sCxcuFBWr14to0aNUpfIgf/fM7Jfv36SmpoqkZGREhkZqTpF9O7dW0wmk4SFhckbb7whGzZskDFjxojBYJCgoCDVoz06OlpdvjKbzVK3bl3x8fGRFStWyN133+1yr2hISIja53x9fcVms0n79u3F4XCIt7e3eHt7S1RUlDRo0EDMZrOsWLFC9u3bJ61bt1Zt7t69u0yaNEnc3d0lODhYHnnkEWnfvr3ajoYNGyYNGzaUKlWqiL+/v4SFhUlQUJCMHDlSPD09xW63S9WqVWXAgAFq/65bt67MmzdPbedubm6yY8cOeeedd9R+t3fvXtm1a5f4+PjIXXfdJa1bt1bHN2cPcGdHtICAANVBw7kdWSwWadu2rXh6ekqHDh3EaDSqznTObbNNmzbSo0cPCQ0NFYPBIIsWLZJff/1VGjduLADk7bfflsWLF4umaWK329WxxWQyqScoOL8HKlasKA888IC89dZb8vzzz4vJZJKQkBCxWq3qsq/znuukpCTRNE2qVKmivquAq/ePtmzZUurWrStffvmluk/Y09NTXnjhBfnoo4/UpeuFCxfK1KlTJTo6WnXGmTx5sthsNjl9+rS0bNlSPD09pVmzZvLDDz/I559/LpMnT5YtW7aIiMjy5cvFarXKwoULZf/+/ZKUlCRms1kqVaokhw8flm3btkmTJk3U5dETJ05IQECA9OrVS3766Sfp2bOnNG/eXB566CE5fvy4VK9eXfz9/WX48OFqmfr16yeRkZHy8ccfy+HDh+Xnn3+Wl156SfWc3b9/v1gsFnn88cdl586dsm/fPpk7d67qOfvoo49K48aN5ciRI3L69Gl1n3ZxMNAVcG2gE7nay6VatWrSuHFjGTlyZKEglp2dre6rul6gc5bj/EJu2rRpscpxBqr27duLu7u7OBwOmTVrlvoiuF6gExFZunSp2Gw2l3stGjVqpMoZPXq0Ogg6u48X/HJxtjksLMzlnqYmTZrI/PnzVZudPQrNZrNUrVpV3QDvvI/Gx8dHGjVqpNqclJQkr732mssjGaKjoyUqKko94gX/uzfDx8dHbDabuLu7qy9Rg8GgHi/hDBK+vr7i7+9f6H6bd955RwYOHCjVq1d3uafNYDCoe/8qVKggVqtVKlWqJLVr13a5f+exxx6TevXqqXsJneX36tVLBg8eXOheHT8/P3n00UclKyvL5bElzoAEXL1x2XlwLPgIEue4Bg0aqBC8Y8cO2bRpk9SpU0csFovUqVPHpael814Rk8kkFStWFH9/f+nYsaNLu4p6zMe1g9lslvbt28uuXbsEuHoPTERERKF7cIq6B6hgwAoICHC5z8pkMknz5s1d7j2rUaOGapPzvipn2T4+PupRG84er0XVd+2jHAr2eHMejJ3jAgIC1Dq9drj28S0FH9VQqVIlqVWrlnptt9tVT2JnD1bnfaDO+zad+52z56NzcG6nfn5+UqVKFbVcBQPjjh071E33VqtV/P39VTnOz8nZQennn3+WJk2aqPXh5uamHtdw7Tpy9o4NDAyUzp07S2RkpJqnevXqsmvXLhH5//cRFVxm5zZmMBjEy8tLmjRpIr169RJvb2+pUKGCWsfOe1lr164tiYmJYrPZxNvbWxo2bKjWg/NfZ3jz8/MTkau9XCtXrix+fn4un8s999wjffv2VffcFdwWatWqJZmZmTJy5Eix2+1iMpnUfM7wHhgYKImJidK3b1913DUYDCq0pKSkyIABA6Ry5crqkRUdO3YUs9nsckxz3rfrvJ/ObrdLdHS0tG/fXt1H6OyYtHfvXtVb2/koFOd6v/a+XWevY2ePZec25LxP193dXQW6H374weV46RyaN28uYWFhKtA5H9HivBfX2Q7n46quXa9ubm5q+T08PFRoWrlypboXsuA+UrCzmPN7oGLFivLwww9L06ZN1TqoWrWqBAcHi8VikapVq6qe0M51WPC7z1lfdna2DB8+XEJCQlRbnffJOf/foUMH8ff3Fzc3N/UoGIPBIM2aNZP169er76T77rvP5fPu16+f/Pbbb6rOF198Ufz9/VUP4AYNGqjvnoCAABkwYID8/vvvav4DBw5Ijx491P2Gnp6ekpiYKPn5+XLy5Emx2WwSHR2teqPm5eVJUlKSOo4FBQVJjx491L4mIvLtt99KbGysWK1Wte2dOXNGRK4GPmcHO4CPLbljOJ/xU17KKS/effddMZvNcuHChTIt41brcx7E/k45f6eMf5pjx44JAHXQ/yvX+2xLqpziutn6bnc5N6uoKxplUQaVDmfHmvJSzj9R0TdREZUjb7/9NipXrozQ0FDs3LkT48ePx/33339TN5eWRBml3eYblVOwcwi5+vrrr3Hu3DnExMTg1KlTGDduHCIjI9X9lqVdzp3ebiIqHxjoysj3339/w9+QPHfuXKmWU1w3U19KSgpSUlIKzXPlyhVcunTpur/ReG2bMzIykJSUhIyMDAQHB+O+++7Diy++eFPtLokynH777Td1c+61Ll++DKPRiEuXLuHy5cuqd6Sz51NxLF26FEOGDAEAdTO0sxwfHx/Mnz+/RANdwfquVbFiRZffEh06dKjqnXytpk2b4qeffipWObfTpUuXMGnSJBw+fBheXl6IjY3F0qVLYTabb7isAQEBqsNFnz59AFz9/OV/Nz137969WOXc6rLearuvre/VV1/FF198odptNBphsVjg4+NTouuoVq1aLh1eCnL2PC7pMkriePdXdfbr1++G+zgAhISEqI4o1yujPEtISHDpwV7QpEmTMGnSpJt+T0hISInUXdxyiutmltXZAa4oX3zxhXriQXmliRTookGlJicnp1DPsoIK9iAqjXKK62bq++OPP1x6kTldvHgRf/75Z6GecUWVUR5dvnwZR48eLXLauXPn4ObmVmQPYrPZjIoVK/5l+WfPnsX//d//FTmtuGXcjJupLzMz87q9vg0Gg0vP0BuVU1ZutKxXrlwp8gflnQpul1xHV3tDXu83NB0OB7y8vEq8jJI43hWnzhvt48DVXrzX++os7rKXpRMnTiAnJ6fIab6+vvD19S2R95RU3X/HzdR36NCh65YTGhp6Wx85UhIY6IiIiIh0js+hIyIiItI5BjoiIiIinWOgIyIiItI5BjoiIiIinWOgIyIqJueP3v/555/Ffk9kZKT6LV8iotuFgY6I7hiDBg2CpmkYOnRooWnDhg2DpmkYNGhQ6TeMiOg2Y6AjojtKeHg4li9f7vLsqYsXL+K9995DREREGbaMiOj2YaAjojtKgwYNEBERgRUrVqhxK1asQHh4OOrXr6/G5ebmYsSIEQgMDISbmxtatmyJLVu2uJS1evVqVK1aFTabDfHx8UU+bHbz5s246667YLPZEB4ejhEjRuD8+fO3bfmIiIrCQEdEd5yHHnoIixcvVq8XLVqEhx9+2GWecePG4eOPP0Zqaiq2b9+OqKgodOzYUf26ybFjx9CzZ0/cfffdSEtLwyOPPIIJEya4lLF792507NgRPXv2xK5du/D+++9j48aNePLJJ2//QhIRFcBAR0R3nAEDBmDjxo04evQo0tPTsWnTJvTv319NP3/+PObNm4fp06cjISEBNWvWxIIFC2Cz2bBw4UIAwLx581C5cmXMnDkT1apVQ79+/Qrdfzd9+nT07dsXiYmJiI6ORmxsLF5//XW8/fbbuHjxYmkuMhH9wxX+wUkiIp3z9/dH586dkZqaChFB586d4e/vr6b/+uuvuHTpElq0aKHGmc1mNGnSBPv27QMA7Nu3D82aNYOmaWqe5s2bu9Szbds2HDp0CEuXLlXjRAT5+fk4cuQIatSocbsWkYjIBQMdEd2RHn74YXXp81//+pfLNOdPWBcMa87xznHF+Znr/Px8DBkyBCNGjCg0jR0wiKg08ZIrEd2ROnXqhLy8POTl5aFjx44u06KiomCxWLBx40Y17tKlS9i6das6q1azZk38+OOPLu+79nWDBg2wZ88eREVFFRosFsttWjIiosIY6IjojmQ0GrFv3z7s27cPRqPRZZqHhwcef/xxjB07Fl9++SX27t2LRx99FBcuXMDgwYMBAEOHDsWvv/6KUaNGYf/+/Vi2bBmWLFniUs748ePxww8/4IknnkBaWhoOHjyIVatWYfjw4aW1mEREABjoiOgOZrfbYbfbi5z20ksv4d5778WAAQPQoEEDHDp0CGvWrIGPjw+Aq5dMP/74Y3z66aeoW7cu3njjDaSkpLiUUadOHWzYsAEHDx5Eq1atUL9+fTzzzDMIDg6+7ctGRFSQJsW5UYSIiIiIyi2eoSMiIiLSOQY6IiIiIp1joCMiIiLSOQY6IiIiIp1joCMiIiLSOQY6IiIiIp1joCMiIiLSOQY6IiIiIp1joCMiIiLSOQY6IiIiIp1joCMiIiLSOQY6IiIiIp37f2CO/aaVKvvQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ! Print the models best parameters\n",
    "i = 0\n",
    "for key, value in models.items():\n",
    "    print(f\"\\n\\n{i}. Sected model: {key}\\n\")\n",
    "    print(f\"Parameters: {value.best_params_}\")\n",
    "    print(f\"Score NMAE in train-validation: {results[key][0]}\")\n",
    "    print(f\"Score MAE (train): {results[key][2]} | Score RMSE (train): {results[key][1]}\")\n",
    "    print(f\"Score MAE (test): {results[key][4]} | Score RMSE (test): {results[key][3]}\")\n",
    "    print(f\"Time: {times[key]}\")\n",
    "    i+=1\n",
    "\n",
    "# ! Plot the test score (MAE)\n",
    "for key, value in results.items():\n",
    "    plt.bar(key, abs(value[4]))\n",
    "    # print(f\"{key}: {abs(value[3])}\")\n",
    "plt.title(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MAE - test\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/basic_methods_score_mae.png\")\n",
    "plt.show()\n",
    "\n",
    "# ! Plot the test score (RMSE)\n",
    "for key, value in results.items():\n",
    "    plt.bar(key, abs(value[3]))\n",
    "    # print(f\"{key}: {abs(value[2])}\")\n",
    "plt.title(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE - test\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder\n",
    "plt.savefig(\"../data/img/basic_methods_score_rmse.png\")\n",
    "plt.show()\n",
    "\n",
    "# ! Plot the time\n",
    "for key, value in times.items():\n",
    "    plt.bar(key, value)\n",
    "plt.title(\"Time\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exporting image as png to ../data/img folder - easier to visualize the annotations, better resolution\n",
    "plt.savefig(\"../data/img/basic_methods_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Exportación del modelo seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "def train_best_model(selected_model):\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Export final selected model (RandForest_select) -> 10th position\n",
    "# Select the 9th position in the dictionary\n",
    "selected_model = models[\"RandForest_select\"]\n",
    "\n",
    "# ! Entrenamos el modelo con los mejores datos\n",
    "best_model = train_best_model(selected_model)\n",
    "\n",
    "print(f\"\\nSelected model: {model}\")\n",
    "\n",
    "# Export model as pickle file in ../data/model folder\n",
    "with open(\"../data/model/modelo_final.pkl\", \"wb\") as file:\n",
    "    pickle.dump(selected_model, file)\n",
    "\n",
    "# ! Compare the model exported with the one loaded - check if it is the same\n",
    "# Load model from pickle file\n",
    "with open(\"../data/model/modelo_final.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(f\"\\nSaved model: {loaded_model}, {type(loaded_model)}, {loaded_model.best_params_}\")\n",
    "    \n",
    "if selected_model.best_params_ == loaded_model.best_params_:\n",
    "    print(\"\\n\\nThe models are the same\")\n",
    "else:\n",
    "    print(\"\\n\\nERROR: The models are different\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# X. Output the Jupyter Notebook as an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export the notebook to HTML\n",
    "os.system(\"jupyter nbconvert --to html model.ipynb --output ../data/html/model.html\")\n",
    "print(\"Notebook exported to HTML\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4c01c8f52586033bb4bb2bf4f864991e275e728809d596b5bf2a750c26b84f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
